# -*- coding: utf-8 -*-
"""
GraphRAG Service - Ø³Ø±ÙˆÛŒØ³ Ø§ØµÙ„ÛŒ GraphRAG
Ø§ÛŒÙ† Ø³Ø±ÙˆÛŒØ³ ØªÙ…Ø§Ù… Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ GraphRAG Ø±Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯
"""

import pandas as pd
import networkx as nx
import spacy
from spacy.lang.en.stop_words import STOP_WORDS
from collections import deque
import pickle
import os
import json
import re
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from enum import Enum

# Import new modules
try:
    from graphrag_new.search import KGSearch
    from graphrag_new.utils import get_entity_type2sampels, get_llm_cache, set_llm_cache, get_relation
    from graphrag_new.query_analyze_prompt import PROMPTS
    from graphrag_new.entity_resolution import EntityResolution
    from rag_new.llm.chat_model import GptTurbo, MoonshotChat, AzureChat, QWenChat, ZhipuChat, OllamaChat, GeminiChat, AnthropicChat
    from rag_new.utils import REDIS_CONN
    from enhanced_context_generator import EnhancedContextGenerator
    NEW_MODULES_AVAILABLE = True
except ImportError:
    NEW_MODULES_AVAILABLE = False
    print("Warning: New GraphRAG modules not available. Using classic methods only.")

def remove_emojis(text: str) -> str:
    """Ø­Ø°Ù Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ø§Ø² Ù…ØªÙ†"""
    # Ø§Ù„Ú¯ÙˆÛŒ regex Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ - Ø´Ø§Ù…Ù„ ØªÙ…Ø§Ù… Ø§Ù†ÙˆØ§Ø¹ Ø§ÛŒÙ…ÙˆØ¬ÛŒ
    emoji_pattern = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # emoticons
        "\U0001F300-\U0001F5FF"  # symbols & pictographs
        "\U0001F680-\U0001F6FF"  # transport & map symbols
        "\U0001F1E0-\U0001F1FF"  # flags (iOS)
        "\U00002702-\U000027B0"  # dingbats
        "\U000024C2-\U0001F251"  # enclosed characters
        "\U0001F900-\U0001F9FF"  # supplemental symbols and pictographs
        "\U0001FA70-\U0001FAFF"  # symbols and pictographs extended-A
        "\U00002600-\U000026FF"  # miscellaneous symbols
        "\U00002B00-\U00002BFF"  # miscellaneous symbols and arrows
        "\U0001F000-\U0001F02F"  # mahjong tiles
        "\U0001F0A0-\U0001F0FF"  # playing cards
        "\U0001F100-\U0001F64F"  # enclosed alphanumeric supplement
        "\U0001F650-\U0001F67F"  # geometric shapes extended
        "\U0001F680-\U0001F6FF"  # transport and map symbols
        "\U0001F700-\U0001F77F"  # alchemical symbols
        "\U0001F780-\U0001F7FF"  # geometric shapes extended
        "\U0001F800-\U0001F8FF"  # supplemental arrows-C
        "\U0001F900-\U0001F9FF"  # supplemental symbols and pictographs
        "\U0001FA00-\U0001FA6F"  # chess symbols
        "\U0001FA70-\U0001FAFF"  # symbols and pictographs extended-A
        "\U00002600-\U000027BF"  # miscellaneous symbols
        "\U00002B00-\U00002BFF"  # miscellaneous symbols and arrows
        "\U00002300-\U000023FF"  # technical symbols
        "\U00002500-\U0000257F"  # box drawing
        "\U00002580-\U0000259F"  # block elements
        "\U000025A0-\U000025FF"  # geometric shapes
        "\U00002600-\U0000267F"  # miscellaneous symbols
        "\U00002680-\U0000269F"  # dingbats
        "\U000026A0-\U000026FF"  # miscellaneous symbols
        "\U00002700-\U000027BF"  # dingbats
        "\U000027C0-\U000027EF"  # miscellaneous mathematical symbols-A
        "\U000027F0-\U000027FF"  # supplemental arrows-A
        "\U00002900-\U0000297F"  # supplemental arrows-B
        "\U00002980-\U000029FF"  # miscellaneous mathematical symbols-B
        "\U00002A00-\U00002AFF"  # supplemental mathematical operators
        "\U00002B00-\U00002BFF"  # miscellaneous symbols and arrows
        "\U00002C60-\U00002C7F"  # latin extended-C
        "\U00002E00-\U00002E7F"  # supplemental punctuation
        "\U00003000-\U0000303F"  # cjk symbols and punctuation
        "\U0000FF00-\U0000FFEF"  # halfwidth and fullwidth forms
        "\U0000FE00-\U0000FE0F"  # variation selectors
        "\U0000FE10-\U0000FE1F"  # vertical forms
        "\U0000FE20-\U0000FE2F"  # combining half marks
        "\U0000FE30-\U0000FE4F"  # cjk compatibility forms
        "\U0000FE50-\U0000FE6F"  # small form variants
        "\U0000FE70-\U0000FEFF"  # arabic presentation forms-B
        "\U0000FF00-\U0000FFEF"  # halfwidth and fullwidth forms
        "\U0000FFF0-\U0000FFFF"  # specials
        "]+", flags=re.UNICODE
    )
    return emoji_pattern.sub('', text).strip()

# Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ú©Ø§Ù…Ù„ ØªÙˆØ¶ÛŒØ­Ø§Øª metaedge Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡â€ŒØ§ÛŒ
METAEDGE_DESCRIPTIONS = {
    # Anatomy relationships
    "AdG": "Anatomyâ€“downregulatesâ€“Gene: ØªÙ†Ø¸ÛŒÙ… Ù…Ù†ÙÛŒ Ú˜Ù† Ø¯Ø± Ø¨Ø§ÙØª",
    "AeG": "Anatomyâ€“expressesâ€“Gene: Ø¨ÛŒØ§Ù† Ú˜Ù† Ø¯Ø± Ø¨Ø§ÙØª",
    "AlD": "Anatomyâ€“localizesâ€“Disease: Ù…Ø­Ù„ Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¯Ø± Ø¨Ø§ÙØª",
    "AuG": "Anatomyâ€“upregulatesâ€“Gene: ØªÙ†Ø¸ÛŒÙ… Ù…Ø«Ø¨Øª Ú˜Ù† Ø¯Ø± Ø¨Ø§ÙØª",
    
    # Biological Process relationships
    "BPpG": "Biological Processâ€“participatesâ€“Gene: Ù…Ø´Ø§Ø±Ú©Øª Ú˜Ù† Ø¯Ø± ÙØ±Ø¢ÛŒÙ†Ø¯ Ø²ÛŒØ³ØªÛŒ",
    "GpBP": "Geneâ€“participatesâ€“Biological Process: Ù…Ø´Ø§Ø±Ú©Øª Ú˜Ù† Ø¯Ø± ÙØ±Ø¢ÛŒÙ†Ø¯ Ø²ÛŒØ³ØªÛŒ",
    
    # Cellular Component relationships
    "CCpG": "Cellular Componentâ€“participatesâ€“Gene: Ù…Ø´Ø§Ø±Ú©Øª Ú˜Ù† Ø¯Ø± Ø§Ø¬Ø²Ø§ÛŒ Ø³Ù„ÙˆÙ„ÛŒ",
    "GpCC": "Geneâ€“participatesâ€“Cellular Component: Ù…Ø´Ø§Ø±Ú©Øª Ú˜Ù† Ø¯Ø± Ø§Ø¬Ø²Ø§ÛŒ Ø³Ù„ÙˆÙ„ÛŒ",
    
    # Compound relationships
    "CbG": "Compoundâ€“bindsâ€“Gene: Ø§ØªØµØ§Ù„ Ø¯Ø§Ø±Ùˆ Ø¨Ù‡ Ú˜Ù†",
    "CcSE": "Compoundâ€“causesâ€“Side Effect: Ø¹ÙˆØ§Ø±Ø¶ Ø¬Ø§Ù†Ø¨ÛŒ Ø¯Ø§Ø±Ùˆ",
    "CdG": "Compoundâ€“downregulatesâ€“Gene: ØªÙ†Ø¸ÛŒÙ… Ù…Ù†ÙÛŒ Ú˜Ù† ØªÙˆØ³Ø· Ø¯Ø§Ø±Ùˆ",
    "CiPC": "Compoundâ€“includesâ€“Pharmacologic Class: Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ø±ÙˆÛŒÛŒ",
    "CpD": "Compoundâ€“palliatesâ€“Disease: ØªØ³Ú©ÛŒÙ† Ø¨ÛŒÙ…Ø§Ø±ÛŒ ØªÙˆØ³Ø· Ø¯Ø§Ø±Ùˆ",
    "CrC": "Compoundâ€“resemblesâ€“Compound: Ø´Ø¨Ø§Ù‡Øª Ø¯Ø§Ø±ÙˆÛŒÛŒ",
    "CtD": "Compoundâ€“treatsâ€“Disease: Ø¯Ø±Ù…Ø§Ù† Ø¨ÛŒÙ…Ø§Ø±ÛŒ ØªÙˆØ³Ø· Ø¯Ø§Ø±Ùˆ",
    "CuG": "Compoundâ€“upregulatesâ€“Gene: ØªÙ†Ø¸ÛŒÙ… Ù…Ø«Ø¨Øª Ú˜Ù† ØªÙˆØ³Ø· Ø¯Ø§Ø±Ùˆ",
    
    # Disease relationships
    "DaG": "Diseaseâ€“associatesâ€“Gene: Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¨Ø§ Ú˜Ù†",
    "DdG": "Diseaseâ€“downregulatesâ€“Gene: ØªÙ†Ø¸ÛŒÙ… Ù…Ù†ÙÛŒ Ú˜Ù† Ø¯Ø± Ø¨ÛŒÙ…Ø§Ø±ÛŒ",
    "DlA": "Diseaseâ€“localizesâ€“Anatomy: Ù…Ø­Ù„ Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¯Ø± Ø¨Ø§ÙØª",
    "DpC": "Diseaseâ€“palliatesâ€“Compound: ØªØ³Ú©ÛŒÙ† Ø¨ÛŒÙ…Ø§Ø±ÛŒ",
    "DpS": "Diseaseâ€“presentsâ€“Symptom: Ø¹Ù„Ø§Ø¦Ù… Ø¨ÛŒÙ…Ø§Ø±ÛŒ",
    "DrD": "Diseaseâ€“resemblesâ€“Disease: Ø´Ø¨Ø§Ù‡Øª Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§",
    "DtC": "Diseaseâ€“treatsâ€“Compound: Ø¯Ø±Ù…Ø§Ù† Ø¨ÛŒÙ…Ø§Ø±ÛŒ",
    "DuG": "Diseaseâ€“upregulatesâ€“Gene: ØªÙ†Ø¸ÛŒÙ… Ù…Ø«Ø¨Øª Ú˜Ù† Ø¯Ø± Ø¨ÛŒÙ…Ø§Ø±ÛŒ",
    
    # Gene relationships
    "GaD": "Geneâ€“associatesâ€“Disease: Ø§Ø±ØªØ¨Ø§Ø· Ú˜Ù† Ø¨Ø§ Ø¨ÛŒÙ…Ø§Ø±ÛŒ",
    "GbC": "Geneâ€“bindsâ€“Compound: Ø§ØªØµØ§Ù„ Ú˜Ù† Ø¨Ù‡ Ø¯Ø§Ø±Ùˆ",
    "GcG": "Geneâ€“covariesâ€“Gene: Ù‡Ù…â€ŒØªØºÛŒÛŒØ±ÛŒ Ú˜Ù†â€ŒÙ‡Ø§",
    "GdA": "Geneâ€“downregulatesâ€“Anatomy: ØªÙ†Ø¸ÛŒÙ… Ù…Ù†ÙÛŒ Ø¨Ø§ÙØª ØªÙˆØ³Ø· Ú˜Ù†",
    "GdC": "Geneâ€“downregulatesâ€“Compound: ØªÙ†Ø¸ÛŒÙ… Ù…Ù†ÙÛŒ Ø¯Ø§Ø±Ùˆ ØªÙˆØ³Ø· Ú˜Ù†",
    "GdD": "Geneâ€“downregulatesâ€“Disease: ØªÙ†Ø¸ÛŒÙ… Ù…Ù†ÙÛŒ Ø¨ÛŒÙ…Ø§Ø±ÛŒ ØªÙˆØ³Ø· Ú˜Ù†",
    "GeA": "Geneâ€“expressesâ€“Anatomy: Ø¨ÛŒØ§Ù† Ú˜Ù† Ø¯Ø± Ø¨Ø§ÙØª",
    "GiG": "Geneâ€“interactsâ€“Gene: ØªØ¹Ø§Ù…Ù„ Ú˜Ù†â€ŒÙ‡Ø§",
    "GuA": "Geneâ€“upregulatesâ€“Anatomy: ØªÙ†Ø¸ÛŒÙ… Ù…Ø«Ø¨Øª Ø¨Ø§ÙØª ØªÙˆØ³Ø· Ú˜Ù†",
    "GuC": "Geneâ€“upregulatesâ€“Compound: ØªÙ†Ø¸ÛŒÙ… Ù…Ø«Ø¨Øª Ø¯Ø§Ø±Ùˆ ØªÙˆØ³Ø· Ú˜Ù†",
    "GuD": "Geneâ€“upregulatesâ€“Disease: ØªÙ†Ø¸ÛŒÙ… Ù…Ø«Ø¨Øª Ø¨ÛŒÙ…Ø§Ø±ÛŒ ØªÙˆØ³Ø· Ú˜Ù†",
    "Gr>G": "Geneâ†’regulatesâ†’Gene: ØªÙ†Ø¸ÛŒÙ… Ú˜Ù† ØªÙˆØ³Ø· Ú˜Ù†",
    "G<rG": "Geneâ†regulatesâ†Gene: ØªÙ†Ø¸ÛŒÙ… Ú˜Ù† ØªÙˆØ³Ø· Ú˜Ù†",
    
    # Molecular Function relationships
    "MFpG": "Molecular Functionâ€“participatesâ€“Gene: Ù…Ø´Ø§Ø±Ú©Øª Ú˜Ù† Ø¯Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…ÙˆÙ„Ú©ÙˆÙ„ÛŒ",
    "GpMF": "Geneâ€“participatesâ€“Molecular Function: Ù…Ø´Ø§Ø±Ú©Øª Ú˜Ù† Ø¯Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…ÙˆÙ„Ú©ÙˆÙ„ÛŒ",
    
    # Pathway relationships
    "PWpG": "Pathwayâ€“participatesâ€“Gene: Ù…Ø´Ø§Ø±Ú©Øª Ú˜Ù† Ø¯Ø± Ù…Ø³ÛŒØ± Ø²ÛŒØ³ØªÛŒ",
    "GpPW": "Geneâ€“participatesâ€“Pathway: Ù…Ø´Ø§Ø±Ú©Øª Ú˜Ù† Ø¯Ø± Ù…Ø³ÛŒØ± Ø²ÛŒØ³ØªÛŒ",
    
    # Pharmacologic Class relationships
    "PCiC": "Pharmacologic Classâ€“includesâ€“Compound: Ø´Ø§Ù…Ù„ Ø¯Ø§Ø±Ùˆ",
    
    # Side Effect relationships
    "SEcC": "Side Effectâ€“causesâ€“Compound: Ø¹ÙˆØ§Ø±Ø¶ Ø¬Ø§Ù†Ø¨ÛŒ",
    
    # Symptom relationships
    "SpD": "Symptomâ€“presentsâ€“Disease: Ø¹Ù„Ø§Ø¦Ù… Ø¨ÛŒÙ…Ø§Ø±ÛŒ"
}

# Ù†Ù‚Ø´â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
BIOLOGICAL_ROLES = {
    "TP53": "Ø³Ø±Ú©ÙˆØ¨â€ŒÚ¯Ø± ØªÙˆÙ…ÙˆØ± Ùˆ ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ú†Ø±Ø®Ù‡ Ø³Ù„ÙˆÙ„ÛŒ",
    "BRCA1": "ØªØ±Ù…ÛŒÙ… DNA Ùˆ Ø³Ø±Ú©ÙˆØ¨â€ŒÚ¯Ø± ØªÙˆÙ…ÙˆØ±",
    "BRCA2": "ØªØ±Ù…ÛŒÙ… DNA Ùˆ Ø³Ø±Ú©ÙˆØ¨â€ŒÚ¯Ø± ØªÙˆÙ…ÙˆØ±",
    "APC": "Ø³Ø±Ú©ÙˆØ¨â€ŒÚ¯Ø± ØªÙˆÙ…ÙˆØ± Ùˆ ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ú†Ø±Ø®Ù‡ Ø³Ù„ÙˆÙ„ÛŒ",
    "PTEN": "Ø³Ø±Ú©ÙˆØ¨â€ŒÚ¯Ø± ØªÙˆÙ…ÙˆØ± Ùˆ ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ù…Ø³ÛŒØ± PI3K",
    "RB1": "Ø³Ø±Ú©ÙˆØ¨â€ŒÚ¯Ø± ØªÙˆÙ…ÙˆØ± Ùˆ ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ú†Ø±Ø®Ù‡ Ø³Ù„ÙˆÙ„ÛŒ",
    "CDKN2A": "Ø³Ø±Ú©ÙˆØ¨â€ŒÚ¯Ø± ØªÙˆÙ…ÙˆØ± Ùˆ ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ú†Ø±Ø®Ù‡ Ø³Ù„ÙˆÙ„ÛŒ",
    "SMAD2": "ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ù…Ø³ÛŒØ± TGF-beta",
    "SMAD4": "ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ù…Ø³ÛŒØ± TGF-beta",
    "PIK3CA": "Ø§Ù†Ú©ÙˆÚ˜Ù† Ùˆ ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ù…Ø³ÛŒØ± PI3K",
    "KRAS": "Ø§Ù†Ú©ÙˆÚ˜Ù† Ùˆ ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ù…Ø³ÛŒØ± MAPK",
    "BRAF": "Ø§Ù†Ú©ÙˆÚ˜Ù† Ùˆ ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ù…Ø³ÛŒØ± MAPK",
    "EGFR": "Ú¯ÛŒØ±Ù†Ø¯Ù‡ ÙØ§Ú©ØªÙˆØ± Ø±Ø´Ø¯ Ø§Ù¾ÛŒØ¯Ø±Ù…ÛŒ",
    "HER2": "Ú¯ÛŒØ±Ù†Ø¯Ù‡ ÙØ§Ú©ØªÙˆØ± Ø±Ø´Ø¯ Ø§Ù¾ÛŒØ¯Ø±Ù…ÛŒ 2",
    "VEGF": "ÙØ§Ú©ØªÙˆØ± Ø±Ø´Ø¯ Ø§Ù†Ø¯ÙˆØªÙ„ÛŒØ§Ù„ Ø¹Ø±ÙˆÙ‚ÛŒ",
    "MYC": "Ø§Ù†Ú©ÙˆÚ˜Ù† Ùˆ ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒ",
    "BCL2": "ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø¢Ù¾ÙˆÙ¾ØªÙˆØ²",
    "BAX": "ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø¢Ù¾ÙˆÙ¾ØªÙˆØ²",
    "CASP3": "Ú©Ø§Ø³Ù¾Ø§Ø² 3 Ùˆ ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø¢Ù¾ÙˆÙ¾ØªÙˆØ²",
    "CASP9": "Ú©Ø§Ø³Ù¾Ø§Ø² 9 Ùˆ ØªÙ†Ø¸ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø¢Ù¾ÙˆÙ¾ØªÙˆØ²"
}

# Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
DISEASE_SIGNIFICANCE = {
    "malignant glioma": "Ú¯Ù„ÛŒÙˆÙ… Ø¨Ø¯Ø®ÛŒÙ… Ù…ØºØ²ÛŒ",
    "glioblastoma": "Ú¯Ù„ÛŒÙˆØ¨Ù„Ø§Ø³ØªÙˆÙ…Ø§",
    "breast cancer": "Ø³Ø±Ø·Ø§Ù† Ù¾Ø³ØªØ§Ù†",
    "lung cancer": "Ø³Ø±Ø·Ø§Ù† Ø±ÛŒÙ‡",
    "colorectal cancer": "Ø³Ø±Ø·Ø§Ù† Ø±ÙˆØ¯Ù‡ Ø¨Ø²Ø±Ú¯",
    "prostate cancer": "Ø³Ø±Ø·Ø§Ù† Ù¾Ø±ÙˆØ³ØªØ§Øª",
    "ovarian cancer": "Ø³Ø±Ø·Ø§Ù† ØªØ®Ù…Ø¯Ø§Ù†",
    "pancreatic cancer": "Ø³Ø±Ø·Ø§Ù† Ù„ÙˆØ²Ø§Ù„Ù…Ø¹Ø¯Ù‡",
    "melanoma": "Ù…Ù„Ø§Ù†ÙˆÙ…",
    "leukemia": "Ù„ÙˆØ³Ù…ÛŒ",
    "lymphoma": "Ù„Ù†ÙÙˆÙ…",
    "cancer": "Ø³Ø±Ø·Ø§Ù†"
}

class RetrievalMethod(Enum):
    """Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ"""
    # Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø§Ø³ÛŒÚ©
    BFS = "BFS"
    DFS = "DFS"
    SHORTEST_PATH = "Shortest Path"
    NEIGHBORS = "Neighbors"
    HYBRID = "Hybrid"
    MULTI_METHOD = "Multi-Method"
    ENSEMBLE = "Ensemble"
    ADAPTIVE = "Adaptive"
    INTELLIGENT = "Intelligent Semantic Search"
    NO_RETRIEVAL = "Ø¨Ø¯ÙˆÙ† Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ (ÙÙ‚Ø· Ù…Ø¯Ù„)"
    
    # Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ GraphRAG
    KG_SEARCH = "KGSearch (Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø§ØµÙ„ÛŒ Ø¬Ø¯ÛŒØ¯)"
    N_HOP_RETRIEVAL = "N-Hop Retrieval (Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ú†Ù†Ø¯Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ)"
    PAGERANK_BASED = "PageRank-Based (Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù‡Ù…ÛŒØª)"
    SEMANTIC_SIMILARITY = "Semantic Similarity (Ø´Ø¨Ø§Ù‡Øª Ù…Ø¹Ù†Ø§ÛŒÛŒ)"
    COMMUNITY_DETECTION = "Community Detection (ØªØ´Ø®ÛŒØµ Ø¬Ø§Ù…Ø¹Ù‡â€ŒÙ‡Ø§)"
    ENTITY_RESOLUTION = "Entity Resolution (Ø­Ù„ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§)"
    HYBRID_NEW = "Hybrid New (ØªØ±Ú©ÛŒØ¨ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯)"

class TokenExtractionMethod(Enum):
    """Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙˆÚ©Ù†"""
    CLASSIC = "Ú©Ù„Ø§Ø³ÛŒÚ© (Ø±ÙˆØ´ Ù‚Ø¨Ù„ÛŒ)"
    LLM_BASED = "LLM-Based (Ù‡ÙˆØ´Ù…Ù†Ø¯)"

class TokenExtractionModel(Enum):
    """Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙˆÚ©Ù†"""
    # OpenAI Models
    OPENAI_GPT_4O = "GPT-4o (Ø¨Ù‡ØªØ±ÛŒÙ† Ú©ÛŒÙÛŒØª)"
    OPENAI_GPT_4O_MINI = "GPT-4o Mini (Ø³Ø±ÛŒØ¹ Ùˆ Ø§Ù‚ØªØµØ§Ø¯ÛŒ)"
    OPENAI_GPT_3_5_TURBO = "GPT-3.5 Turbo (Ø³Ø±ÛŒØ¹)"
    
    # Anthropic Models
    ANTHROPIC_CLAUDE_3_5_SONNET = "Claude 3.5 Sonnet"
    ANTHROPIC_CLAUDE_3_5_HAIKU = "Claude 3.5 Haiku"
    
    # Google Models
    GOOGLE_GEMINI_1_5_PRO = "Gemini 1.5 Pro"
    GOOGLE_GEMINI_1_5_FLASH = "Gemini 1.5 Flash"

class ContextTextType(Enum):
    """Ø§Ù†ÙˆØ§Ø¹ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡"""
    SIMPLE = "Ù…ØªÙ† Ø³Ø§Ø¯Ù‡ Ø¹Ù…ÙˆÙ…ÛŒ"
    INTELLIGENT = "Ù…ØªÙ† ØªØ®ØµØµÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯"
    SCIENTIFIC_ANALYTICAL = "Ù…ØªÙ† Ø¹Ù„Ù…ÛŒ-ØªØ­Ù„ÛŒÙ„ÛŒ (ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ)"
    NARRATIVE = "Ù…ØªÙ† Ø±ÙˆØ§ÛŒÛŒ (Ø³Ø§Ø¯Ù‡ Ùˆ ØªÙˆØµÛŒÙÛŒ)"
    DATA_DRIVEN = "Ù…ØªÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ…Ø­ÙˆØ± (Ø±Ø§Ø¨Ø·Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù„ÛŒØ³Øª)"
    STEP_BY_STEP = "Ù…ØªÙ† ØªÙˆØ¶ÛŒØ­ Ù‚Ø¨Ù„ Ø§Ø² Ø³Ø¤Ø§Ù„ (Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ú¯Ø§Ù… Ø¨Ù‡ Ú¯Ø§Ù…)"
    COMPACT_DIRECT = "Ù…ØªÙ† ÙØ´Ø±Ø¯Ù‡ Ùˆ Ù…Ø³ØªÙ‚ÛŒÙ…"
    BIOLOGICAL_PATHWAY = "Ù…ØªÙ† Ù…Ø³ÛŒØ± Ø²ÛŒØ³ØªÛŒ (ØªØ®ØµØµÛŒ)"
    CLINICAL_RELEVANCE = "Ù…ØªÙ† Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§Ù„ÛŒÙ†ÛŒ"
    MECHANISTIC_DETAILED = "Ù…ØªÙ† Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ ØªÙØµÛŒÙ„ÛŒ"

class GenerationModel(Enum):
    """Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ†"""
    # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ Ùˆ Ø±Ø§ÛŒÚ¯Ø§Ù†
    GENERAL_SIMPLE = "General Simple (Ù¾Ø§Ø³Ø® Ø³Ø§Ø¯Ù‡ Ùˆ Ø¹Ù…ÙˆÙ…ÛŒ)"
    SIMPLE = "Simple Template"
    GPT_SIMULATION = "GPT Simulation"
    CUSTOM = "Custom Model"
    HUGGINGFACE = "HuggingFace Models"
    
    # OpenAI GPT Models
    OPENAI_GPT_4O = "OpenAI GPT-4o (Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ùˆ Ù‚ÙˆÛŒâ€ŒØªØ±ÛŒÙ†)"
    OPENAI_GPT_4O_MINI = "OpenAI GPT-4o Mini (Ø³Ø±ÛŒØ¹ Ùˆ Ø§Ù‚ØªØµØ§Ø¯ÛŒ)"
    OPENAI_GPT_4_TURBO = "OpenAI GPT-4 Turbo (ØªØ¹Ø§Ø¯Ù„ Ø³Ø±Ø¹Øª Ùˆ Ú©ÛŒÙÛŒØª)"
    OPENAI_GPT_4 = "OpenAI GPT-4 (Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§)"
    OPENAI_GPT_3_5_TURBO = "OpenAI GPT-3.5 Turbo (Ø³Ø±ÛŒØ¹ Ùˆ Ø§Ù‚ØªØµØ§Ø¯ÛŒ)"
    OPENAI_GPT_3_5_TURBO_16K = "OpenAI GPT-3.5 Turbo 16K (Ù…ØªÙ† Ø·ÙˆÙ„Ø§Ù†ÛŒ)"
    
    # Anthropic Claude Models
    ANTHROPIC_CLAUDE_3_5_SONNET = "Anthropic Claude 3.5 Sonnet (Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ†)"
    ANTHROPIC_CLAUDE_3_5_HAIKU = "Anthropic Claude 3.5 Haiku (Ø³Ø±ÛŒØ¹)"
    ANTHROPIC_CLAUDE_3_OPUS = "Anthropic Claude 3 Opus (Ù‚ÙˆÛŒâ€ŒØªØ±ÛŒÙ†)"
    ANTHROPIC_CLAUDE_3_SONNET = "Anthropic Claude 3 Sonnet (ØªØ¹Ø§Ø¯Ù„)"
    ANTHROPIC_CLAUDE_3_HAIKU = "Anthropic Claude 3 Haiku (Ø³Ø±ÛŒØ¹)"
    
    # Google Gemini Models
    GOOGLE_GEMINI_1_5_PRO = "Google Gemini 1.5 Pro (Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ†)"
    GOOGLE_GEMINI_1_5_FLASH = "Google Gemini 1.5 Flash (Ø³Ø±ÛŒØ¹)"
    GOOGLE_GEMINI_1_0_PRO = "Google Gemini 1.0 Pro (Ù¾Ø§ÛŒØ¯Ø§Ø±)"
    GOOGLE_GEMINI_1_0_FLASH = "Google Gemini 1.0 Flash (Ø³Ø±ÛŒØ¹)"
    
    # Ø³Ø§ÛŒØ± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
    META_LLAMA_3_1 = "Meta Llama 3.1 (Ù…Ø­Ù„ÛŒ)"
    MISTRAL_AI = "Mistral AI (Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§)"
    COHERE_COMMAND = "Cohere Command (ØªØ®ØµØµÛŒ)"
    PERPLEXITY_SONAR = "Perplexity Sonar (Ø¬Ø³ØªØ¬ÙˆÚ¯Ø±)"
    
    # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ
    OPENAI_GPT = "OpenAI GPT"
    ANTHROPIC_CLAUDE = "Anthropic Claude"
    GOOGLE_GEMINI = "Google Gemini"

@dataclass
class GraphNode:
    """Ù†Ù…Ø§ÛŒØ´ ÛŒÚ© Ù†ÙˆØ¯ Ú¯Ø±Ø§Ù"""
    id: str
    name: str
    kind: str
    depth: int = 0
    score: float = 1.0

@dataclass
class GraphEdge:
    """Ù†Ù…Ø§ÛŒØ´ ÛŒÚ© ÛŒØ§Ù„ Ú¯Ø±Ø§Ù"""
    source: str
    target: str
    relation: str
    weight: float = 1.0

@dataclass
class RetrievalResult:
    """Ù†ØªÛŒØ¬Ù‡ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ"""
    nodes: List[GraphNode]
    edges: List[GraphEdge]
    paths: List[List[str]]
    context_text: str
    method: str
    query: str

@dataclass
class GenerationResult:
    """Ù†ØªÛŒØ¬Ù‡ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ†"""
    answer: str
    model: str
    context_used: str
    confidence: float

class GraphRAGService:
    """Ø³Ø±ÙˆÛŒØ³ Ø§ØµÙ„ÛŒ GraphRAG"""
    
    def __init__(self, graph_data_path: str = None):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆÛŒØ³ GraphRAG"""
        self.graph_data_path = graph_data_path or "hetionet_graph.pkl"
        self.G = None
        self.nlp = None
        # Ø§ÛŒÙ†Ø¯Ú©Ø³â€ŒÙ‡Ø§ Ùˆ Ú©Ø´â€ŒÙ‡Ø§
        self._name_to_ids = {}
        self._id_to_name = {}
        self._kind_to_ids = {}
        self._name_entries = []  # [(lower_name, node_id)] Ø¨Ø±Ø§ÛŒ fallback ÙØ§Ø²ÛŒ Ø³Ø¨Ú©
        self._pagerank = {}
        self._keyword_cache = {}
        self._last_intent = None
        # Ú˜Ù†Ø±Ø§ØªÙˆØ± Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡
        try:
            self.context_generator = EnhancedContextGenerator()
        except Exception:
            self.context_generator = None
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù‚Ø§Ø¨Ù„ ØªØºÛŒÛŒØ± Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
        self.config = {
            'max_nodes': 10,           # Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯Ù‡
            'max_edges': 20,           # Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯Ù‡
            'max_depth': 3,            # Ø­Ø¯Ø§Ú©Ø«Ø± Ø¹Ù…Ù‚ Ø¬Ø³ØªØ¬Ùˆ
            'max_paths': 5,            # Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ù…Ø³ÛŒØ±Ù‡Ø§
            'max_context_length': 2000, # Ø­Ø¯Ø§Ú©Ø«Ø± Ø·ÙˆÙ„ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ (Ú©Ø§Ø±Ø§Ú©ØªØ±)
            'max_answer_tokens': 1000,  # Ø­Ø¯Ø§Ú©Ø«Ø± ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø³Ø®
            'max_prompt_tokens': 4000,  # Ø­Ø¯Ø§Ú©Ø«Ø± ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ
            'enable_verbose_logging': True,  # Ù†Ù…Ø§ÛŒØ´ Ø¬Ø²Ø¦ÛŒØ§Øª
            'enable_biological_enrichment': True,  # ØºÙ†ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø²ÛŒØ³ØªÛŒ
            'enable_smart_filtering': True,  # ÙÛŒÙ„ØªØ± Ù‡ÙˆØ´Ù…Ù†Ø¯
        }
        
        # API Keys
        self.openai_api_key = None
        # self.anthropic_api_key = None
        # self.gemini_api_key = None
        
        self.initialize()
    
    def set_config(self, **kwargs):
        """ØªØºÛŒÛŒØ± ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…"""
        for key, value in kwargs.items():
            if key in self.config:
                self.config[key] = value
                print(f" ØªÙ†Ø¸ÛŒÙ… {key} = {value}")
            else:
                print(f" ØªÙ†Ø¸ÛŒÙ… Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {key}")
    
    def get_config(self):
        """Ø¯Ø±ÛŒØ§ÙØª ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙØ¹Ù„ÛŒ"""
        return self.config.copy()
    
    def initialize(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆÛŒØ³"""
        print(" Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ GraphRAG Service...")
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ spaCy
        try:
            self.nlp = spacy.load("en_core_web_sm")
            print(" Ù…Ø¯Ù„ spaCy Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
        except:
            print(" Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ spaCy - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ Ø³Ø§Ø¯Ù‡")
            self.nlp = None
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø±Ø§Ù
        if self.graph_data_path and os.path.exists(self.graph_data_path):
            self.load_graph_from_file()
        else:
            self.create_sample_graph()

    def _post_graph_loaded(self):
        """Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ù¾Ø³ Ø§Ø² Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ/Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø±Ø§Ù: Ø³Ø§Ø®Øª Ø§ÛŒÙ†Ø¯Ú©Ø³â€ŒÙ‡Ø§ Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ PageRank ØªÙ†Ø¨Ù„"""
        self._build_node_indices()
        # PageRank Ø±Ø§ Ø¨Ù‡â€ŒØµÙˆØ±Øª ØªÙ†Ø¨Ù„ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…Ø› Ø§ÛŒÙ†Ø¬Ø§ Ø§Ú¯Ø± Ú¯Ø±Ø§Ù Ú©ÙˆÚ†Ú© Ø¨Ø§Ø´Ø¯ Ø­Ø³Ø§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        try:
            if self.G and self.G.number_of_nodes() <= 5000:
                import networkx as nx
                self._pagerank = nx.pagerank(self.G, alpha=0.85)
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§ÙˆÙ„ÛŒÙ‡ PageRank: {e}")

    def _build_node_indices(self):
        """Ø³Ø§Ø®Øª Ø§ÛŒÙ†Ø¯Ú©Ø³â€ŒÙ‡Ø§ÛŒ Ú©Ù…â€ŒØ­Ø¬Ù… Ø¨Ø±Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ø³Ø±ÛŒØ¹ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¨Ø§ Ù†ÙˆØ¯Ù‡Ø§"""
        self._name_to_ids.clear()
        self._id_to_name.clear()
        self._kind_to_ids.clear()
        self._name_entries.clear()
        if not self.G:
            return
        for node_id, attrs in self.G.nodes(data=True):
            name = str(attrs.get('name', node_id))
            kind = str(attrs.get('kind', 'Unknown'))
            self._id_to_name[node_id] = name
            lower_name = name.lower()
            self._name_to_ids.setdefault(lower_name, []).append(node_id)
            self._kind_to_ids.setdefault(kind, []).append(node_id)
            # ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø´Ø§Ù…Ù„ Ø³Ø§Ø¯Ù‡
            self._name_entries.append((lower_name, node_id))

    def _display_node(self, node_id: str) -> str:
        """Ù†Ù…Ø§ÛŒØ´ Ø§Ù†Ø³Ø§Ù†ÛŒ ÛŒÚ© Ù†ÙˆØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø§Ù… Ùˆ Ù†ÙˆØ¹ (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯)"""
        try:
            name = self._id_to_name.get(node_id) or self.G.nodes[node_id].get('name', node_id)
            kind = self.G.nodes[node_id].get('kind')
            return f"{name} ({kind})" if kind else str(name)
        except Exception:
            return str(node_id)

    def _ensure_pagerank(self):
        if not self._pagerank and self.G:
            try:
                import networkx as nx
                self._pagerank = nx.pagerank(self.G, alpha=0.85)
            except Exception:
                self._pagerank = {}
    
    def create_sample_graph(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø±Ø§Ù Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§Ø®ØªØ§Ø± ÙˆØ§Ù‚Ø¹ÛŒ Hetionet"""
        print(" Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø±Ø§Ù Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Hetionet...")
        
        self.G = nx.DiGraph()
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†ÙˆØ¯Ù‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ metanodes ÙˆØ§Ù‚Ø¹ÛŒ Hetionet
        nodes_data = [
            # Gene nodes (20945 total in Hetionet)
            ('Gene::TP53', {'name': 'TP53', 'kind': 'Gene', 'metanode': 'Gene'}),
            ('Gene::BRCA1', {'name': 'BRCA1', 'kind': 'Gene', 'metanode': 'Gene'}),
            ('Gene::MMP9', {'name': 'MMP9', 'kind': 'Gene', 'metanode': 'Gene'}),
            ('Gene::BID', {'name': 'BID', 'kind': 'Gene', 'metanode': 'Gene'}),
            ('Gene::HMGB3', {'name': 'HMGB3', 'kind': 'Gene', 'metanode': 'Gene'}),
            ('Gene::KCNQ2', {'name': 'KCNQ2', 'kind': 'Gene', 'metanode': 'Gene'}),
            ('Gene::APOE', {'name': 'APOE', 'kind': 'Gene', 'metanode': 'Gene'}),
            ('Gene::CFTR', {'name': 'CFTR', 'kind': 'Gene', 'metanode': 'Gene'}),
            
            # Anatomy nodes (402 total in Hetionet)
            ('Anatomy::Heart', {'name': 'Heart', 'kind': 'Anatomy', 'metanode': 'Anatomy'}),
            ('Anatomy::Brain', {'name': 'Brain', 'kind': 'Anatomy', 'metanode': 'Anatomy'}),
            ('Anatomy::Liver', {'name': 'Liver', 'kind': 'Anatomy', 'metanode': 'Anatomy'}),
            ('Anatomy::Lung', {'name': 'Lung', 'kind': 'Anatomy', 'metanode': 'Anatomy'}),
            ('Anatomy::Kidney', {'name': 'Kidney', 'kind': 'Anatomy', 'metanode': 'Anatomy'}),
            ('Anatomy::Stomach', {'name': 'Stomach', 'kind': 'Anatomy', 'metanode': 'Anatomy'}),
            
            # Disease nodes (137 total in Hetionet)
            ('Disease::Breast Cancer', {'name': 'Breast Cancer', 'kind': 'Disease', 'metanode': 'Disease'}),
            ('Disease::Lung Cancer', {'name': 'Lung Cancer', 'kind': 'Disease', 'metanode': 'Disease'}),
            ('Disease::Heart Disease', {'name': 'Heart Disease', 'kind': 'Disease', 'metanode': 'Disease'}),
            ('Disease::Alzheimer Disease', {'name': 'Alzheimer Disease', 'kind': 'Disease', 'metanode': 'Disease'}),
            ('Disease::Cystic Fibrosis', {'name': 'Cystic Fibrosis', 'kind': 'Disease', 'metanode': 'Disease'}),
            
            # Compound nodes (1552 total in Hetionet)
            ('Compound::Aspirin', {'name': 'Aspirin', 'kind': 'Compound', 'metanode': 'Compound'}),
            ('Compound::Ibuprofen', {'name': 'Ibuprofen', 'kind': 'Compound', 'metanode': 'Compound'}),
            ('Compound::Paracetamol', {'name': 'Paracetamol', 'kind': 'Compound', 'metanode': 'Compound'}),
            ('Compound::Caffeine', {'name': 'Caffeine', 'kind': 'Compound', 'metanode': 'Compound'}),
            ('Compound::Vitamin C', {'name': 'Vitamin C', 'kind': 'Compound', 'metanode': 'Compound'}),
            ('Compound::Metformin', {'name': 'Metformin', 'kind': 'Compound', 'metanode': 'Compound'}),
            
            # Biological Process nodes (11381 total in Hetionet)
            ('BiologicalProcess::Cell Death', {'name': 'Cell Death', 'kind': 'Biological Process', 'metanode': 'Biological Process'}),
            ('BiologicalProcess::DNA Repair', {'name': 'DNA Repair', 'kind': 'Biological Process', 'metanode': 'Biological Process'}),
            ('BiologicalProcess::Cell Cycle', {'name': 'Cell Cycle', 'kind': 'Biological Process', 'metanode': 'Biological Process'}),
            ('BiologicalProcess::Apoptosis', {'name': 'Apoptosis', 'kind': 'Biological Process', 'metanode': 'Biological Process'}),
            
            # Pathway nodes (1822 total in Hetionet)
            ('Pathway::Apoptosis', {'name': 'Apoptosis', 'kind': 'Pathway', 'metanode': 'Pathway'}),
            ('Pathway::Cell Cycle', {'name': 'Cell Cycle', 'kind': 'Pathway', 'metanode': 'Pathway'}),
            ('Pathway::DNA Repair', {'name': 'DNA Repair', 'kind': 'Pathway', 'metanode': 'Pathway'}),
            
            # Symptom nodes (438 total in Hetionet)
            ('Symptom::Pain', {'name': 'Pain', 'kind': 'Symptom', 'metanode': 'Symptom'}),
            ('Symptom::Fever', {'name': 'Fever', 'kind': 'Symptom', 'metanode': 'Symptom'}),
            ('Symptom::Cough', {'name': 'Cough', 'kind': 'Symptom', 'metanode': 'Symptom'}),
            ('Symptom::Fatigue', {'name': 'Fatigue', 'kind': 'Symptom', 'metanode': 'Symptom'}),
            
            # Side Effect nodes (5734 total in Hetionet)
            ('SideEffect::Nausea', {'name': 'Nausea', 'kind': 'Side Effect', 'metanode': 'Side Effect'}),
            ('SideEffect::Headache', {'name': 'Headache', 'kind': 'Side Effect', 'metanode': 'Side Effect'}),
            ('SideEffect::Dizziness', {'name': 'Dizziness', 'kind': 'Side Effect', 'metanode': 'Side Effect'}),
            
            # Molecular Function nodes (2884 total in Hetionet)
            ('MolecularFunction::Enzyme', {'name': 'Enzyme', 'kind': 'Molecular Function', 'metanode': 'Molecular Function'}),
            ('MolecularFunction::Receptor', {'name': 'Receptor', 'kind': 'Molecular Function', 'metanode': 'Molecular Function'}),
            ('MolecularFunction::Transporter', {'name': 'Transporter', 'kind': 'Molecular Function', 'metanode': 'Molecular Function'}),
            
            # Cellular Component nodes (1391 total in Hetionet)
            ('CellularComponent::Nucleus', {'name': 'Nucleus', 'kind': 'Cellular Component', 'metanode': 'Cellular Component'}),
            ('CellularComponent::Mitochondria', {'name': 'Mitochondria', 'kind': 'Cellular Component', 'metanode': 'Cellular Component'}),
            ('CellularComponent::Cell Membrane', {'name': 'Cell Membrane', 'kind': 'Cellular Component', 'metanode': 'Cellular Component'}),
            
            # Pharmacologic Class nodes (345 total in Hetionet)
            ('PharmacologicClass::NSAID', {'name': 'NSAID', 'kind': 'Pharmacologic Class', 'metanode': 'Pharmacologic Class'}),
            ('PharmacologicClass::Antibiotic', {'name': 'Antibiotic', 'kind': 'Pharmacologic Class', 'metanode': 'Pharmacologic Class'}),
            ('PharmacologicClass::Antihypertensive', {'name': 'Antihypertensive', 'kind': 'Pharmacologic Class', 'metanode': 'Pharmacologic Class'})
        ]
        
        for node_id, attrs in nodes_data:
            self.G.add_node(node_id, **attrs)
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÛŒØ§Ù„â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ metaedges ÙˆØ§Ù‚Ø¹ÛŒ Hetionet
        edges_data = [
            # Anatomy - expresses - Gene (AeG) - 526407 edges in Hetionet
            ('Anatomy::Heart', 'Gene::MMP9', 'AeG'),
            ('Anatomy::Heart', 'Gene::BID', 'AeG'),
            ('Anatomy::Heart', 'Gene::KCNQ2', 'AeG'),
            ('Anatomy::Brain', 'Gene::APOE', 'AeG'),
            ('Anatomy::Brain', 'Gene::TP53', 'AeG'),
            ('Anatomy::Liver', 'Gene::BRCA1', 'AeG'),
            ('Anatomy::Lung', 'Gene::CFTR', 'AeG'),
            
            # Anatomy - upregulates - Gene (AuG) - 97848 edges in Hetionet
            ('Anatomy::Heart', 'Gene::HMGB3', 'AuG'),
            ('Anatomy::Brain', 'Gene::BRCA1', 'AuG'),
            
            # Anatomy - downregulates - Gene (AdG) - 102240 edges in Hetionet
            ('Anatomy::Liver', 'Gene::MMP9', 'AdG'),
            
            # Disease - associates - Gene (DaG) - 12623 edges in Hetionet
            ('Disease::Breast Cancer', 'Gene::BRCA1', 'DaG'),
            ('Disease::Breast Cancer', 'Gene::TP53', 'DaG'),
            ('Disease::Lung Cancer', 'Gene::MMP9', 'DaG'),
            ('Disease::Alzheimer Disease', 'Gene::APOE', 'DaG'),
            ('Disease::Cystic Fibrosis', 'Gene::CFTR', 'DaG'),
            
            # Disease - upregulates - Gene (DuG) - 7731 edges in Hetionet
            ('Disease::Breast Cancer', 'Gene::BID', 'DuG'),
            ('Disease::Lung Cancer', 'Gene::TP53', 'DuG'),
            
            # Disease - downregulates - Gene (DdG) - 7623 edges in Hetionet
            ('Disease::Heart Disease', 'Gene::KCNQ2', 'DdG'),
            
            # Disease - localizes - Anatomy (DlA) - 3602 edges in Hetionet
            ('Disease::Breast Cancer', 'Anatomy::Stomach', 'DlA'),
            ('Disease::Lung Cancer', 'Anatomy::Lung', 'DlA'),
            ('Disease::Heart Disease', 'Anatomy::Heart', 'DlA'),
            
            # Disease - presents - Symptom (DpS) - 3357 edges in Hetionet
            ('Disease::Breast Cancer', 'Symptom::Pain', 'DpS'),
            ('Disease::Lung Cancer', 'Symptom::Cough', 'DpS'),
            ('Disease::Heart Disease', 'Symptom::Fatigue', 'DpS'),
            
            # Compound - binds - Gene (CbG) - 11571 edges in Hetionet
            ('Compound::Caffeine', 'Gene::TP53', 'CbG'),
            ('Compound::Vitamin C', 'Gene::BRCA1', 'CbG'),
            ('Compound::Metformin', 'Gene::APOE', 'CbG'),
            
            # Compound - treats - Disease (CtD) - 755 edges in Hetionet
            ('Compound::Aspirin', 'Disease::Heart Disease', 'CtD'),
            ('Compound::Metformin', 'Disease::Breast Cancer', 'CtD'),
            
            # Compound - palliates - Disease (CpD) - 390 edges in Hetionet
            ('Compound::Ibuprofen', 'Disease::Breast Cancer', 'CpD'),
            ('Compound::Paracetamol', 'Disease::Lung Cancer', 'CpD'),
            
            # Compound - causes - Side Effect (CcSE) - 138944 edges in Hetionet
            ('Compound::Aspirin', 'SideEffect::Nausea', 'CcSE'),
            ('Compound::Ibuprofen', 'SideEffect::Headache', 'CcSE'),
            ('Compound::Caffeine', 'SideEffect::Dizziness', 'CcSE'),
            
            # Compound - upregulates - Gene (CuG) - 18756 edges in Hetionet
            ('Compound::Vitamin C', 'Gene::TP53', 'CuG'),
            ('Compound::Metformin', 'Gene::BRCA1', 'CuG'),
            
            # Compound - downregulates - Gene (CdG) - 21102 edges in Hetionet
            ('Compound::Caffeine', 'Gene::MMP9', 'CdG'),
            
            # Gene - participates - Biological Process (GpBP) - 559504 edges in Hetionet
            ('Gene::BID', 'BiologicalProcess::Cell Death', 'GpBP'),
            ('Gene::TP53', 'BiologicalProcess::DNA Repair', 'GpBP'),
            ('Gene::BRCA1', 'BiologicalProcess::Apoptosis', 'GpBP'),
            ('Gene::MMP9', 'BiologicalProcess::Cell Cycle', 'GpBP'),
            
            # Gene - participates - Pathway (GpPW) - 84372 edges in Hetionet
            ('Gene::BRCA1', 'Pathway::Apoptosis', 'GpPW'),
            ('Gene::TP53', 'Pathway::Cell Cycle', 'GpPW'),
            ('Gene::BID', 'Pathway::DNA Repair', 'GpPW'),
            
            # Gene - participates - Molecular Function (GpMF) - 97222 edges in Hetionet
            ('Gene::TP53', 'MolecularFunction::Enzyme', 'GpMF'),
            ('Gene::BRCA1', 'MolecularFunction::Receptor', 'GpMF'),
            ('Gene::CFTR', 'MolecularFunction::Transporter', 'GpMF'),
            
            # Gene - participates - Cellular Component (GpCC) - 73566 edges in Hetionet
            ('Gene::BRCA1', 'CellularComponent::Nucleus', 'GpCC'),
            ('Gene::TP53', 'CellularComponent::Mitochondria', 'GpCC'),
            ('Gene::CFTR', 'CellularComponent::Cell Membrane', 'GpCC'),
            
            # Gene - interacts - Gene (GiG) - 147164 edges in Hetionet
            ('Gene::TP53', 'Gene::BRCA1', 'GiG'),
            ('Gene::MMP9', 'Gene::BID', 'GiG'),
            ('Gene::APOE', 'Gene::CFTR', 'GiG'),
            
            # Gene > regulates > Gene (Gr>G) - 265672 edges in Hetionet
            ('Gene::TP53', 'Gene::MMP9', 'Gr>G'),
            ('Gene::BRCA1', 'Gene::BID', 'Gr>G'),
            ('Gene::APOE', 'Gene::KCNQ2', 'Gr>G'),
            
            # Gene - covaries - Gene (GcG) - 61690 edges in Hetionet
            ('Gene::TP53', 'Gene::BRCA1', 'GcG'),
            ('Gene::MMP9', 'Gene::BID', 'GcG'),
            
            # Pharmacologic Class - includes - Compound (PCiC) - 1029 edges in Hetionet
            ('PharmacologicClass::NSAID', 'Compound::Aspirin', 'PCiC'),
            ('PharmacologicClass::NSAID', 'Compound::Ibuprofen', 'PCiC'),
            ('PharmacologicClass::Antibiotic', 'Compound::Metformin', 'PCiC'),
            
            # Compound - resembles - Compound (CrC) - 6486 edges in Hetionet
            ('Compound::Aspirin', 'Compound::Ibuprofen', 'CrC'),
            ('Compound::Caffeine', 'Compound::Vitamin C', 'CrC'),
            
            # Disease - resembles - Disease (DrD) - 543 edges in Hetionet
            ('Disease::Breast Cancer', 'Disease::Lung Cancer', 'DrD'),
            ('Disease::Alzheimer Disease', 'Disease::Cystic Fibrosis', 'DrD')
        ]
        
        for source, target, metaedge in edges_data:
            self.G.add_edge(source, target, metaedge=metaedge, relation=metaedge)
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ú©ÙˆØ³ Ø¨Ø±Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ø³ÙˆØ§Ù„Ø§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡
        reverse_edges_data = [
            # Gene - expressed_in - Anatomy (GeA) - Ù…Ø¹Ú©ÙˆØ³ AeG
            ('Gene::MMP9', 'Anatomy::Heart', 'GeA'),
            ('Gene::BID', 'Anatomy::Heart', 'GeA'),
            ('Gene::KCNQ2', 'Anatomy::Heart', 'GeA'),
            ('Gene::APOE', 'Anatomy::Brain', 'GeA'),
            ('Gene::TP53', 'Anatomy::Brain', 'GeA'),
            ('Gene::BRCA1', 'Anatomy::Liver', 'GeA'),
            ('Gene::CFTR', 'Anatomy::Lung', 'GeA'),
            
            # Gene - upregulates - Anatomy (GuA) - Ù…Ø¹Ú©ÙˆØ³ AuG
            ('Gene::HMGB3', 'Anatomy::Heart', 'GuA'),
            ('Gene::BRCA1', 'Anatomy::Brain', 'GuA'),
            
            # Gene - downregulates - Anatomy (GdA) - Ù…Ø¹Ú©ÙˆØ³ AdG
            ('Gene::MMP9', 'Anatomy::Liver', 'GdA'),
            
            # Gene - associates - Disease (GaD) - Ù…Ø¹Ú©ÙˆØ³ DaG
            ('Gene::BRCA1', 'Disease::Breast Cancer', 'GaD'),
            ('Gene::TP53', 'Disease::Breast Cancer', 'GaD'),
            ('Gene::MMP9', 'Disease::Lung Cancer', 'GaD'),
            ('Gene::APOE', 'Disease::Alzheimer Disease', 'GaD'),
            ('Gene::CFTR', 'Disease::Cystic Fibrosis', 'GaD'),
            
            # Gene - upregulates - Disease (GuD) - Ù…Ø¹Ú©ÙˆØ³ DuG
            ('Gene::BID', 'Disease::Breast Cancer', 'GuD'),
            ('Gene::TP53', 'Disease::Lung Cancer', 'GuD'),
            
            # Gene - downregulates - Disease (GdD) - Ù…Ø¹Ú©ÙˆØ³ DdG
            ('Gene::KCNQ2', 'Disease::Heart Disease', 'GdD'),
            
            # Anatomy - localizes - Disease (AlD) - Ù…Ø¹Ú©ÙˆØ³ DlA
            ('Anatomy::Stomach', 'Disease::Breast Cancer', 'AlD'),
            ('Anatomy::Lung', 'Disease::Lung Cancer', 'AlD'),
            ('Anatomy::Heart', 'Disease::Heart Disease', 'AlD'),
            
            # Symptom - presents - Disease (SpD) - Ù…Ø¹Ú©ÙˆØ³ DpS
            ('Symptom::Pain', 'Disease::Breast Cancer', 'SpD'),
            ('Symptom::Cough', 'Disease::Lung Cancer', 'SpD'),
            ('Symptom::Fatigue', 'Disease::Heart Disease', 'SpD'),
            
            # Gene - binds - Compound (GbC) - Ù…Ø¹Ú©ÙˆØ³ CbG
            ('Gene::TP53', 'Compound::Caffeine', 'GbC'),
            ('Gene::BRCA1', 'Compound::Vitamin C', 'GbC'),
            ('Gene::APOE', 'Compound::Metformin', 'GbC'),
            
            # Disease - treated_by - Compound (DtC) - Ù…Ø¹Ú©ÙˆØ³ CtD
            ('Disease::Heart Disease', 'Compound::Aspirin', 'DtC'),
            ('Disease::Breast Cancer', 'Compound::Metformin', 'DtC'),
            
            # Disease - palliated_by - Compound (DpC) - Ù…Ø¹Ú©ÙˆØ³ CpD
            ('Disease::Breast Cancer', 'Compound::Ibuprofen', 'DpC'),
            ('Disease::Lung Cancer', 'Compound::Paracetamol', 'DpC'),
            
            # Side Effect - caused_by - Compound (SEcC) - Ù…Ø¹Ú©ÙˆØ³ CcSE
            ('SideEffect::Nausea', 'Compound::Aspirin', 'SEcC'),
            ('SideEffect::Headache', 'Compound::Ibuprofen', 'SEcC'),
            ('SideEffect::Dizziness', 'Compound::Caffeine', 'SEcC'),
            
            # Gene - upregulates - Compound (GuC) - Ù…Ø¹Ú©ÙˆØ³ CuG
            ('Gene::TP53', 'Compound::Vitamin C', 'GuC'),
            ('Gene::BRCA1', 'Compound::Metformin', 'GuC'),
            
            # Gene - downregulates - Compound (GdC) - Ù…Ø¹Ú©ÙˆØ³ CdG
            ('Gene::MMP9', 'Compound::Caffeine', 'GdC'),
            
            # Biological Process - participates - Gene (BPpG) - Ù…Ø¹Ú©ÙˆØ³ GpBP
            ('BiologicalProcess::Cell Death', 'Gene::BID', 'BPpG'),
            ('BiologicalProcess::DNA Repair', 'Gene::TP53', 'BPpG'),
            ('BiologicalProcess::Apoptosis', 'Gene::BRCA1', 'BPpG'),
            ('BiologicalProcess::Cell Cycle', 'Gene::MMP9', 'BPpG'),
            
            # Pathway - participates - Gene (PWpG) - Ù…Ø¹Ú©ÙˆØ³ GpPW
            ('Pathway::Apoptosis', 'Gene::BRCA1', 'PWpG'),
            ('Pathway::Cell Cycle', 'Gene::TP53', 'PWpG'),
            ('Pathway::DNA Repair', 'Gene::BID', 'PWpG'),
            
            # Molecular Function - participates - Gene (MFpG) - Ù…Ø¹Ú©ÙˆØ³ GpMF
            ('MolecularFunction::Enzyme', 'Gene::TP53', 'MFpG'),
            ('MolecularFunction::Receptor', 'Gene::BRCA1', 'MFpG'),
            ('MolecularFunction::Transporter', 'Gene::CFTR', 'MFpG'),
            
            # Cellular Component - participates - Gene (CCpG) - Ù…Ø¹Ú©ÙˆØ³ GpCC
            ('CellularComponent::Nucleus', 'Gene::BRCA1', 'CCpG'),
            ('CellularComponent::Mitochondria', 'Gene::TP53', 'CCpG'),
            ('CellularComponent::Cell Membrane', 'Gene::CFTR', 'CCpG'),
            
            # Compound - includes - Pharmacologic Class (CiPC) - Ù…Ø¹Ú©ÙˆØ³ PCiC
            ('Compound::Aspirin', 'PharmacologicClass::NSAID', 'CiPC'),
            ('Compound::Ibuprofen', 'PharmacologicClass::NSAID', 'CiPC'),
            ('Compound::Metformin', 'PharmacologicClass::Antibiotic', 'CiPC')
        ]
        
        for source, target, metaedge in reverse_edges_data:
            self.G.add_edge(source, target, metaedge=metaedge, relation=metaedge)
        
        print(f" Ú¯Ø±Ø§Ù Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Hetionet Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {self.G.number_of_nodes()} Ù†ÙˆØ¯ØŒ {self.G.number_of_edges()} ÛŒØ§Ù„")
        print(f" Ø´Ø§Ù…Ù„ {len([n for n, d in self.G.nodes(data=True) if d.get('metanode') == 'Gene'])} Ú˜Ù†ØŒ {len([n for n, d in self.G.nodes(data=True) if d.get('metanode') == 'Anatomy'])} Ø¢Ù†Ø§ØªÙˆÙ…ÛŒ")
        print(f" Ø´Ø§Ù…Ù„ {len([e for e in self.G.edges(data=True) if e[2].get('metaedge') == 'AeG'])} ÛŒØ§Ù„ AeG (Anatomy-expresses-Gene)")
        print(f" Ø´Ø§Ù…Ù„ {len([e for e in self.G.edges(data=True) if e[2].get('metaedge') == 'GeA'])} ÛŒØ§Ù„ GeA (Gene-expressed_in-Anatomy) - Ù…Ø¹Ú©ÙˆØ³")
        self._post_graph_loaded()
    
    def load_graph_from_file(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú¯Ø±Ø§Ù Ø§Ø² ÙØ§ÛŒÙ„"""
        try:
            with open(self.graph_data_path, 'rb') as f:
                self.G = pickle.load(f)
            print(f" Ú¯Ø±Ø§Ù Ø§Ø² ÙØ§ÛŒÙ„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: {self.G.number_of_nodes()} Ù†ÙˆØ¯ØŒ {self.G.number_of_edges()} ÛŒØ§Ù„")
            self._post_graph_loaded()
        except Exception as e:
            print(f" Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú¯Ø±Ø§Ù: {e}")
            self.create_sample_graph()
    
    def extract_keywords(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø§Ø² Ù…ØªÙ† Ø¨Ø§ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ú˜Ù†â€ŒÙ‡Ø§ Ùˆ Ø§ØµØ·Ù„Ø§Ø­Ø§Øª ØªØ®ØµØµÛŒ"""
        # Ú©Ø´ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª
        if text in self._keyword_cache:
            return self._keyword_cache[text]
        if self.nlp is None:
            # fallback Ø³Ø§Ø¯Ù‡ Ø¨Ø¯ÙˆÙ† spaCy
            import re as _re
            tokens = _re.sub(r"[^\w\s]", " ", text.lower()).split()
            keywords = sorted(set(t for t in tokens if len(t) >= 2))
            self._keyword_cache[text] = keywords
            return keywords
        doc = self.nlp(text)
        keywords = set()
        
        # Ù†Ú¯Ø§Ø´Øª ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ù‡Ù…
        persian_to_english = {
            # Ú˜Ù†â€ŒÙ‡Ø§
            'Ú˜Ù†': 'gene', 'Ú˜Ù†â€ŒÙ‡Ø§': 'genes', 'Ù¾Ø±ÙˆØªØ¦ÛŒÙ†': 'protein', 'Ù¾Ø±ÙˆØªØ¦ÛŒÙ†â€ŒÙ‡Ø§': 'proteins',
            'Ø¯ÛŒâ€ŒØ§Ù†â€ŒØ§ÛŒ': 'dna', 'Ø¢Ø±â€ŒØ§Ù†â€ŒØ§ÛŒ': 'rna', 'Ø§Ù…â€ŒØ¢Ø±â€ŒØ§Ù†â€ŒØ§ÛŒ': 'mrna',
            
            # Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ Ùˆ Ø§Ù†Ø¯Ø§Ù…â€ŒÙ‡Ø§
            'Ú©Ø¨Ø¯': 'liver', 'Ù…ØºØ²': 'brain', 'Ù‚Ù„Ø¨': 'heart', 'Ø±ÛŒÙ‡': 'lung', 'Ú©Ù„ÛŒÙ‡': 'kidney',
            'Ù…Ø¹Ø¯Ù‡': 'stomach', 'Ù…Ø§Ù‡ÛŒÚ†Ù‡': 'muscle', 'Ø§Ø³ØªØ®ÙˆØ§Ù†': 'bone', 'Ø®ÙˆÙ†': 'blood',
            'Ø¨Ø§ÙØª': 'tissue', 'Ø¨Ø§ÙØªâ€ŒÙ‡Ø§': 'tissues', 'Ø§Ù†Ø¯Ø§Ù…': 'organ', 'Ø§Ù†Ø¯Ø§Ù…â€ŒÙ‡Ø§': 'organs',
            'Ø¨Ø¯Ù†': 'body', 'Ø¨Ø®Ø´ Ø¨Ø¯Ù†': 'body part',
            
            # Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§
            'Ø³Ø±Ø·Ø§Ù†': 'cancer', 'Ø³Ø±Ø·Ø§Ù†â€ŒÙ‡Ø§': 'cancers', 'ØªÙˆÙ…ÙˆØ±': 'tumor', 'ØªÙˆÙ…ÙˆØ±Ù‡Ø§': 'tumors',
            'Ø¨ÛŒÙ…Ø§Ø±ÛŒ': 'disease', 'Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§': 'diseases', 'Ø§Ø®ØªÙ„Ø§Ù„': 'disorder', 'Ø§Ø®ØªÙ„Ø§Ù„Ø§Øª': 'disorders',
            'Ø³Ù†Ø¯Ø±Ù…': 'syndrome', 'Ø³Ù†Ø¯Ø±Ù…â€ŒÙ‡Ø§': 'syndromes', 'Ø¨Ø¯Ø®ÛŒÙ…ÛŒ': 'malignancy', 'Ø¨Ø¯Ø®ÛŒÙ…ÛŒâ€ŒÙ‡Ø§': 'malignancies',
            'Ø³Ø±Ø·Ø§Ù† Ø³ÛŒÙ†Ù‡': 'breast cancer', 'Ø³Ø±Ø·Ø§Ù† Ø±ÛŒÙ‡': 'lung cancer', 'Ø³Ø±Ø·Ø§Ù† Ú©Ø¨Ø¯': 'liver cancer',
            'Ø³Ø±Ø·Ø§Ù† Ù…ØºØ²': 'brain cancer', 'Ø³Ø±Ø·Ø§Ù† Ø®ÙˆÙ†': 'blood cancer', 'Ø³Ø±Ø·Ø§Ù† Ù…Ø¹Ø¯Ù‡': 'stomach cancer',
            'Ø¯ÛŒØ§Ø¨Øª': 'diabetes', 'Ø¢Ù„Ø²Ø§ÛŒÙ…Ø±': 'alzheimer', 'ÙÛŒØ¨Ø±ÙˆØ²': 'fibrosis',
            
            # Ø¯Ø§Ø±ÙˆÙ‡Ø§
            'Ø¯Ø§Ø±Ùˆ': 'drug', 'Ø¯Ø§Ø±ÙˆÙ‡Ø§': 'drugs', 'Ø¯Ø§Ø±ÙˆÛŒ': 'drug', 'Ø¯Ø§Ø±ÙˆÛŒÛŒ': 'drug',
            'Ø¯Ø§Ø±ÙˆÙ‡Ø§ÛŒ': 'drugs', 'Ø¯Ø§Ø±ÙˆÛŒÛŒ': 'drug', 'Ø¯Ø§Ø±ÙˆÙ‡Ø§': 'drugs',
            'Ø¢Ø³Ù¾Ø±ÛŒÙ†': 'aspirin', 'Ø§ÛŒØ¨ÙˆÙ¾Ø±ÙˆÙÙ†': 'ibuprofen', 'Ú©Ø§ÙØ¦ÛŒÙ†': 'caffeine',
            'ÙˆÛŒØªØ§Ù…ÛŒÙ†': 'vitamin', 'ÙˆÛŒØªØ§Ù…ÛŒÙ†â€ŒÙ‡Ø§': 'vitamins', 'Ø´ÛŒÙ…ÛŒØ§ÛŒÛŒ': 'chemical',
            'Ø´ÛŒÙ…ÛŒØ§ÛŒÛŒâ€ŒÙ‡Ø§': 'chemicals', 'Ù…ÙˆÙ„Ú©ÙˆÙ„': 'molecule', 'Ù…ÙˆÙ„Ú©ÙˆÙ„â€ŒÙ‡Ø§': 'molecules',
            'ØªØ±Ú©ÛŒØ¨': 'compound', 'ØªØ±Ú©ÛŒØ¨Ø§Øª': 'compounds', 'Ø¯Ø§Ø±Ùˆ': 'medication',
            'Ø¯Ø§Ø±ÙˆÙ‡Ø§': 'medications', 'Ø¯Ø§Ø±Ùˆ': 'medicine', 'Ø¯Ø§Ø±ÙˆÙ‡Ø§': 'medicines',
            
            # ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ
            'ÙØ±Ø¢ÛŒÙ†Ø¯': 'process', 'ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§': 'processes', 'Ø²ÛŒØ³ØªÛŒ': 'biological',
            'Ù…Ø³ÛŒØ±': 'pathway', 'Ù…Ø³ÛŒØ±Ù‡Ø§': 'pathways', 'Ù…Ú©Ø§Ù†ÛŒØ³Ù…': 'mechanism',
            'Ø¹Ù…Ù„Ú©Ø±Ø¯': 'function', 'Ø¹Ù…Ù„Ú©Ø±Ø¯Ù‡Ø§': 'functions', 'ÙØ¹Ø§Ù„ÛŒØª': 'activity',
            'ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§': 'activities', 'Ø¢Ù¾ÙˆÙ¾ØªÙˆØ²': 'apoptosis', 'Ú†Ø±Ø®Ù‡ Ø³Ù„ÙˆÙ„ÛŒ': 'cell cycle',
            'ØªØ±Ù…ÛŒÙ… Ø¯ÛŒâ€ŒØ§Ù†â€ŒØ§ÛŒ': 'dna repair', 'ØªÙ‚Ø³ÛŒÙ… Ø³Ù„ÙˆÙ„ÛŒ': 'cell division',
            
            # Ø¹Ù„Ø§Ø¦Ù…
            'Ø¹Ù„Ø§Ø¦Ù…': 'symptom', 'Ø¹Ù„Ø§Ø¦Ù…': 'symptoms', 'Ù†Ø´Ø§Ù†Ù‡': 'sign', 'Ù†Ø´Ø§Ù†Ù‡â€ŒÙ‡Ø§': 'signs',
            'ØªØ¬Ù„ÛŒ': 'manifestation', 'ØªØ¬Ù„ÛŒØ§Øª': 'manifestations', 'Ù†Ø´Ø§Ù†Ù‡': 'indication',
            'Ø¯Ø±Ø¯': 'pain', 'ØªØ¨': 'fever', 'Ø³Ø±ÙÙ‡': 'cough', 'Ø®Ø³ØªÚ¯ÛŒ': 'fatigue',
            
            # Ø¹ÙˆØ§Ø±Ø¶ Ø¬Ø§Ù†Ø¨ÛŒ
            'Ø¹ÙˆØ§Ø±Ø¶ Ø¬Ø§Ù†Ø¨ÛŒ': 'side effect', 'Ø¹ÙˆØ§Ø±Ø¶ Ø¬Ø§Ù†Ø¨ÛŒ': 'side effects', 'Ø¹ÙˆØ§Ø±Ø¶': 'adverse',
            'ÙˆØ§Ú©Ù†Ø´': 'reaction', 'ÙˆØ§Ú©Ù†Ø´â€ŒÙ‡Ø§': 'reactions', 'Ø³Ù…ÛŒØª': 'toxicity',
            'ØªÙ‡ÙˆØ¹': 'nausea', 'Ø³Ø±Ø¯Ø±Ø¯': 'headache', 'Ø³Ø±Ú¯ÛŒØ¬Ù‡': 'dizziness',
            
            # Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…ÙˆÙ„Ú©ÙˆÙ„ÛŒ
            'Ù…ÙˆÙ„Ú©ÙˆÙ„ÛŒ': 'molecular', 'Ø¢Ù†Ø²ÛŒÙ…ÛŒ': 'enzymatic', 'Ø¢Ù†Ø²ÛŒÙ…': 'enzyme',
            'Ú¯ÛŒØ±Ù†Ø¯Ù‡': 'receptor', 'Ø­Ø§Ù…Ù„': 'transporter', 'Ø­Ø§Ù…Ù„â€ŒÙ‡Ø§': 'transporters',
            
            # Ø§Ø¬Ø²Ø§ÛŒ Ø³Ù„ÙˆÙ„ÛŒ
            'Ø³Ù„ÙˆÙ„ÛŒ': 'cellular', 'Ø¬Ø²Ø¡': 'component', 'Ø§Ø¬Ø²Ø§': 'components',
            'Ø§Ù†Ø¯Ø§Ù…Ú©': 'organelle', 'Ø§Ù†Ø¯Ø§Ù…Ú©â€ŒÙ‡Ø§': 'organelles', 'Ø³Ø§Ø®ØªØ§Ø±': 'structure',
            'Ù‡Ø³ØªÙ‡': 'nucleus', 'Ù…ÛŒØªÙˆÚ©Ù†Ø¯Ø±ÛŒ': 'mitochondria', 'ØºØ´Ø§Ø¡': 'membrane',
            
            # Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ø±ÙˆÛŒÛŒ
            'Ø¯Ø§Ø±ÙˆÛŒÛŒ': 'pharmacologic', 'Ø¯Ø§Ø±ÙˆØ´Ù†Ø§Ø®ØªÛŒ': 'pharmacological', 'Ø·Ø¨Ù‚Ù‡': 'class',
            'Ø·Ø¨Ù‚Ø§Øª': 'classes', 'Ø¯Ø³ØªÙ‡': 'category', 'Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§': 'categories',
            'Ù†ÙˆØ¹': 'type', 'Ø§Ù†ÙˆØ§Ø¹': 'types', 'Ø¢Ù†ØªÛŒâ€ŒØ¨ÛŒÙˆØªÛŒÚ©': 'antibiotic',
            'Ø¶Ø¯ ÙØ´Ø§Ø± Ø®ÙˆÙ†': 'antihypertensive',
            
            # Ú©Ù„Ù…Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ
            'Ú©Ø¯Ø§Ù…': 'which', 'Ú†Ù‡': 'what', 'Ú©Ø¬Ø§': 'where', 'Ú†Ú¯ÙˆÙ†Ù‡': 'how',
            'Ú†Ø±Ø§': 'why', 'Ú†Ù‡ Ø²Ù…Ø§Ù†ÛŒ': 'when', 'Ú†Ù‡ Ú©Ø³ÛŒ': 'who',
            'Ù…Ø±ØªØ¨Ø·': 'related', 'Ù…Ø±ØªØ¨Ø· Ø¨Ø§': 'related to', 'Ù…Ø±Ø¨ÙˆØ·': 'associated',
            'Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡': 'associated with', 'Ù…ØªØµÙ„': 'connected', 'Ù…ØªØµÙ„ Ø¨Ù‡': 'connected to',
            'Ø¨ÛŒØ§Ù†': 'expression', 'Ø¨ÛŒØ§Ù† Ù…ÛŒâ€ŒØ´ÙˆØ¯': 'expressed', 'Ø¨ÛŒØ§Ù† Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯': 'expressed',
            'Ø¯Ø±Ù…Ø§Ù†': 'treatment', 'Ø¯Ø±Ù…Ø§Ù† Ù…ÛŒâ€ŒÚ©Ù†Ø¯': 'treats', 'Ø¯Ø±Ù…Ø§Ù† Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯': 'treat',
            'Ø§Ø³ØªÙØ§Ø¯Ù‡': 'used', 'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯': 'used', 'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯': 'used',
            'Ù†Ù‚Ø´': 'role', 'Ù†Ù‚Ø´ Ø¯Ø§Ø±Ø¯': 'plays role', 'Ù†Ù‚Ø´ Ø¯Ø§Ø±Ù†Ø¯': 'play role',
            'Ø´Ø±Ú©Øª': 'participate', 'Ø´Ø±Ú©Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯': 'participates', 'Ø´Ø±Ú©Øª Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯': 'participate',
            'ØªØ¹Ø§Ù…Ù„': 'interaction', 'ØªØ¹Ø§Ù…Ù„ Ø¯Ø§Ø±Ø¯': 'interacts', 'ØªØ¹Ø§Ù…Ù„ Ø¯Ø§Ø±Ù†Ø¯': 'interact',
            'ØªÙ†Ø¸ÛŒÙ…': 'regulation', 'ØªÙ†Ø¸ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†Ø¯': 'regulates', 'ØªÙ†Ø¸ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯': 'regulate',
            'Ø§ÙØ²Ø§ÛŒØ´': 'upregulation', 'Ø§ÙØ²Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯': 'upregulates', 'Ú©Ø§Ù‡Ø´': 'downregulation',
            'Ú©Ø§Ù‡Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯': 'downregulates', 'Ù…Ø­Ù„': 'location', 'Ù…Ø­Ù„ Ø§Ø³Øª': 'located',
            'ÛŒØ§ÙØª': 'found', 'ÛŒØ§ÙØª Ù…ÛŒâ€ŒØ´ÙˆØ¯': 'found', 'ÛŒØ§ÙØª Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯': 'found'
        }
        
        # Ù†Ú¯Ø§Ø´Øª Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ù‡ÙˆØ± Ùˆ Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¢Ù†Ù‡Ø§ (Ø¨Ø§ ØªØ±Ø¬ÛŒØ­ Ú©Ø§Ù…Ù„-Ù†Ø§Ù… Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ù‡ÛŒØ² Ø§Ø² ØªØ·Ø¨ÛŒÙ‚ Ø§Ø´ØªØ¨Ø§Ù‡ TP53RK)
        famous_genes = {
            'tp53': ['TP53', 'Tumor Protein P53', 'Tumor Suppressor P53', 'P53'],
            'brca1': ['BRCA1', 'Breast Cancer 1', 'BRCA1 Gene'],
            'brca2': ['BRCA2', 'Breast Cancer 2', 'BRCA2 Gene'],
            'apoe': ['APOE', 'Apolipoprotein E', 'APOE Gene'],
            'cftr': ['CFTR', 'Cystic Fibrosis Transmembrane Conductance Regulator'],
            'mmp9': ['MMP9', 'Matrix Metallopeptidase 9'],
            'bid': ['BID', 'BH3 Interacting Domain Death Agonist'],
            'kcnq2': ['KCNQ2', 'Potassium Voltage-Gated Channel Subfamily Q Member 2'],
            'hmgb3': ['HMGB3', 'High Mobility Group Box 3']
        }
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ù‡ÙˆØ± Ø¯Ø± Ù…ØªÙ†
        text_lower = text.lower()
        for gene_key, gene_variants in famous_genes.items():
            if gene_key in text_lower:
                keywords.add(gene_key)
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†Ø§Ù… Ø§ØµÙ„ÛŒ Ú˜Ù†
                keywords.add(gene_variants[0])
        
        # ØªØ¨Ø¯ÛŒÙ„ Ú©Ù„Ù…Ø§Øª ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
        for persian_word, english_word in persian_to_english.items():
            if persian_word in text:
                keywords.add(english_word)
                print(f"ğŸ”„ ØªØ¨Ø¯ÛŒÙ„ ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ: '{persian_word}' -> '{english_word}'")
        
        # Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…â€ŒØ¯Ø§Ø±
        for ent in doc.ents:
            if ent.label_ not in {"DATE", "TIME", "PERCENT", "MONEY", "QUANTITY", "ORDINAL", "CARDINAL"}:
                # Ø­Ø°Ù Ø¹Ù„Ø§Ø¦Ù… Ù†Ú¯Ø§Ø±Ø´ÛŒ Ø§Ø² Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
                clean_text = ''.join(c for c in ent.text.lower() if c.isalnum() or c.isspace())
                if clean_text.strip():
                    keywords.add(clean_text.strip())
        
        # Ø§Ø³Ù…â€ŒÙ‡Ø§ Ùˆ Ø§Ø³Ù… Ø®Ø§Øµâ€ŒÙ‡Ø§
        for token in doc:
            if (token.pos_ in {"NOUN", "PROPN"} and 
                token.text.lower() not in STOP_WORDS and 
                token.is_alpha and len(token.text) > 2):
                # Ø­Ø°Ù Ø¹Ù„Ø§Ø¦Ù… Ù†Ú¯Ø§Ø±Ø´ÛŒ
                clean_text = ''.join(c for c in token.text.lower() if c.isalnum() or c.isspace())
                if clean_text.strip():
                    keywords.add(clean_text.strip())
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ ØªØ®ØµØµÛŒ
        technical_terms = [
            'cancer', 'tumor', 'malignancy', 'oncology', 'carcinoma', 'sarcoma', 
            'leukemia', 'lymphoma', 'gene', 'protein', 'dna', 'rna', 'mrna',
            'apoptosis', 'cell cycle', 'dna repair', 'mutation', 'expression',
            'regulation', 'pathway', 'signaling', 'metabolic', 'cascade'
        ]
        
        for term in technical_terms:
            if term in text_lower:
                keywords.add(term)
        
        # Ø­Ø°Ù Ú©Ù„Ù…Ø§Øª Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¹Ù…ÙˆÙ…ÛŒ
        filtered_keywords = set()
        for keyword in keywords:
            if len(keyword) >= 2 and keyword not in ['the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by']:
                filtered_keywords.add(keyword)
        
        result = sorted(filtered_keywords)
        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú©Ø´
        if len(self._keyword_cache) > 1024:
            self._keyword_cache.clear()
        self._keyword_cache[text] = result
        return result
    
    def analyze_question_intent(self, query: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ù…ÙÙ‡ÙˆÙ…ÛŒ Ø³ÙˆØ§Ù„ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ØµØ¯ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¬Ø¯ÙˆÙ„ Ù†Ú¯Ø§Ø´Øª Hetionet"""
        query_lower = query.lower()
        
        # 1. ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¬Ø¯ÙˆÙ„ Ù†Ú¯Ø§Ø´Øª
        question_patterns = {
            # Ø¨ÛŒØ§Ù† Ú˜Ù† Ø¯Ø± Ø¨Ø§ÙØª
            'anatomy_expression': {
                'patterns': ['expressed in', 'expression in', 'genes in', 'expressed by', 'genes are expressed', 'what genes are expressed'],
                'metaedges': ['AeG'],
                'description': 'Ú©Ø¯Ø§Ù… Ú˜Ù†â€ŒÙ‡Ø§ Ø¯Ø± [Ø¨Ø§ÙØª] Ø¨ÛŒØ§Ù† Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ØŸ'
            },
            # Ø¨ÛŒØ§Ù† Ú˜Ù† Ø¯Ø± Ù…Ú©Ø§Ù† Ø®Ø§Øµ
            'gene_expression_location': {
                'patterns': ['where is', 'expressed in', 'found in', 'located in', 'where does'],
                'metaedges': ['GeA'],
                'description': 'Ú˜Ù† [X] Ø¯Ø± Ú©Ø¬Ø§ Ø¨ÛŒØ§Ù† Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŸ'
            },
            # Ù…Ø´Ø§Ø±Ú©Øª Ø¯Ø± ÙØ±Ø¢ÛŒÙ†Ø¯ Ø²ÛŒØ³ØªÛŒ
            'biological_participation': {
                'patterns': ['participates in', 'involved in', 'role in', 'part of', 'participate'],
                'metaedges': ['GpBP', 'GpMF', 'GpCC'],
                'description': 'Ú˜Ù†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± [ÙØ±Ø¢ÛŒÙ†Ø¯ Ø²ÛŒØ³ØªÛŒ] Ø´Ø±Ú©Øª Ø¯Ø§Ø±Ù†Ø¯ØŸ'
            },
            # ØªØ¹Ø§Ù…Ù„ Ú˜Ù†â€ŒÙ‡Ø§
            'gene_interaction': {
                'patterns': ['interacts', 'interaction', 'binds', 'binding', 'interact with', 'which genes interact'],
                'metaedges': ['GiG'],
                'description': 'Ú˜Ù†ÛŒ Ú©Ù‡ Ø¨Ø§ Ú˜Ù† [X] ØªØ¹Ø§Ù…Ù„ Ø¯Ø§Ø±Ø¯ØŸ'
            },
            # ØªÙ†Ø¸ÛŒÙ… Ú˜Ù† ØªÙˆØ³Ø· Ø¨ÛŒÙ…Ø§Ø±ÛŒ
            'disease_gene_regulation': {
                'patterns': ['regulates', 'upregulates', 'downregulates', 'associated', 'associates'],
                'metaedges': ['DuG', 'DdG', 'DaG'],
                'description': 'Ú˜Ù†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨ÛŒÙ…Ø§Ø±ÛŒ [Y] Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŸ'
            },
            # Ø¯Ø±Ù…Ø§Ù† Ø¨ÛŒÙ…Ø§Ø±ÛŒ
            'disease_treatment': {
                'patterns': ['treats', 'treatment', 'therapy', 'therapeutic', 'treat'],
                'metaedges': ['CtD'],
                'description': 'Ø¯Ø§Ø±ÙˆÛŒÛŒ Ú©Ù‡ Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø±Ø§ Ø¯Ø±Ù…Ø§Ù† Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ'
            },
            # ØªÙ†Ø¸ÛŒÙ… Ú˜Ù† ØªÙˆØ³Ø· Ø¯Ø§Ø±Ùˆ
            'compound_gene_regulation': {
                'patterns': ['upregulates', 'downregulates', 'binds to', 'regulates'],
                'metaedges': ['CuG', 'CdG', 'CbG'],
                'description': 'Ø¯Ø§Ø±ÙˆÛŒÛŒ Ú©Ù‡ Ú˜Ù† Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ'
            },
            # Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¨Ø§ÙØª
            'anatomy_disease': {
                'patterns': ['diseases in', 'affects', 'localized to', 'disease in'],
                'metaedges': ['DlA'],
                'description': 'Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ù‡ [Ø¨Ø§ÙØª] Ù…Ø±Ø¨ÙˆØ·Ù†Ø¯ØŸ'
            },
            # Ø§Ø«Ø± Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¨Ø± Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ (Ø¬Ø¯ÛŒØ¯)
            'disease_tissue_effect': {
                'patterns': ['how does', 'affect', 'affects', 'effect on', 'effects on', 'tissue', 'tissues'],
                'metaedges': ['DlA', 'DuG', 'DdG', 'AeG', 'AuG', 'AdG', 'GpBP'],
                'description': 'Ú†Ú¯ÙˆÙ†Ù‡ Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¨Ø± Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø§Ø«Ø± Ù…ÛŒâ€ŒÚ¯Ø°Ø§Ø±Ø¯ØŸ'
            },
            # Ø¹Ù„Ø§Ø¦Ù… Ø¨ÛŒÙ…Ø§Ø±ÛŒ
            'disease_symptom': {
                'patterns': ['symptoms', 'presents', 'signs', 'manifestation', 'symptom'],
                'metaedges': ['DpS'],
                'description': 'Ø¹Ù„Ø§Ø¦Ù… Ø¨ÛŒÙ…Ø§Ø±ÛŒ [Z] Ú†ÛŒØ³ØªØŸ'
            },
            # Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡
            'disease_similarity': {
                'patterns': ['similar', 'resembles', 'alike', 'related', 'similar to'],
                'metaedges': ['DrD'],
                'description': 'Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡ Ø¨Ù‡ Ø¨ÛŒÙ…Ø§Ø±ÛŒ [X]ØŸ'
            },
            # Ø¹ÙˆØ§Ø±Ø¶ Ø¯Ø§Ø±Ùˆ
            'compound_side_effect': {
                'patterns': ['side effect', 'adverse', 'reaction', 'causes', 'side effects'],
                'metaedges': ['CcSE'],
                'description': 'Ø¹ÙˆØ§Ø±Ø¶ Ø¯Ø§Ø±ÙˆÛŒ [X] Ú†ÛŒØ³ØªØŸ'
            },
            # Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ú˜Ù†
            'gene_pathway': {
                'patterns': ['pathway', 'signaling', 'metabolic', 'cascade', 'pathways'],
                'metaedges': ['GpPW'],
                'description': 'ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ú˜Ù† Ø¯Ø± Ø¢Ù†Ù‡Ø§ Ù†Ù‚Ø´ Ø¯Ø§Ø±Ø¯ØŸ'
            },
            # ØªÙ†Ø¸ÛŒÙ… Ú˜Ù† ØªÙˆØ³Ø· Ú˜Ù† Ø¯ÛŒÚ¯Ø±
            'gene_regulation': {
                'patterns': ['regulates', 'controls', 'regulation', 'regulate'],
                'metaedges': ['Gr>G'],
                'description': 'Ú˜Ù†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ú˜Ù† [X] Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŸ'
            },
            # Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ú˜Ù†â€ŒÙ‡Ø§
            'gene_covariation': {
                'patterns': [
                    'covary', 'covaries', 'co-vary', 'co-varies',
                    'coexpression', 'co-expression', 'coexpressed',
                    'correlated', 'correlation',
                    'Ù‡Ù…â€ŒÙˆØ§Ø±ÛŒØ§Ù†Ø³', 'Ù‡Ù…ÙˆØ§Ø±ÛŒØ§Ù†Ø³', 'Ù‡Ù…â€ŒØ¨Ø±ÙˆØ²', 'Ù‡Ù…Ø¨Ø±ÙˆØ²', 'Ù‡Ù…â€ŒØªØºÛŒÛŒØ±', 'Ù‡Ù…ØªØºÛŒÛŒØ±'
                ],
                'metaedges': ['GcG'],
                'description': 'Ú˜Ù†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ Ú˜Ù† [X] Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¯Ø§Ø±Ù†Ø¯ØŸ'
            }
        }
        
        # ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„
        detected_type = "general"
        detected_metaedges = []
        
        for qtype, config in question_patterns.items():
            for pattern in config['patterns']:
                if pattern in query_lower:
                    detected_type = qtype
                    detected_metaedges.extend(config['metaedges'])
                    break
            if detected_type != "general":
                break
        
        # 2. Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ metanodes Hetionet
        entity_mapping = {
            'Gene': ['gene', 'genes', 'protein', 'proteins', 'dna', 'rna', 'mrna', 'genetic', 'molecular', 'tp53', 'brca1', 'apoe', 'cftr', 'mmp9', 'bid', 'kcnq2', 'hmgb3'],
            'Anatomy': ['anatomy', 'organ', 'tissue', 'heart', 'brain', 'liver', 'lung', 'kidney', 'stomach', 'breast'],
            'Disease': ['disease', 'disorder', 'condition', 'syndrome', 'cancer', 'tumor', 'alzheimer', 'diabetes', 'cystic fibrosis', 'breast cancer', 'lung cancer', 'heart disease'],
            'Compound': ['compound', 'drug', 'medication', 'medicine', 'chemical', 'molecule', 'aspirin', 'insulin', 'caffeine', 'vitamin c', 'metformin', 'ibuprofen', 'paracetamol'],
            'Biological Process': ['process', 'biological', 'cellular', 'metabolic', 'apoptosis', 'inflammation', 'cell death', 'dna repair', 'cell cycle'],
            'Pathway': ['pathway', 'signaling', 'metabolic', 'cascade', 'wnt', 'notch', 'apoptosis pathway'],
            'Symptom': ['symptom', 'sign', 'manifestation', 'presentation', 'pain', 'fever', 'cough', 'fatigue'],
            'Side Effect': ['side effect', 'adverse', 'reaction', 'toxicity', 'nausea', 'headache', 'dizziness'],
            'Molecular Function': ['function', 'molecular', 'catalytic', 'binding', 'enzyme', 'receptor', 'transporter'],
            'Cellular Component': ['component', 'cellular', 'organelle', 'structure', 'nucleus', 'mitochondria', 'cell membrane'],
            'Pharmacologic Class': ['class', 'pharmacologic', 'therapeutic', 'antibiotic', 'antiviral', 'nsaid']
        }
        
        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
        detected_entities = []
        entity_types = []
        
        for entity_type, keywords in entity_mapping.items():
            for keyword in keywords:
                if keyword in query_lower:
                    if entity_type not in entity_types:
                        entity_types.append(entity_type)
                    if keyword not in detected_entities:
                        detected_entities.append(keyword)
        
        # 3. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡
        keywords = self.extract_keywords(query)
        
        # 4. ØªØ´Ø®ÛŒØµ Ø¬Ù‡Øª Ø±Ø§Ø¨Ø·Ù‡
        direction = "forward"
        if any(word in query_lower for word in ['where', 'location', 'found in', 'expressed in', 'where is', 'where does']):
            direction = "reverse"
        
        return {
            'question_type': detected_type,
            'metaedges': list(set(detected_metaedges)),  # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±
            'entities': detected_entities,
            'entity_types': entity_types,
            'keywords': keywords,
            'direction': direction,
            'query': query,
            'query_lower': query_lower,
            'description': question_patterns.get(detected_type, {}).get('description', 'Ø³ÙˆØ§Ù„ Ø¹Ù…ÙˆÙ…ÛŒ')
        }
    
    def intelligent_semantic_search(self, query: str, max_depth: int = 3) -> List[Tuple[str, int, float, str]]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¬Ø¯ÙˆÙ„ Ù†Ú¯Ø§Ø´Øª Hetionet"""
        if not self.G:
            return []
        
        # ØªØ­Ù„ÛŒÙ„ Ù…ÙÙ‡ÙˆÙ…ÛŒ Ø³ÙˆØ§Ù„
        intent = self.analyze_question_intent(query)
        print(f"ğŸ” ØªØ­Ù„ÛŒÙ„ Ù…ÙÙ‡ÙˆÙ…ÛŒ Ø³ÙˆØ§Ù„: {intent['question_type']}")
        print(f"ğŸ“Š Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§: {intent['entity_types']}")
        print(f"ğŸ”— metaedges: {intent['metaedges']}")
        print(f"ğŸ“ ØªÙˆØ¶ÛŒØ­: {intent['description']}")
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
        keywords = intent['keywords']
        print(f"ğŸ”‘ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: {keywords}")
        
        # ØªØ·Ø¨ÛŒÙ‚ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¨Ø§ Ù†ÙˆØ¯Ù‡Ø§
        matched_nodes = self.match_tokens_to_nodes(keywords)
        print(f"ğŸ¯ Ù†ÙˆØ¯Ù‡Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ ÛŒØ§ÙØªÙ‡: {matched_nodes}")
        
        # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ù†ÙˆØ¯ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ù†Ú©Ø±Ø¯ØŒ Ø³Ø¹ÛŒ Ú©Ù† Ù‡Ù…Ù‡ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø±Ø§ ØªØ·Ø¨ÛŒÙ‚ Ø¯Ù‡ÛŒ
        if not matched_nodes:
            print("âš ï¸ Ù‡ÛŒÚ† Ù†ÙˆØ¯ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ù†Ú©Ø±Ø¯ØŒ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ù‡Ù…Ù‡ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§")
            all_tokens = query.lower().split()
            matched_nodes = self.match_tokens_to_nodes(all_tokens)
            print(f"ğŸ¯ Ù†ÙˆØ¯Ù‡Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ ÛŒØ§ÙØªÙ‡ (ØªÙ„Ø§Ø´ Ø¯ÙˆÙ…): {matched_nodes}")
        
        results = []
        
        # ØªØ´Ø®ÛŒØµ Ø³ÙˆØ§Ù„Ø§Øª Ø®Ø§Øµ Ú˜Ù†-Ø³Ø±Ø·Ø§Ù†
        if self._is_gene_cancer_question(query, matched_nodes):
            print("ğŸ¯ ØªØ´Ø®ÛŒØµ Ø³ÙˆØ§Ù„ Ú˜Ù†-Ø³Ø±Ø·Ø§Ù†")
            results = self._search_gene_cancer_relationships(query, matched_nodes, max_depth)
        # Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„ Ùˆ metaedgesØŒ Ø±ÙˆØ´ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†
        elif intent['question_type'] == 'anatomy_expression':
            print("ğŸ«€ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: Ø¨ÛŒØ§Ù† Ú˜Ù† Ø¯Ø± Ø¢Ù†Ø§ØªÙˆÙ…ÛŒ")
            results = self._search_by_metaedges(matched_nodes, intent, ['AeG'], max_depth)
            
        elif intent['question_type'] == 'gene_expression_location':
            print("ğŸ“ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: Ù…Ú©Ø§Ù† Ø¨ÛŒØ§Ù† Ú˜Ù†")
            results = self._search_by_metaedges(matched_nodes, intent, ['GeA'], max_depth)
            
        elif intent['question_type'] == 'biological_participation':
            print("ğŸ§¬ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: Ù…Ø´Ø§Ø±Ú©Øª Ø¯Ø± ÙØ±Ø¢ÛŒÙ†Ø¯ Ø²ÛŒØ³ØªÛŒ")
            results = self._search_by_metaedges(matched_nodes, intent, ['GpBP', 'GpMF', 'GpCC'], max_depth)
            
        elif intent['question_type'] == 'gene_interaction':
            print("ğŸ”— ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: ØªØ¹Ø§Ù…Ù„ Ú˜Ù†â€ŒÙ‡Ø§")
            results = self._search_by_metaedges(matched_nodes, intent, ['GiG'], max_depth)
            
        elif intent['question_type'] == 'disease_gene_regulation':
            print("ğŸ¥ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: ØªÙ†Ø¸ÛŒÙ… Ú˜Ù† ØªÙˆØ³Ø· Ø¨ÛŒÙ…Ø§Ø±ÛŒ")
            results = self._search_by_metaedges(matched_nodes, intent, ['DuG', 'DdG', 'DaG'], max_depth)
            
        elif intent['question_type'] == 'disease_treatment':
            print("ğŸ’Š ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: Ø¯Ø±Ù…Ø§Ù† Ø¨ÛŒÙ…Ø§Ø±ÛŒ")
            results = self._search_by_metaedges(matched_nodes, intent, ['CtD'], max_depth)
            
        elif intent['question_type'] == 'compound_gene_regulation':
            print("ğŸ§ª ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: ØªÙ†Ø¸ÛŒÙ… Ú˜Ù† ØªÙˆØ³Ø· Ø¯Ø§Ø±Ùˆ")
            results = self._search_by_metaedges(matched_nodes, intent, ['CuG', 'CdG', 'CbG'], max_depth)
            
        elif intent['question_type'] == 'anatomy_disease':
            print("ğŸ¥ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¨Ø§ÙØª")
            results = self._search_by_metaedges(matched_nodes, intent, ['DlA'], max_depth)
            
        elif intent['question_type'] == 'disease_symptom':
            print(" ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: Ø¹Ù„Ø§Ø¦Ù… Ø¨ÛŒÙ…Ø§Ø±ÛŒ")
            results = self._search_by_metaedges(matched_nodes, intent, ['DpS'], max_depth)
            
        elif intent['question_type'] == 'disease_similarity':
            print("ğŸ”„ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡")
            results = self._search_by_metaedges(matched_nodes, intent, ['DrD'], max_depth)
            
        elif intent['question_type'] == 'compound_side_effect':
            print("âš ï¸ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: Ø¹ÙˆØ§Ø±Ø¶ Ø¯Ø§Ø±Ùˆ")
            results = self._search_by_metaedges(matched_nodes, intent, ['CcSE'], max_depth)
            
        elif intent['question_type'] == 'gene_pathway':
            print("ğŸ›¤ï¸ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ú˜Ù†")
            results = self._search_by_metaedges(matched_nodes, intent, ['GpPW'], max_depth)
            
        elif intent['question_type'] == 'gene_regulation':
            print("ğŸ›ï¸ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: ØªÙ†Ø¸ÛŒÙ… Ú˜Ù† ØªÙˆØ³Ø· Ú˜Ù† Ø¯ÛŒÚ¯Ø±")
            results = self._search_by_metaedges(matched_nodes, intent, ['Gr>G'], max_depth)
            
        elif intent['question_type'] == 'gene_covariation':
            print("ğŸ“ˆ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ú˜Ù†â€ŒÙ‡Ø§")
            results = self._search_by_metaedges(matched_nodes, intent, ['GcG'], max_depth)
            
        else:
            print("ğŸ” ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: Ø¹Ù…ÙˆÙ…ÛŒ")
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙ…Ø§Ù… metaedges Ù…ÙˆØ¬ÙˆØ¯
            all_metaedges = ['AeG', 'GeA', 'GpBP', 'GpMF', 'GpCC', 'GpPW', 'GiG', 'Gr>G', 'GcG', 
                           'DuG', 'DdG', 'DaG', 'DlA', 'DpS', 'DrD', 'CtD', 'CuG', 'CdG', 'CbG', 'CcSE']
            results = self._search_by_metaedges(matched_nodes, intent, all_metaedges, max_depth)
        
        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø± Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø²
        unique_results = {}
        for node_id, depth, score, explanation in results:
            if node_id not in unique_results or score > unique_results[node_id][2]:
                unique_results[node_id] = (node_id, depth, score, explanation)
        
        final_results = sorted(unique_results.values(), key=lambda x: x[2], reverse=True)
        
        return final_results
    
    def _is_gene_cancer_question(self, query: str, matched_nodes: Dict[str, str]) -> bool:
        """ØªØ´Ø®ÛŒØµ Ø³ÙˆØ§Ù„Ø§Øª Ú˜Ù†-Ø³Ø±Ø·Ø§Ù†"""
        query_lower = query.lower()
        cancer_keywords = ['cancer', 'tumor', 'malignancy', 'oncology', 'carcinoma', 'sarcoma', 'leukemia', 'lymphoma']
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ú©Ù„Ù…Ø§Øª Ø³Ø±Ø·Ø§Ù†
        has_cancer = any(keyword in query_lower for keyword in cancer_keywords)
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ú˜Ù†â€ŒÙ‡Ø§
        has_gene = any(self.G.nodes[node_id].get('kind') == 'Gene' for node_id in matched_nodes.values())
        
        return has_cancer and has_gene
    
    def _search_gene_cancer_relationships(self, query: str, matched_nodes: Dict[str, str], max_depth: int) -> List[Tuple[str, int, float, str]]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ø±ÙˆØ§Ø¨Ø· Ú˜Ù†-Ø³Ø±Ø·Ø§Ù†"""
        results = []
        
        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú˜Ù†â€ŒÙ‡Ø§ Ùˆ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø±Ø·Ø§Ù†
        gene_nodes = []
        cancer_nodes = []
        
        for token, node_id in matched_nodes.items():
            node_attrs = self.G.nodes[node_id]
            if node_attrs.get('kind') == 'Gene':
                gene_nodes.append((token, node_id))
            elif node_attrs.get('kind') == 'Disease':
                # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø³Ø±Ø·Ø§Ù† Ø§Ø³Øª
                node_name_lower = node_attrs['name'].lower()
                cancer_keywords = ['cancer', 'tumor', 'malignancy', 'carcinoma', 'sarcoma', 'leukemia', 'lymphoma']
                if any(keyword in node_name_lower for keyword in cancer_keywords):
                    cancer_nodes.append((token, node_id))
        
        print(f"ğŸ§¬ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡: {[name for name, _ in gene_nodes]}")
        print(f"ğŸ¥ Ø³Ø±Ø·Ø§Ù†â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡: {[name for name, _ in cancer_nodes]}")
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬
        for gene_token, gene_node_id in gene_nodes:
            gene_name = self.G.nodes[gene_node_id]['name']
            # Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ø±Ø§ÛŒ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
            score = 10.0  # Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ø±Ø§ÛŒ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
            explanation = f"Primary gene: {gene_name}"
            results.append((gene_node_id, 0, score, explanation))
            print(f"  âœ… Ú˜Ù† Ø§ØµÙ„ÛŒ: {gene_name} (Ø§Ù…ØªÛŒØ§Ø²: {score})")
        
        # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø±ÙˆØ§Ø¨Ø· Ù…Ø³ØªÙ‚ÛŒÙ… Ú˜Ù†-Ø³Ø±Ø·Ø§Ù†
        for gene_token, gene_node_id in gene_nodes:
            gene_name = self.G.nodes[gene_node_id]['name']
            print(f"ğŸ” Ø¬Ø³ØªØ¬ÙˆÛŒ Ø±ÙˆØ§Ø¨Ø· Ø¨Ø±Ø§ÛŒ Ú˜Ù†: {gene_name}")
            
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒÙ…Ø§Ø±ÛŒ
            for neighbor in self.G.neighbors(gene_node_id):
                neighbor_attrs = self.G.nodes[neighbor]
                if neighbor_attrs.get('kind') == 'Disease':
                    edge_data = self.G.get_edge_data(gene_node_id, neighbor)
                    if edge_data:
                        metaedge = edge_data.get('metaedge', 'Unknown')
                        # Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ§Ø¨Ø· Ø³Ø±Ø·Ø§Ù†
                        neighbor_name_lower = neighbor_attrs['name'].lower()
                        cancer_score = 2.0 if any(keyword in neighbor_name_lower for keyword in ['cancer', 'tumor', 'malignancy']) else 1.0
                        
                        score = self._calculate_metaedge_score(metaedge, 1) * cancer_score
                        explanation = f"{gene_name} related to {neighbor_attrs['name']} via {metaedge}"
                        
                        results.append((neighbor, 1, score, explanation))
                        print(f"  âœ… {neighbor_attrs['name']} - {metaedge} (Ø§Ù…ØªÛŒØ§Ø²: {score})")
            
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ú©ÙˆØ³ (Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ú©Ù‡ Ø¨Ù‡ Ú˜Ù† Ù…ØªØµÙ„ Ù‡Ø³ØªÙ†Ø¯)
            for other_node, other_attrs in self.G.nodes(data=True):
                if other_attrs.get('kind') == 'Disease' and other_node != gene_node_id:
                    for neighbor in self.G.neighbors(other_node):
                        if neighbor == gene_node_id:
                            edge_data = self.G.get_edge_data(other_node, neighbor)
                            if edge_data:
                                metaedge = edge_data.get('metaedge', 'Unknown')
                                # Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ§Ø¨Ø· Ø³Ø±Ø·Ø§Ù†
                                other_name_lower = other_attrs['name'].lower()
                                cancer_score = 2.0 if any(keyword in other_name_lower for keyword in ['cancer', 'tumor', 'malignancy']) else 1.0
                                
                                score = self._calculate_metaedge_score(metaedge, 1) * cancer_score * 0.8  # Ø§Ù…ØªÛŒØ§Ø² Ú©Ù…ØªØ± Ø¨Ø±Ø§ÛŒ Ù…Ø¹Ú©ÙˆØ³
                                explanation = f"{other_attrs['name']} related to {gene_name} via {metaedge}"
                                
                                results.append((other_node, 1, score, explanation))
                                print(f"  âœ… {other_attrs['name']} - {metaedge} Ù…Ø¹Ú©ÙˆØ³ (Ø§Ù…ØªÛŒØ§Ø²: {score})")
        
        # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¹Ù…ÛŒÙ‚ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ§Ø¨Ø· ØºÛŒØ±Ù…Ø³ØªÙ‚ÛŒÙ…
        if max_depth > 1:
            for gene_token, gene_node_id in gene_nodes:
                print(f"ğŸ” Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¹Ù…ÛŒÙ‚ Ø¨Ø±Ø§ÛŒ Ú˜Ù†: {self.G.nodes[gene_node_id]['name']}")
                dfs_results = self.dfs_search(gene_node_id, max_depth)
                for found_node, depth in dfs_results:
                    found_attrs = self.G.nodes[found_node]
                    if found_attrs.get('kind') == 'Disease':
                        # Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù…Ù‚ Ùˆ Ù†ÙˆØ¹ Ø¨ÛŒÙ…Ø§Ø±ÛŒ
                        neighbor_name_lower = found_attrs['name'].lower()
                        cancer_score = 1.5 if any(keyword in neighbor_name_lower for keyword in ['cancer', 'tumor', 'malignancy']) else 1.0
                        
                        score = self._calculate_metaedge_score('Unknown', depth) * cancer_score * (1.0 / depth)
                        explanation = f"{found_attrs['name']} found at depth {depth} from {self.G.nodes[gene_node_id]['name']}"
                        
                        results.append((found_node, depth, score, explanation))
                        print(f"  âœ… {found_attrs['name']} Ø¯Ø± Ø¹Ù…Ù‚ {depth} (Ø§Ù…ØªÛŒØ§Ø²: {score})")
        
        return results
    
    def _search_genes_expressed_in_anatomy(self, matched_nodes: Dict[str, str], intent: Dict, max_depth: int = 2) -> List[Tuple[str, int, float, str]]:
        """
        Ø¬Ø³ØªØ¬Ùˆ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ú©Ø¯Ø§Ù… Ú˜Ù†â€ŒÙ‡Ø§ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø±ÙˆØ§Ø¨Ø· Ù…Ø®ØªÙ„Ù Ø¯Ø± ÛŒÚ© Ø§Ù†Ø¯Ø§Ù… Ø®Ø§Øµ Ø¨ÛŒØ§Ù† Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
        Ø¨Ø± Ø§Ø³Ø§Ø³ Hetionet: AeG (expresses), AuG (upregulates), AdG (downregulates)

        Args:
            matched_nodes (dict): Ù†Ú¯Ø§Ø´Øª ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¨Ù‡ Ù†ÙˆØ¯Ù‡Ø§
            intent (dict): Ù†ØªÛŒØ¬Ù‡ intent detection
            max_depth (int): Ø­Ø¯Ø§Ú©Ø«Ø± Ø¹Ù…Ù‚ Ø¬Ø³ØªØ¬Ùˆ

        Returns:
            List[Tuple[str, int, float, str]]: Ù„ÛŒØ³Øª Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ú˜Ù† Ù¾ÛŒØ¯Ø§ Ø´Ø¯Ù‡ Ø¨Ø§ Ø¹Ù…Ù‚ Ùˆ Ù†Ù…Ø±Ù‡
        """
        results = []
        
        for token, node_id in matched_nodes.items():
            if self.G.nodes[node_id]['kind'] == 'Anatomy':
                anatomy_name = self.G.nodes[node_id]['name']
                print(f"ğŸ” Ø¬Ø³ØªØ¬ÙˆÛŒ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ {anatomy_name} Ø¯Ø± Hetionet")
                
                # Ø¨Ø±Ø±Ø³ÛŒ ØªÙ…Ø§Ù… Ø±ÙˆØ§Ø¨Ø· Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¨ÛŒØ§Ù† Ú˜Ù†
                expression_relations = ['AeG', 'AuG', 'AdG']  # Anatomy -> Gene relations
                
                for relation in expression_relations:
                    relation_name = {
                        'AeG': 'expresses',
                        'AuG': 'upregulates', 
                        'AdG': 'downregulates'
                    }.get(relation, relation)
                    
                    print(f"  ğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ø±Ø§Ø¨Ø·Ù‡ {relation} ({relation_name})")
                    
                    for neighbor in self.G.neighbors(node_id):
                        if self.G.nodes[neighbor]['kind'] == 'Gene':
                            edge_data = self.G.get_edge_data(node_id, neighbor)
                            if edge_data and edge_data.get('metaedge') == relation:
                                gene_name = self.G.nodes[neighbor]['name']
                                
                                # Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø±Ø§Ø¨Ø·Ù‡
                                if relation == 'AeG':
                                    score = 5.0  # Ø¨ÛŒØ§Ù† Ù…Ø³ØªÙ‚ÛŒÙ…
                                    explanation = f"{gene_name} is expressed in {anatomy_name}"
                                elif relation == 'AuG':
                                    score = 4.5  # ØªÙ†Ø¸ÛŒÙ… Ù…Ø«Ø¨Øª
                                    explanation = f"{gene_name} is upregulated in {anatomy_name}"
                                elif relation == 'AdG':
                                    score = 4.0  # ØªÙ†Ø¸ÛŒÙ… Ù…Ù†ÙÛŒ
                                    explanation = f"{gene_name} is downregulated in {anatomy_name}"
                                else:
                                    score = 3.5
                                    explanation = f"{gene_name} is related to {anatomy_name} via {relation}"
                                
                                results.append((neighbor, 1, score, explanation))
                                print(f"    âœ… {gene_name} - {relation_name} Ø¯Ø± {anatomy_name} (Ø§Ù…ØªÛŒØ§Ø²: {score})")
                
                # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ú©ÙˆØ³ (Gene -> Anatomy) Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
                print(f"  ğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹Ú©ÙˆØ³ (Gene -> {anatomy_name})")
                reverse_relations = ['GeA', 'GuA', 'GdA']  # Gene -> Anatomy relations
                
                for gene_node, gene_attrs in self.G.nodes(data=True):
                    if gene_attrs.get('kind') == 'Gene':
                        for neighbor in self.G.neighbors(gene_node):
                            if neighbor == node_id:
                                edge_data = self.G.get_edge_data(gene_node, neighbor)
                                if edge_data:
                                    relation = edge_data.get('metaedge')
                                    if relation in reverse_relations:
                                        gene_name = gene_attrs['name']
                                        
                                        # Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹Ú©ÙˆØ³
                                        if relation == 'GeA':
                                            score = 4.0
                                            explanation = f"{gene_name} expresses in {anatomy_name}"
                                        elif relation == 'GuA':
                                            score = 3.5
                                            explanation = f"{gene_name} upregulates in {anatomy_name}"
                                        elif relation == 'GdA':
                                            score = 3.0
                                            explanation = f"{gene_name} downregulates in {anatomy_name}"
                                        else:
                                            score = 2.5
                                            explanation = f"{gene_name} related to {anatomy_name} via {relation}"
                                        
                                        results.append((gene_node, 1, score, explanation))
                                        print(f"    âœ… {gene_name} - Ø±Ø§Ø¨Ø·Ù‡ Ù…Ø¹Ú©ÙˆØ³ {relation} Ø¨Ø§ {anatomy_name} (Ø§Ù…ØªÛŒØ§Ø²: {score})")
                
                # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¹Ù…ÛŒÙ‚ Ø¨Ø§ ÙÛŒÙ„ØªØ± Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒØ§Ù†
                print(f"  ğŸ” Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¹Ù…ÛŒÙ‚ Ø¨Ø§ ÙÛŒÙ„ØªØ± Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒØ§Ù†")
                for depth in range(2, max_depth + 1):
                    for relation in expression_relations:
                        dfs_results = self.dfs_search(node_id, depth, relation_filter=relation)
                        for gene_node, gene_depth in dfs_results:
                            if self.G.nodes[gene_node]['kind'] == 'Gene':
                                gene_name = self.G.nodes[gene_node]['name']
                                score = 4.0 / gene_depth  # Ú©Ø§Ù‡Ø´ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¹Ù…Ù‚
                                explanation = f"{gene_name} related to {anatomy_name} via {relation} (depth {gene_depth})"
                                results.append((gene_node, gene_depth, score, explanation))
                                print(f"    âœ… {gene_name} - Ø¹Ù…Ù‚ {gene_depth} Ø¨Ø§ Ø±Ø§Ø¨Ø·Ù‡ {relation} (Ø§Ù…ØªÛŒØ§Ø²: {score:.2f})")
        
        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø²
        unique_results = {}
        for node_id, depth, score, explanation in results:
            if node_id not in unique_results or score > unique_results[node_id][1]:
                unique_results[node_id] = (depth, score, explanation)
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø²
        sorted_results = sorted(unique_results.items(), key=lambda x: x[1][1], reverse=True)
        
        final_results = [(node_id, depth, score, explanation) for node_id, (depth, score, explanation) in sorted_results]
        
        print(f"ğŸ“Š Ù…Ø¬Ù…ÙˆØ¹ {len(final_results)} Ú˜Ù† Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ ÛŒØ§ÙØª Ø´Ø¯")
        return final_results
    
    # def _add_node_if_not_exists(self, node_id: str):
    #     """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†ÙˆØ¯ Ø¨Ù‡ Ú¯Ø±Ø§Ù Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯"""
    #     if not self.G.has_node(node_id):
    #         # Ø§ÛŒØ¬Ø§Ø¯ Ù†ÙˆØ¯ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
    #         self.G.add_node(node_id, name=node_id, kind='Unknown')
    #         print(f"  â• Ù†ÙˆØ¯ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯: {node_id}")
    
    # def _add_edge_if_not_exists(self, source: str, target: str, relation: str = 'Unknown'):
    #     """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÛŒØ§Ù„ Ø¨Ù‡ Ú¯Ø±Ø§Ù Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯"""
    #     if not self.G.has_edge(source, target):
    #         self.G.add_edge(source, target, metaedge=relation, relation=relation)
    #         print(f"  â• ÛŒØ§Ù„ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯: {source} â†’ {target} ({relation})")
    
    def _search_anatomy_expression(self, matched_nodes: Dict[str, str], intent: Dict, max_depth: int) -> List[Tuple[str, int, float, str]]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¨ÛŒØ§Ù† Ú˜Ù† Ø¯Ø± Ø¢Ù†Ø§ØªÙˆÙ…ÛŒ Ø¨Ø§ ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø±ÙˆØ§Ø¨Ø· AeG (Anatomy â†’ expresses â†’ Gene)"""
        results = []
        
        for token, node_id in matched_nodes.items():
            if self.G.nodes[node_id]['kind'] == 'Anatomy':
                anatomy_name = self.G.nodes[node_id]['name']
                print(f"ğŸ” Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¨ÛŒØ§Ù† Ú˜Ù† Ø¯Ø± {anatomy_name} Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø§Ø¨Ø·Ù‡ AeG")
                
                # Ø±ÙˆØ´ 1: ÛŒØ§ÙØªÙ† Ù…Ø³ØªÙ‚ÛŒÙ… Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ§Ù† Ø´Ø¯Ù‡ (Anatomy â†’ expresses â†’ Gene)
                for neighbor in self.G.neighbors(node_id):
                    if self.G.nodes[neighbor]['kind'] == 'Gene':
                        edge_data = self.G.get_edge_data(node_id, neighbor)
                        if edge_data and edge_data.get('metaedge') == 'AeG':
                            results.append((neighbor, 1, 5.0, f"{self.G.nodes[neighbor]['name']} expressed in {anatomy_name}"))
                            print(f"  âœ… {self.G.nodes[neighbor]['name']} - Ø¨ÛŒØ§Ù† Ù…Ø³ØªÙ‚ÛŒÙ… Ø¯Ø± {anatomy_name} (AeG)")
                
                # Ø±ÙˆØ´ 2: Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ú©ÙˆØ³ (Gene â†’ expresses â†’ Anatomy) - Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
                for gene_node, gene_attrs in self.G.nodes(data=True):
                    if gene_attrs.get('kind') == 'Gene':
                        for neighbor in self.G.neighbors(gene_node):
                            if neighbor == node_id:
                                edge_data = self.G.get_edge_data(gene_node, neighbor)
                                if edge_data and edge_data.get('metaedge') == 'GeA':
                                    results.append((gene_node, 1, 4.5, f"{gene_attrs['name']} expressed in {anatomy_name}"))
                                    print(f"  âœ… {gene_attrs['name']} - Ø¨ÛŒØ§Ù† Ù…Ø¹Ú©ÙˆØ³ Ø¯Ø± {anatomy_name} (GeA)")
                
                # Ø±ÙˆØ´ 3: Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¹Ù…ÛŒÙ‚ Ø¨Ø§ ÙÛŒÙ„ØªØ± Ø¯Ù‚ÛŒÙ‚ AeG
                for depth in range(2, max_depth + 1):
                    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² DFS Ø¨Ø§ ÙÛŒÙ„ØªØ± Ø¯Ù‚ÛŒÙ‚
                    dfs_results = self.dfs_search(node_id, depth, relation_filter='AeG')
                    for gene_node, gene_depth in dfs_results:
                        if self.G.nodes[gene_node]['kind'] == 'Gene':
                            score = 4.0 / gene_depth
                            results.append((gene_node, gene_depth, score, f"{self.G.nodes[gene_node]['name']} expressed in {anatomy_name} (depth {gene_depth})"))
                            print(f"  âœ… {self.G.nodes[gene_node]['name']} - Ø¹Ù…Ù‚ {gene_depth} (AeG)")
                
                # Ø±ÙˆØ´ 4: Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± Ù†Ø§Ù…â€ŒÙ‡Ø§ (Ø¨Ø±Ø§ÛŒ Ù‚Ù„Ø¨)
                if 'heart' in token.lower() or 'heart' in anatomy_name.lower():
                    for gene_node, gene_attrs in self.G.nodes(data=True):
                        if gene_attrs.get('kind') == 'Gene':
                            gene_name = gene_attrs['name'].lower()
                            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù‚Ù„Ø¨
                            if any(keyword in gene_name for keyword in ['cardiac', 'heart', 'myocardial', 'cardio']):
                                results.append((gene_node, 2, 3.5, f"Ú˜Ù† Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù‚Ù„Ø¨: {gene_attrs['name']}"))
                                print(f"  âœ… {gene_attrs['name']} - Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù‚Ù„Ø¨")
        
        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø²
        unique_results = {}
        for node_id, depth, score, reason in results:
            if node_id not in unique_results or score > unique_results[node_id][1]:
                unique_results[node_id] = (depth, score, reason)
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø²
        sorted_results = sorted(unique_results.items(), key=lambda x: x[1][1], reverse=True)
        
        return [(node_id, depth, score, reason) for node_id, (depth, score, reason) in sorted_results]
    
    def _search_disease_related(self, matched_nodes: Dict[str, str], intent: Dict, max_depth: int) -> List[Tuple[str, int, float, str]]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§"""
        results = []
        
        for token, node_id in matched_nodes.items():
            if self.G.nodes[node_id]['kind'] == 'Disease':
                # ÛŒØ§ÙØªÙ† Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¨ÛŒÙ…Ø§Ø±ÛŒ
                for neighbor in self.G.neighbors(node_id):
                    if self.G.nodes[neighbor]['kind'] == 'Gene':
                        edge_data = self.G.get_edge_data(node_id, neighbor)
                        if edge_data:
                            results.append((neighbor, 1, 5.0, f"Ù…Ø±ØªØ¨Ø· Ø¨Ø§ {self.G.nodes[node_id]['name']}"))
                
                # ÛŒØ§ÙØªÙ† Ø¯Ø§Ø±ÙˆÙ‡Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†ÛŒ
                for neighbor in self.G.neighbors(node_id):
                    if self.G.nodes[neighbor]['kind'] == 'Drug':
                        edge_data = self.G.get_edge_data(node_id, neighbor)
                        if edge_data and 'treats' in edge_data.get('metaedge', ''):
                            results.append((neighbor, 1, 4.5, f"Ø¯Ø±Ù…Ø§Ù† {self.G.nodes[node_id]['name']}"))
                
                # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¹Ù…ÛŒÙ‚â€ŒØªØ±
                for depth in range(2, max_depth + 1):
                    for path in nx.single_source_shortest_path(self.G, node_id, cutoff=depth).values():
                        if len(path) == depth + 1:
                            target_node = path[-1]
                            score = 4.0 / depth
                            results.append((target_node, depth, score, f"Ù…Ø³ÛŒØ± {depth} Ø³Ø·Ø­ÛŒ"))
        
        return results
    
    def _search_drug_related(self, matched_nodes: Dict[str, str], intent: Dict, max_depth: int) -> List[Tuple[str, int, float, str]]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¯Ø§Ø±ÙˆÙ‡Ø§"""
        results = []
        
        for token, node_id in matched_nodes.items():
            if self.G.nodes[node_id]['kind'] == 'Drug':
                # ÛŒØ§ÙØªÙ† Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§ÛŒÙ† Ø¯Ø§Ø±Ùˆ Ø¯Ø±Ù…Ø§Ù† Ù…ÛŒâ€ŒÚ©Ù†Ø¯
                for neighbor in self.G.neighbors(node_id):
                    if self.G.nodes[neighbor]['kind'] == 'Disease':
                        edge_data = self.G.get_edge_data(node_id, neighbor)
                        if edge_data and 'treats' in edge_data.get('metaedge', ''):
                            results.append((neighbor, 1, 5.0, f"Ø¯Ø±Ù…Ø§Ù† Ø´Ø¯Ù‡ ØªÙˆØ³Ø· {self.G.nodes[node_id]['name']}"))
                
                # ÛŒØ§ÙØªÙ† Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù‡Ø¯Ù
                for neighbor in self.G.neighbors(node_id):
                    if self.G.nodes[neighbor]['kind'] == 'Gene':
                        edge_data = self.G.get_edge_data(node_id, neighbor)
                        if edge_data:
                            results.append((neighbor, 1, 4.5, f"Ù‡Ø¯Ù {self.G.nodes[node_id]['name']}"))
        
        return results
    
    def _search_gene_function(self, matched_nodes: Dict[str, str], intent: Dict, max_depth: int) -> List[Tuple[str, int, float, str]]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ú˜Ù†â€ŒÙ‡Ø§"""
        results = []
        
        for token, node_id in matched_nodes.items():
            if self.G.nodes[node_id]['kind'] == 'Gene':
                # ÛŒØ§ÙØªÙ† ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ù…Ø±ØªØ¨Ø·
                for neighbor in self.G.neighbors(node_id):
                    if self.G.nodes[neighbor]['kind'] == 'Biological_Process':
                        edge_data = self.G.get_edge_data(node_id, neighbor)
                        if edge_data:
                            results.append((neighbor, 1, 4.5, f"ÙØ±Ø¢ÛŒÙ†Ø¯ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ {self.G.nodes[node_id]['name']}"))
                
                # ÛŒØ§ÙØªÙ† Ú˜Ù†â€ŒÙ‡Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ
                for neighbor in self.G.neighbors(node_id):
                    if self.G.nodes[neighbor]['kind'] == 'Gene':
                        edge_data = self.G.get_edge_data(node_id, neighbor)
                        if edge_data and 'interacts_with' in edge_data.get('metaedge', ''):
                            results.append((neighbor, 1, 4.0, f"ØªØ¹Ø§Ù…Ù„ Ø¨Ø§ {self.G.nodes[node_id]['name']}"))
        
        return results
    
    def _search_general(self, matched_nodes: Dict[str, str], intent: Dict, max_depth: int) -> List[Tuple[str, int, float, str]]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¹Ù…ÙˆÙ…ÛŒ"""
        results = []
        
        for token, node_id in matched_nodes.items():
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§
            for neighbor in self.G.neighbors(node_id):
                score = 4.0
                results.append((neighbor, 1, score, f"Ù‡Ù…Ø³Ø§ÛŒÙ‡ {self.G.nodes[node_id]['name']}"))
            
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¹Ù…ÛŒÙ‚â€ŒØªØ±
            for depth in range(2, max_depth + 1):
                for path in nx.single_source_shortest_path(self.G, node_id, cutoff=depth).values():
                    if len(path) == depth + 1:
                        target_node = path[-1]
                        score = 3.0 / depth
                        results.append((target_node, depth, score, f"Ù…Ø³ÛŒØ± {depth} Ø³Ø·Ø­ÛŒ"))
        
        return results
    
    def match_tokens_to_nodes(self, tokens: List[str]) -> Dict[str, str]:
        """ØªØ·Ø¨ÛŒÙ‚ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¨Ø§ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ú¯Ø±Ø§Ù Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² ØªØ·Ø¨ÛŒÙ‚ Ù†ÙˆØ¹ Ù…ÙˆØ¬ÙˆØ¯ÛŒØª Ø¨Ø± Ø§Ø³Ø§Ø³ Hetionet"""
        matched = {}
        
        # Ù†Ú¯Ø§Ø´Øª Ú©Ø§Ù…Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ metanodes Hetionet
        fallback_kinds = {
            # Gene (20945 nodes)
            'gene': 'Gene', 'genes': 'Gene', 'protein': 'Gene', 'proteins': 'Gene',
            'dna': 'Gene', 'rna': 'Gene', 'mrna': 'Gene', 'genetic': 'Gene',
            
            # Anatomy (402 nodes)
            'anatomy': 'Anatomy', 'anatomical': 'Anatomy', 'organ': 'Anatomy', 'organs': 'Anatomy',
            'tissue': 'Anatomy', 'tissues': 'Anatomy', 'body': 'Anatomy', 'body part': 'Anatomy',
            'heart': 'Anatomy', 'brain': 'Anatomy', 'liver': 'Anatomy', 'lung': 'Anatomy',
            'kidney': 'Anatomy', 'stomach': 'Anatomy', 'muscle': 'Anatomy', 'bone': 'Anatomy',
            'blood': 'Anatomy',
            
            # Disease (137 nodes)
            'disease': 'Disease', 'diseases': 'Disease', 'disorder': 'Disease', 'disorders': 'Disease',
            'syndrome': 'Disease', 'syndromes': 'Disease', 'cancer': 'Disease', 'cancers': 'Disease',
            'tumor': 'Disease', 'tumors': 'Disease', 'malignancy': 'Disease', 'malignancies': 'Disease',
            'diabetes': 'Disease', 'alzheimer': 'Disease', 'fibrosis': 'Disease',
            'breast cancer': 'Disease', 'lung cancer': 'Disease', 'liver cancer': 'Disease',
            'brain cancer': 'Disease', 'blood cancer': 'Disease', 'stomach cancer': 'Disease',
            
            # Compound (1552 nodes)
            'compound': 'Compound', 'compounds': 'Compound', 'drug': 'Compound', 'drugs': 'Compound',
            'medication': 'Compound', 'medications': 'Compound', 'medicine': 'Compound', 'medicines': 'Compound',
            'chemical': 'Compound', 'chemicals': 'Compound', 'molecule': 'Compound', 'molecules': 'Compound',
            'aspirin': 'Compound', 'ibuprofen': 'Compound', 'caffeine': 'Compound', 'vitamin': 'Compound',
            
            # Biological Process (11381 nodes)
            'process': 'Biological Process', 'processes': 'Biological Process', 'biological': 'Biological Process',
            'pathway': 'Biological Process', 'pathways': 'Biological Process', 'mechanism': 'Biological Process',
            'function': 'Biological Process', 'functions': 'Biological Process', 'activity': 'Biological Process',
            'apoptosis': 'Biological Process', 'cell cycle': 'Biological Process', 'dna repair': 'Biological Process',
            
            # Pathway (1822 nodes)
            'pathway': 'Pathway', 'pathways': 'Pathway', 'signaling': 'Pathway', 'metabolic': 'Pathway',
            'cascade': 'Pathway', 'cascades': 'Pathway', 'network': 'Pathway', 'networks': 'Pathway',
            
            # Symptom (438 nodes)
            'symptom': 'Symptom', 'symptoms': 'Symptom', 'sign': 'Symptom', 'signs': 'Symptom',
            'manifestation': 'Symptom', 'manifestations': 'Symptom', 'indication': 'Symptom',
            'pain': 'Symptom', 'fever': 'Symptom', 'cough': 'Symptom', 'fatigue': 'Symptom',
            
            # Side Effect (5734 nodes)
            'side effect': 'Side Effect', 'side effects': 'Side Effect', 'adverse': 'Side Effect',
            'reaction': 'Side Effect', 'reactions': 'Side Effect', 'toxicity': 'Side Effect',
            'nausea': 'Side Effect', 'headache': 'Side Effect', 'dizziness': 'Side Effect',
            
            # Molecular Function (2884 nodes)
            'molecular': 'Molecular Function', 'function': 'Molecular Function', 'functions': 'Molecular Function',
            'activity': 'Molecular Function', 'activities': 'Molecular Function', 'enzymatic': 'Molecular Function',
            'enzyme': 'Molecular Function', 'receptor': 'Molecular Function', 'transporter': 'Molecular Function',
            
            # Cellular Component (1391 nodes)
            'cellular': 'Cellular Component', 'component': 'Cellular Component', 'components': 'Cellular Component',
            'organelle': 'Cellular Component', 'organelles': 'Cellular Component', 'structure': 'Cellular Component',
            'nucleus': 'Cellular Component', 'mitochondria': 'Cellular Component', 'membrane': 'Cellular Component',
            
            # Pharmacologic Class (345 nodes)
            'pharmacologic': 'Pharmacologic Class', 'pharmacological': 'Pharmacologic Class', 'class': 'Pharmacologic Class',
            'category': 'Pharmacologic Class', 'categories': 'Pharmacologic Class', 'type': 'Pharmacologic Class',
            'nsaid': 'Pharmacologic Class', 'antibiotic': 'Pharmacologic Class', 'antihypertensive': 'Pharmacologic Class'
        }
        
        # Ù†Ú¯Ø§Ø´Øª Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ù‡ÙˆØ± Ùˆ Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¢Ù†Ù‡Ø§
        famous_genes = {
            'tp53': ['TP53', 'P53', 'p53', 'Tumor Protein P53', 'Tumor Suppressor P53'],
            'brca1': ['BRCA1', 'Breast Cancer 1', 'BRCA1 Gene'],
            'brca2': ['BRCA2', 'Breast Cancer 2', 'BRCA2 Gene'],
            'apoe': ['APOE', 'Apolipoprotein E', 'APOE Gene'],
            'cftr': ['CFTR', 'Cystic Fibrosis Transmembrane Conductance Regulator'],
            'mmp9': ['MMP9', 'Matrix Metallopeptidase 9'],
            'bid': ['BID', 'BH3 Interacting Domain Death Agonist'],
            'kcnq2': ['KCNQ2', 'Potassium Voltage-Gated Channel Subfamily Q Member 2'],
            'hmgb3': ['HMGB3', 'High Mobility Group Box 3']
        }
        
        for token in tokens:
            token_lower = token.lower()
            found = False
            
            # Ø±ÙˆØ´ 1: ØªØ·Ø¨ÛŒÙ‚ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ù‡ÙˆØ±
            if token_lower in famous_genes:
                gene_variants = famous_genes[token_lower]
                # Ø§Ø¨ØªØ¯Ø§ ØªØ·Ø¨ÛŒÙ‚ Ø¯Ù‚ÛŒÙ‚ Ù†Ø§Ù… Ú©Ø§Ù…Ù„ Ú˜Ù†ØŒ Ø³Ù¾Ø³ ØªØ·Ø¨ÛŒÙ‚â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ù…Ù„
                for node_id, attrs in self.G.nodes(data=True):
                    if attrs.get('kind') == 'Gene' and attrs.get('name', '').upper() == 'TP53' and token_lower == 'tp53':
                        matched[token] = node_id
                        found = True
                        print(f"ğŸ” ØªØ·Ø¨ÛŒÙ‚ Ú˜Ù† Ù…Ø´Ù‡ÙˆØ± (Ù‚ÙÙ„ Ø¯Ù‚ÛŒÙ‚): '{token}' -> {attrs['name']} ({attrs.get('kind', 'Unknown')})")
                        break
                if not found:
                    for variant in gene_variants:
                        for node_id, attrs in self.G.nodes(data=True):
                            if (attrs.get('kind') == 'Gene' and 
                                variant.upper() == attrs.get('name', '').upper()):
                                matched[token] = node_id
                                found = True
                                print(f"ğŸ” ØªØ·Ø¨ÛŒÙ‚ Ú˜Ù† Ù…Ø´Ù‡ÙˆØ± (Ø¯Ù‚ÛŒÙ‚): '{token}' -> {attrs['name']} ({attrs.get('kind', 'Unknown')})")
                                break
                        if found:
                            break
                if not found:
                    for variant in gene_variants:
                        for node_id, attrs in self.G.nodes(data=True):
                            if (attrs.get('kind') == 'Gene' and 
                                variant.upper() in attrs.get('name', '').upper()):
                                matched[token] = node_id
                                found = True
                                print(f"ğŸ” ØªØ·Ø¨ÛŒÙ‚ Ú˜Ù† Ù…Ø´Ù‡ÙˆØ± (Ø´Ø§Ù…Ù„): '{token}' -> {attrs['name']} ({attrs.get('kind', 'Unknown')})")
                                break
                        if found:
                            break
                    if found:
                        break
            
            # Ø±ÙˆØ´ 2: Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø§Ù…
            if not found:
                import re
                gene_symbol_like = bool(re.fullmatch(r"[A-Za-z0-9\-]{2,10}", token)) and sum(1 for c in token if c.isalpha() and c.isupper()) >= 2
                for node_id, attrs in self.G.nodes(data=True):
                    name = attrs.get('name', '')
                    name_lower = name.lower()
                    # Ø§Ú¯Ø± Ø´Ø¨ÛŒÙ‡ Ù†Ù…Ø§Ø¯ Ú˜Ù†ÛŒ Ø§Ø³ØªØŒ Ø¨Ø±Ø§ÛŒ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Gene ÙÙ‚Ø· ØªØ·Ø¨ÛŒÙ‚ Ø¯Ù‚ÛŒÙ‚ Ø±Ø§ Ù‚Ø¨ÙˆÙ„ Ú©Ù†
                    if gene_symbol_like and attrs.get('kind') == 'Gene':
                        if name_upper := name.upper():
                            if token.upper() == name_upper:
                                matched[token] = node_id
                                found = True
                                print(f"ğŸ” ØªØ·Ø¨ÛŒÙ‚ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ú˜Ù†: '{token}' -> {name}")
                                break
                        continue  # Ø§Ø² ØªØ·Ø¨ÛŒÙ‚â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ù…Ù„ Ù…Ø«Ù„ TP53RK Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ú©Ù†
                    # Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØ± Ø§Ù†ÙˆØ§Ø¹ØŒ ØªØ·Ø¨ÛŒÙ‚ Ø´Ø§Ù…Ù„ Ù…Ø¬Ø§Ø² Ø§Ø³Øª
                    if token_lower in name_lower:
                        matched[token] = node_id
                        found = True
                        print(f"ğŸ” ØªØ·Ø¨ÛŒÙ‚ Ù…Ø³ØªÙ‚ÛŒÙ…: '{token}' -> {name} ({attrs.get('kind', 'Unknown')})")
                        break
            
            # Ø±ÙˆØ´ 3: Ø¬Ø³ØªØ¬ÙˆÛŒ ÙØ§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ù„Ù…Ø§Øª Ù…Ø´Ø§Ø¨Ù‡ (Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø§ Ø§ÛŒÙ†Ø¯Ú©Ø³)
            if not found and len(token) >= 3:
                # 3.1 ØªØ·Ø¨ÛŒÙ‚ Ø¯Ù‚ÛŒÙ‚ Ø§Ø² Ø§ÛŒÙ†Ø¯Ú©Ø³ Ù†Ø§Ù…â€ŒÙ‡Ø§
                if token_lower in self._name_to_ids:
                    matched[token] = self._name_to_ids[token_lower][0]
                    found = True
                else:
                    # 3.2 Ø´Ø§Ù…Ù„ Ø¨ÙˆØ¯Ù† Ø³Ø¨Ú© Ø±ÙˆÛŒ ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ†Ø¯Ú©Ø³â€ŒØ´Ø¯Ù‡ (Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø§ÛŒÛŒ)
                    limit_scan = min(len(self._name_entries), 10000)
                    for name_lower, node_id in self._name_entries[:limit_scan]:
                        if token_lower in name_lower:
                            matched[token] = node_id
                            found = True
                            break
            
            # Ø±ÙˆØ´ 3: Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ù…ÙˆØ¬ÙˆØ¯ÛŒØª
            if not found and token_lower in fallback_kinds:
                kind = fallback_kinds[token_lower]
                candidates = [(nid, attrs) for nid, attrs in self.G.nodes(data=True)
                            if attrs.get('kind') == kind or attrs.get('metanode') == kind]
                
                if candidates:
                    # Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ú©Ø§Ù†Ø¯ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø¨Ø§Ù‡Øª Ù†Ø§Ù…
                    best_candidate = None
                    best_score = 0
                    
                    for nid, attrs in candidates:
                        name_lower = attrs['name'].lower()
                        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø´Ø¨Ø§Ù‡Øª
                        if token_lower in name_lower:
                            score = len(token_lower) / len(name_lower)
                        elif any(word in name_lower for word in token_lower.split()):
                            score = 0.5
                        else:
                            score = 0.1
                        
                        if score > best_score:
                            best_score = score
                            best_candidate = (nid, attrs)
                    
                    if best_candidate:
                        matched[token] = best_candidate[0]
                        print(f"ğŸ” ØªØ·Ø¨ÛŒÙ‚ Ù†ÙˆØ¹ Ù…ÙˆØ¬ÙˆØ¯ÛŒØª: '{token}' -> {kind} (Ù†Ù…ÙˆÙ†Ù‡: {best_candidate[1]['name']})")
                        found = True
            
            # Ø±ÙˆØ´ 4: Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¬Ø²Ø¦ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ù„Ù…Ø§Øª Ú†Ù†Ø¯Ø¨Ø®Ø´ÛŒ
            if not found and ' ' in token_lower:
                words = token_lower.split()
                for node_id, attrs in self.G.nodes(data=True):
                    name_lower = attrs['name'].lower()
                    if all(word in name_lower for word in words):
                        matched[token] = node_id
                        found = True
                        print(f"ğŸ” ØªØ·Ø¨ÛŒÙ‚ Ø¬Ø²Ø¦ÛŒ: '{token}' -> {attrs['name']} ({attrs.get('kind', 'Unknown')})")
                        break
            
            # Ø±ÙˆØ´ 5: ØªØ·Ø¨ÛŒÙ‚ Ú©Ù„Ù…Ø§Øª ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡
            if not found and any('\u0600' <= c <= '\u06FF' for c in token):  # Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
                # Ù†Ú¯Ø§Ø´Øª Ú©Ù„Ù…Ø§Øª ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ø¨Ù‡ØªØ±
                persian_mapping = {
                    'Ø³Ø±Ø·Ø§Ù†': 'cancer',
                    'Ú©Ø¨Ø¯': 'liver', 
                    'Ù…ØºØ²': 'brain',
                    'Ù‚Ù„Ø¨': 'heart',
                    'Ø±ÛŒÙ‡': 'lung',
                    'Ú©Ù„ÛŒÙ‡': 'kidney',
                    'Ù…Ø¹Ø¯Ù‡': 'stomach',
                    'Ù…Ø§Ù‡ÛŒÚ†Ù‡': 'muscle',
                    'Ø§Ø³ØªØ®ÙˆØ§Ù†': 'bone',
                    'Ø®ÙˆÙ†': 'blood',
                    'Ø¨Ø§ÙØª': 'tissue',
                    'Ø§Ù†Ø¯Ø§Ù…': 'organ',
                    'Ø¨Ø¯Ù†': 'body',
                    'Ø¨ÛŒÙ…Ø§Ø±ÛŒ': 'disease',
                    'Ø¯Ø§Ø±Ùˆ': 'drug',
                    'Ø¢Ø³Ù¾Ø±ÛŒÙ†': 'aspirin',
                    'Ú˜Ù†': 'gene',
                    'Ù¾Ø±ÙˆØªØ¦ÛŒÙ†': 'protein',
                    'ÙØ±Ø¢ÛŒÙ†Ø¯': 'process',
                    'Ø¢Ù¾ÙˆÙ¾ØªÙˆØ²': 'apoptosis'
                }
                
                if token in persian_mapping:
                    english_word = persian_mapping[token]
                    # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù†ÙˆØ¯ Ø¨Ø§ Ù†Ø§Ù… Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
                    for node_id, attrs in self.G.nodes(data=True):
                        if english_word in attrs['name'].lower():
                            matched[token] = node_id
                            found = True
                            print(f"ğŸ” ØªØ·Ø¨ÛŒÙ‚ ÙØ§Ø±Ø³ÛŒ-Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ: '{token}' -> {attrs['name']} ({attrs.get('kind', 'Unknown')})")
                            break
            
            # Ø±ÙˆØ´ 5: Ø¬Ø³ØªØ¬ÙˆÛŒ ÙØ§Ø²ÛŒ ÙˆÛŒÚ˜Ù‡ Ú˜Ù†â€ŒÙ‡Ø§ Ø¨Ø§ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ù†ÙˆØ¹
            if not found and len(token) >= 3 and 'Gene' in self._kind_to_ids:
                for node_id in self._kind_to_ids['Gene'][: min(5000, len(self._kind_to_ids['Gene']))]:
                    attrs = self.G.nodes[node_id]
                    name_lower = attrs.get('name', '').lower()
                    if not name_lower:
                        continue
                    if (token_lower in name_lower or name_lower in token_lower or any(word in name_lower for word in token_lower.split())):
                        matched[token] = node_id
                        found = True
                        break
            
            if not found:
                print(f"âŒ ØªØ·Ø¨ÛŒÙ‚ Ù†Ø´Ø¯: '{token}'")
        
        return matched

    def _preferred_core_kinds_for_question(self, question_type: str) -> List[str]:
        mapping = {
            'biological_participation': ['Gene', 'Pathway', 'Biological Process'],
            'gene_interaction': ['Gene'],
            'disease_gene_regulation': ['Gene', 'Disease'],
            'disease_treatment': ['Disease', 'Compound'],
            'compound_gene_regulation': ['Gene', 'Compound'],
            'anatomy_expression': ['Anatomy', 'Gene'],
            'anatomy_disease': ['Disease', 'Anatomy'],
            'gene_pathway': ['Gene', 'Pathway'],
            'gene_regulation': ['Gene'],
            'gene_covariation': ['Gene'],
            'disease_symptom': ['Disease', 'Symptom'],
            'disease_similarity': ['Disease'],
        }
        return mapping.get(question_type, ['Gene', 'Disease', 'Pathway'])

    def _extract_core_nodes(self, query: str, matched_nodes: Dict[str, str], intent: Dict[str, Any]) -> List[str]:
        """Ø§Ù†ØªØ®Ø§Ø¨ Ù‡Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³ÙˆØ§Ù„ØŒ Ù†ÛŒØª Ùˆ ØªØ·Ø¨ÛŒÙ‚â€ŒÙ‡Ø§.
        Ù‚ÙˆØ§Ø¹Ø¯:
        - Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡ Ú˜Ù†ØŒ ÙÙ‚Ø· ØªØ·Ø¨ÛŒÙ‚ Ø¯Ù‚ÛŒÙ‚ Ù†Ø§Ù… Ú˜Ù† Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† Ù‡Ø³ØªÙ‡ Ù¾Ø°ÛŒØ±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        - Ø§Ù†ÙˆØ§Ø¹ Ù‡Ø³ØªÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„ Ù…Ø­Ø¯ÙˆØ¯ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
        - Ø¯Ø± ØµÙˆØ±Øª Ù†Ø¨ÙˆØ¯ ØªØ·Ø¨ÛŒÙ‚ Ø¯Ù‚ÛŒÙ‚ØŒ Ø§Ø² ØªØ·Ø¨ÛŒÙ‚â€ŒÙ‡Ø§ÛŒ Ø¹Ø¨Ø§Ø±ØªÛŒ Ú©Ø§Ù…Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        """
        ql = (query or '').lower()
        tokens = set([t.strip() for t in re.split(r"[^A-Za-z0-9]+", ql) if t.strip()])
        preferred_kinds = set(self._preferred_core_kinds_for_question(intent.get('question_type', 'general')))

        core_nodes: List[str] = []
        # Ù…Ø±Ø­Ù„Ù‡ 1: ØªØ·Ø¨ÛŒÙ‚ Ø¯Ù‚ÛŒÙ‚ Ù†Ù…Ø§Ø¯ Ú˜Ù†
        for token, node_id in matched_nodes.items():
            attrs = self.G.nodes[node_id]
            name = attrs.get('name', '')
            kind = attrs.get('kind')
            # ÙÙ‚Ø· Ø§Ù†ÙˆØ§Ø¹ ØªØ±Ø¬ÛŒØ­ÛŒ
            if kind not in preferred_kinds:
                continue
            # Ú˜Ù†: Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØ·Ø¨ÛŒÙ‚ Ø¯Ù‚ÛŒÙ‚ Ù†Ù…Ø§Ø¯
            if kind == 'Gene':
                gene_symbol_like = bool(re.fullmatch(r"[A-Za-z0-9\-]{2,10}", token)) and sum(1 for c in token if c.isalpha() and c.isupper()) >= 2
                if gene_symbol_like and token.upper() == name.upper():
                    core_nodes.append(node_id)
            else:
                # ØºÛŒØ± Ú˜Ù†: ØªØ·Ø¨ÛŒÙ‚ Ø¹ÛŒÙ† Ø¹Ø¨Ø§Ø±Øª Ú©Ø§Ù…Ù„
                if token == name.lower():
                    core_nodes.append(node_id)

        # Ù…Ø±Ø­Ù„Ù‡ 2: Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯ØŒ Ø§Ø² Ù‚ÛŒØ¯ Ø¹Ø¨Ø§Ø±Øª Ú©Ø§Ù…Ù„ Ø¯Ø± Ù…ØªÙ† Ø³ÙˆØ§Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        if not core_nodes:
            for token, node_id in matched_nodes.items():
                attrs = self.G.nodes[node_id]
                kind = attrs.get('kind')
                name_lower = attrs.get('name', '').lower()
                if kind in preferred_kinds and name_lower in ql:
                    # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø­Ø§Ù„Ø§Øª Ø­Ø§ÙˆÛŒ Ù¾Ø³ÙˆÙ†Ø¯/Ù¾ÛŒØ´ÙˆÙ†Ø¯ Ø¨Ø±Ø§ÛŒ Ú˜Ù†â€ŒÙ‡Ø§
                    if kind == 'Gene':
                        continue
                    core_nodes.append(node_id)

        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø¨Ø§ Ø­ÙØ¸ ØªØ±ØªÛŒØ¨
        seen = set()
        unique_core_nodes = []
        for nid in core_nodes:
            if nid not in seen:
                seen.add(nid)
                unique_core_nodes.append(nid)
        return unique_core_nodes
    
    def bfs_search(self, start_node: str, max_depth: int = 2) -> List[Tuple[str, int]]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø·Ø­ Ø§ÙˆÙ„"""
        visited = set()
        queue = deque([(start_node, 0)])
        result = []
        
        while queue:
            node, depth = queue.popleft()
            if node in visited or depth > max_depth:
                continue
            visited.add(node)
            result.append((node, depth))
            # ÙÛŒÙ„ØªØ± ÛŒØ§Ù„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ù‡ÛŒØ² Ø§Ø² Ù†ÙˆÛŒØ²: ÙÙ‚Ø· ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø±Ø§ÛŒ metaedge/relation Ù…Ø¹ØªØ¨Ø±
            for neighbor in self.G.neighbors(node):
                ed = self.G.get_edge_data(node, neighbor) or {}
                if not ed.get('metaedge') and not ed.get('relation'):
                    continue
                if neighbor not in visited:
                    queue.append((neighbor, depth + 1))
        
        return result
    
    def dfs_search(self, start_node: str, max_depth: int = 2, relation_filter: str = None) -> List[Tuple[str, int]]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¹Ù…ÛŒÙ‚ Ø§ÙˆÙ„ Ø¨Ø§ Ø§Ù…Ú©Ø§Ù† ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø±Ø§Ø¨Ø·Ù‡"""
        visited = set()
        result = []
        
        def dfs(node, depth):
            if depth > max_depth or node in visited:
                return
            visited.add(node)
            result.append((node, depth))
            
            for neighbor in self.G.neighbors(node):
                if neighbor not in visited:
                    # Ø§Ú¯Ø± ÙÛŒÙ„ØªØ± Ø±Ø§Ø¨Ø·Ù‡ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ØŒ ÙÙ‚Ø· ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†
                    edge_data = self.G.get_edge_data(node, neighbor) or {}
                    if relation_filter:
                        rel = (edge_data.get('relation') or edge_data.get('metaedge') or '').lower()
                        if relation_filter.lower() not in rel:
                            continue
                    # Ø­Ø°Ù ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ù…ØªØ§Ø¯Ø§Ø¯Ù‡
                    if not edge_data.get('relation') and not edge_data.get('metaedge'):
                        continue
                    dfs(neighbor, depth + 1)
        
        dfs(start_node, 0)
        return result
    
    def get_shortest_paths(self, source: str, target: str, max_paths: int = 3) -> List[List[str]]:
        """ÛŒØ§ÙØªÙ† Ú©ÙˆØªØ§Ù‡â€ŒØªØ±ÛŒÙ† Ù…Ø³ÛŒØ±Ù‡Ø§"""
        try:
            paths = list(nx.all_shortest_paths(self.G, source=source, target=target))
            return paths[:max_paths]
        except nx.NetworkXNoPath:
            return []
    
    def get_neighbors_by_type(self, node_id: str, kind_filter: str = None) -> List[Tuple[str, str]]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹"""
        neighbors = []
        for neighbor in self.G.neighbors(node_id):
            kind = self.G.nodes[neighbor].get('kind')
            if kind_filter is None or kind == kind_filter:
                neighbors.append((neighbor, self.G.nodes[neighbor]['name']))
        return neighbors
    
    def hybrid_search(self, nodes: List[str], max_depth: int = 2) -> List[Tuple[str, int]]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ"""
        all_results = []
        for node in nodes:
            bfs_result = self.bfs_search(node, max_depth)
            all_results.extend(bfs_result)
        
        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù…Ù‚
        unique_results = {}
        for node, depth in all_results:
            if node not in unique_results or depth < unique_results[node]:
                unique_results[node] = depth
        
        return sorted(unique_results.items(), key=lambda x: x[1])
    
    def multi_method_search(self, nodes: List[str], max_depth: int = 2) -> List[Tuple[str, int, str]]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ú†Ù†Ø¯ Ø±ÙˆØ´ÛŒ - ØªØ±Ú©ÛŒØ¨ BFSØŒ DFSØŒ Ùˆ Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§"""
        all_results = []
        
        for node in nodes:
            # BFS
            bfs_result = self.bfs_search(node, max_depth)
            for n, depth in bfs_result:
                all_results.append((n, depth, 'BFS'))
            
            # DFS
            dfs_result = self.dfs_search(node, max_depth)
            for n, depth in dfs_result:
                all_results.append((n, depth, 'DFS'))
            
            # Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…
            neighbors = self.get_neighbors_by_type(node)
            for nid, name in neighbors:
                all_results.append((nid, 1, 'Neighbors'))
        
        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ
        unique_results = {}
        for node, depth, method in all_results:
            if node not in unique_results:
                unique_results[node] = {'depth': depth, 'methods': [method], 'score': 1.0}
            else:
                unique_results[node]['methods'].append(method)
                unique_results[node]['score'] += 0.5  # Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
                if depth < unique_results[node]['depth']:
                    unique_results[node]['depth'] = depth
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø² Ùˆ Ø¹Ù…Ù‚
        sorted_results = []
        for node, info in unique_results.items():
            sorted_results.append((node, info['depth'], ', '.join(info['methods'])))
        
        return sorted(sorted_results, key=lambda x: (x[1], -len(x[2].split(', '))))
    
    def ensemble_search(self, nodes: List[str], max_depth: int = 2) -> List[Tuple[str, int, float]]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ú¯Ø±ÙˆÙ‡ÛŒ - ØªØ±Ú©ÛŒØ¨ Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§ Ø¨Ø§ ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ"""
        method_weights = {
            'BFS': 1.0,
            'DFS': 0.8,
            'SHORTEST_PATH': 1.2,
            'NEIGHBORS': 0.9
        }
        
        all_results = {}
        
        for node in nodes:
            # BFS
            bfs_result = self.bfs_search(node, max_depth)
            for n, depth in bfs_result:
                if n not in all_results:
                    all_results[n] = {'score': 0, 'depth': depth, 'count': 0}
                all_results[n]['score'] += method_weights['BFS'] / (depth + 1)
                all_results[n]['count'] += 1
            
            # DFS
            dfs_result = self.dfs_search(node, max_depth)
            for n, depth in dfs_result:
                if n not in all_results:
                    all_results[n] = {'score': 0, 'depth': depth, 'count': 0}
                all_results[n]['score'] += method_weights['DFS'] / (depth + 1)
                all_results[n]['count'] += 1
            
            # Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§
            neighbors = self.get_neighbors_by_type(node)
            for nid, name in neighbors:
                if nid not in all_results:
                    all_results[nid] = {'score': 0, 'depth': 1, 'count': 0}
                all_results[nid]['score'] += method_weights['NEIGHBORS']
                all_results[nid]['count'] += 1
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø²
        sorted_results = []
        for node, info in all_results.items():
            final_score = info['score'] * (1 + 0.1 * info['count'])  # Ù¾Ø§Ø¯Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªÚ©Ø±Ø§Ø±
            sorted_results.append((node, info['depth'], final_score))
        
        return sorted(sorted_results, key=lambda x: x[2], reverse=True)
    
    def adaptive_search(self, nodes: List[str], max_depth: int = 2, query: str = "") -> List[Tuple[str, int, str]]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ ØªØ·Ø¨ÛŒÙ‚ÛŒ - Ø§Ù†ØªØ®Ø§Ø¨ Ø±ÙˆØ´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ù†ÙˆØ¯ Ùˆ Ø³ÙˆØ§Ù„"""
        all_results = []
        query_lower = query.lower()
        
        # ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„
        is_expression_question = any(word in query_lower for word in ['expressed', 'expression', 'express', 'genes'])
        is_relationship_question = any(word in query_lower for word in ['relationship', 'related', 'connection', 'link'])
        is_function_question = any(word in query_lower for word in ['function', 'role', 'purpose', 'effect'])
        
        print(f"ğŸ” ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: expression={is_expression_question}, relationship={is_relationship_question}, function={is_function_question}")
        
        for node in nodes:
            node_kind = self.G.nodes[node]['kind']
            node_name = self.G.nodes[node]['name']
            print(f"  ğŸ“ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†ÙˆØ¯: {node_name} ({node_kind})")
            
            # Ø§Ù†ØªØ®Ø§Ø¨ Ø±ÙˆØ´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ù†ÙˆØ¯ Ùˆ Ø³ÙˆØ§Ù„
            if node_kind == 'Anatomy' and is_expression_question:
                # Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¨ÛŒØ§Ù† Ø¯Ø± Ø¢Ù†Ø§ØªÙˆÙ…ÛŒØŒ Ø§Ø² Ø¬Ø³ØªØ¬ÙˆÛŒ ØªØ®ØµØµÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
                print(f"    ğŸ«€ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¬Ø³ØªØ¬ÙˆÛŒ ØªØ®ØµØµÛŒ Ø¢Ù†Ø§ØªÙˆÙ…ÛŒ Ø¨Ø±Ø§ÛŒ {node_name}")
                
                # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ§Ù† Ø´Ø¯Ù‡
                for neighbor in self.G.neighbors(node):
                    if self.G.nodes[neighbor]['kind'] == 'Gene':
                        edge_data = self.G.get_edge_data(node, neighbor)
                        if edge_data:
                            relation = edge_data.get('metaedge', '')
                            if relation == 'AeG':
                                all_results.append((neighbor, 1, 'Expression-Direct'))
                                print(f"      âœ… {self.G.nodes[neighbor]['name']} - Ø¨ÛŒØ§Ù† Ù…Ø³ØªÙ‚ÛŒÙ… (AeG)")
                
                # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ú©ÙˆØ³
                for gene_node, gene_attrs in self.G.nodes(data=True):
                    if gene_attrs.get('kind') == 'Gene':
                        for neighbor in self.G.neighbors(gene_node):
                            if neighbor == node:
                                edge_data = self.G.get_edge_data(gene_node, neighbor)
                                if edge_data:
                                    relation = edge_data.get('metaedge', '')
                                    if relation == 'GeA':
                                        all_results.append((gene_node, 1, 'Expression-Reverse'))
                                        print(f"      âœ… {gene_attrs['name']} - Ø¨ÛŒØ§Ù† Ù…Ø¹Ú©ÙˆØ³ (GeA)")
                
                # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¹Ù…ÛŒÙ‚ Ø¨Ø§ ÙÛŒÙ„ØªØ±
                dfs_result = self.dfs_search(node, max_depth, relation_filter='AeG')
                for n, depth in dfs_result:
                    if self.G.nodes[n]['kind'] == 'Gene':
                        all_results.append((n, depth, 'Expression-DFS'))
                        print(f"      âœ… {self.G.nodes[n]['name']} - Ø¹Ù…Ù‚ {depth}")
            
            elif node_kind in ['Gene', 'Disease']:
                # Ø¨Ø±Ø§ÛŒ Ú˜Ù†â€ŒÙ‡Ø§ Ùˆ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø§Ø² BFS Ùˆ Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§
                print(f"    ğŸ§¬ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² BFS Ø¨Ø±Ø§ÛŒ {node_name}")
                bfs_result = self.bfs_search(node, max_depth)
                for n, depth in bfs_result:
                    all_results.append((n, depth, 'BFS'))
                
                neighbors = self.get_neighbors_by_type(node)
                for nid, name in neighbors:
                    all_results.append((nid, 1, 'Neighbors'))
            
            elif node_kind in ['Drug', 'Compound']:
                # Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø±ÙˆÙ‡Ø§ Ø§Ø² DFS Ùˆ Ú©ÙˆØªØ§Ù‡â€ŒØªØ±ÛŒÙ† Ù…Ø³ÛŒØ±
                print(f"    ğŸ’Š Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² DFS Ø¨Ø±Ø§ÛŒ {node_name}")
                dfs_result = self.dfs_search(node, max_depth)
                for n, depth in dfs_result:
                    all_results.append((n, depth, 'DFS'))
            
            elif node_kind in ['Biological Process', 'Pathway']:
                # Ø¨Ø±Ø§ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ø§Ø² Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§
                print(f"    âš™ï¸ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø±Ø§ÛŒ {node_name}")
                bfs_result = self.bfs_search(node, max_depth)
                for n, depth in bfs_result:
                    all_results.append((n, depth, 'BFS'))
                
                dfs_result = self.dfs_search(node, max_depth)
                for n, depth in dfs_result:
                    all_results.append((n, depth, 'DFS'))
            
            else:
                # Ø¨Ø±Ø§ÛŒ Ø¨Ù‚ÛŒÙ‡ Ø§Ø² Ø±ÙˆØ´ ØªØ±Ú©ÛŒØ¨ÛŒ
                print(f"    ğŸ”„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø±Ø§ÛŒ {node_name}")
                hybrid_result = self.hybrid_search([node], max_depth)
                for n, depth in hybrid_result:
                    all_results.append((n, depth, 'Hybrid'))
        
        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ
        unique_results = {}
        for node, depth, method in all_results:
            if node not in unique_results:
                unique_results[node] = (depth, method, 1)
            else:
                # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ ØªÚ©Ø±Ø§Ø±
                unique_results[node] = (min(depth, unique_results[node][0]), 
                                      method, unique_results[node][2] + 1)
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù…Ù‚ Ùˆ Ø§Ù…ØªÛŒØ§Ø²
        sorted_results = []
        for node, (depth, method, count) in unique_results.items():
            # Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ´
            method_score = {
                'Expression-Direct': 5.0,
                'Expression-Reverse': 4.5,
                'Expression-DFS': 4.0,
                'BFS': 3.5,
                'DFS': 3.0,
                'Neighbors': 2.5,
                'Hybrid': 2.0
            }.get(method, 1.0)
            
            final_score = method_score * (1 + 0.1 * count) / (depth + 1)
            sorted_results.append((node, depth, method, final_score))
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒ
        sorted_results.sort(key=lambda x: x[3], reverse=True)
        
        return [(node, depth, method) for node, depth, method, score in sorted_results]
    
    def retrieve_information(self, query: str, method: RetrievalMethod, 
                           max_depth: int = None, max_nodes: int = None) -> RetrievalResult:
        """Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² Ú¯Ø±Ø§Ù"""
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ú¯Ø± Ù…Ù‚Ø¯Ø§Ø± Ø¯Ø§Ø¯Ù‡ Ù†Ø´Ø¯Ù‡
        if max_depth is None:
            max_depth = self.config['max_depth']
        if max_nodes is None:
            max_nodes = self.config['max_nodes']
        """Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² Ú¯Ø±Ø§Ù"""
        print(f"ğŸ” Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø§ Ø±ÙˆØ´ {method}...")
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
        keywords = self.extract_keywords(query)
        print(f"Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: {keywords}")
        
        # ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ú¯Ø±Ø§Ù
        matches = self.match_tokens_to_nodes(keywords)
        print(f"ØªØ·Ø¨ÛŒÙ‚â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡: {matches}")
        
        nodes = []
        edges = []
        paths = []
        
        if method == RetrievalMethod.BFS:
            # BFS Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†ÙˆØ¯ ØªØ·Ø¨ÛŒÙ‚ ÛŒØ§ÙØªÙ‡
            for token, node_id in matches.items():
                bfs_result = self.bfs_search(node_id, max_depth)
                for node, depth in bfs_result[:max_nodes]:
                    nodes.append(GraphNode(
                        id=node,
                        name=self.G.nodes[node]['name'],
                        kind=self.G.nodes[node]['kind'],
                        depth=depth
                    ))
        
        elif method == RetrievalMethod.DFS:
            # DFS Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†ÙˆØ¯ ØªØ·Ø¨ÛŒÙ‚ ÛŒØ§ÙØªÙ‡
            for token, node_id in matches.items():
                dfs_result = self.dfs_search(node_id, max_depth)
                for node, depth in dfs_result[:max_nodes]:
                    nodes.append(GraphNode(
                        id=node,
                        name=self.G.nodes[node]['name'],
                        kind=self.G.nodes[node]['kind'],
                        depth=depth
                    ))
        
        elif method == RetrievalMethod.SHORTEST_PATH:
            # Ú©ÙˆØªØ§Ù‡â€ŒØªØ±ÛŒÙ† Ù…Ø³ÛŒØ± Ø¨ÛŒÙ† Ù†ÙˆØ¯Ù‡Ø§
            if len(matches) >= 2:
                node_ids = list(matches.values())
                for i in range(len(node_ids)):
                    for j in range(i+1, len(node_ids)):
                        paths.extend(self.get_shortest_paths(node_ids[i], node_ids[j]))
                        
                        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ù…Ø³ÛŒØ±
                        for path in paths:
                            for k, node in enumerate(path):
                                nodes.append(GraphNode(
                                    id=node,
                                    name=self.G.nodes[node]['name'],
                                    kind=self.G.nodes[node]['kind'],
                                    depth=k
                                ))
            else:
                # Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² 2 Ù†ÙˆØ¯ Ù¾ÛŒØ¯Ø§ Ø´Ø¯ØŒ Ø§Ø² BFS Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
                print("âš ï¸ Ú©Ù…ØªØ± Ø§Ø² 2 Ù†ÙˆØ¯ Ø¨Ø±Ø§ÛŒ SHORTEST_PATH Ù¾ÛŒØ¯Ø§ Ø´Ø¯. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² BFS...")
                for token, node_id in matches.items():
                    bfs_result = self.bfs_search(node_id, max_depth)
                    for node, depth in bfs_result[:max_nodes]:
                        nodes.append(GraphNode(
                            id=node,
                            name=self.G.nodes[node]['name'],
                            kind=self.G.nodes[node]['kind'],
                            depth=depth
                        ))
        
        elif method == RetrievalMethod.NEIGHBORS:
            # Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…
            for token, node_id in matches.items():
                neighbors = self.get_neighbors_by_type(node_id)
                for nid, name in neighbors[:max_nodes]:
                    nodes.append(GraphNode(
                        id=nid,
                        name=name,
                        kind=self.G.nodes[nid]['kind'],
                        depth=1
                    ))
        
        elif method == RetrievalMethod.HYBRID:
            # ØªØ±Ú©ÛŒØ¨ÛŒ Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§
            if len(matches) >= 2:
                node_ids = list(matches.values())
                hybrid_result = self.hybrid_search(node_ids, max_depth)
                for node, depth in hybrid_result[:max_nodes]:
                    nodes.append(GraphNode(
                        id=node,
                        name=self.G.nodes[node]['name'],
                        kind=self.G.nodes[node]['kind'],
                        depth=depth
                    ))
            else:
                # Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² 2 Ù†ÙˆØ¯ Ù¾ÛŒØ¯Ø§ Ø´Ø¯ØŒ Ø§Ø² BFS Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
                print("âš ï¸ Ú©Ù…ØªØ± Ø§Ø² 2 Ù†ÙˆØ¯ Ø¨Ø±Ø§ÛŒ HYBRID Ù¾ÛŒØ¯Ø§ Ø´Ø¯. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² BFS...")
                for token, node_id in matches.items():
                    bfs_result = self.bfs_search(node_id, max_depth)
                    for node, depth in bfs_result[:max_nodes]:
                        nodes.append(GraphNode(
                            id=node,
                            name=self.G.nodes[node]['name'],
                            kind=self.G.nodes[node]['kind'],
                            depth=depth
                        ))
        
        elif method == RetrievalMethod.MULTI_METHOD:
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ú†Ù†Ø¯ Ø±ÙˆØ´ÛŒ
            if len(matches) >= 1:
                node_ids = list(matches.values())
                multi_result = self.multi_method_search(node_ids, max_depth)
                for node, depth, methods in multi_result[:max_nodes]:
                    nodes.append(GraphNode(
                        id=node,
                        name=self.G.nodes[node]['name'],
                        kind=self.G.nodes[node]['kind'],
                        depth=depth,
                        score=len(methods.split(', '))  # Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¹Ø¯Ø§Ø¯ Ø±ÙˆØ´â€ŒÙ‡Ø§
                    ))
            else:
                print("âš ï¸ Ù‡ÛŒÚ† Ù†ÙˆØ¯ÛŒ Ø¨Ø±Ø§ÛŒ MULTI_METHOD Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        
        elif method == RetrievalMethod.ENSEMBLE:
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ú¯Ø±ÙˆÙ‡ÛŒ
            if len(matches) >= 1:
                node_ids = list(matches.values())
                ensemble_result = self.ensemble_search(node_ids, max_depth)
                for node, depth, score in ensemble_result[:max_nodes]:
                    nodes.append(GraphNode(
                        id=node,
                        name=self.G.nodes[node]['name'],
                        kind=self.G.nodes[node]['kind'],
                        depth=depth,
                        score=score
                    ))
            else:
                print("âš ï¸ Ù‡ÛŒÚ† Ù†ÙˆØ¯ÛŒ Ø¨Ø±Ø§ÛŒ ENSEMBLE Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        
        elif method == RetrievalMethod.ADAPTIVE:
            # Ø¬Ø³ØªØ¬ÙˆÛŒ ØªØ·Ø¨ÛŒÙ‚ÛŒ Ø¨Ø§ Ù¾Ø§Ø³ Ø¯Ø§Ø¯Ù† query
            if len(matches) >= 1:
                node_ids = list(matches.values())
                adaptive_result = self.adaptive_search(node_ids, max_depth, query)
                for node, depth, method in adaptive_result[:max_nodes]:
                    nodes.append(GraphNode(
                        id=node,
                        name=self.G.nodes[node]['name'],
                        kind=self.G.nodes[node]['kind'],
                        depth=depth
                    ))
            else:
                print("âš ï¸ Ù‡ÛŒÚ† Ù†ÙˆØ¯ÛŒ Ø¨Ø±Ø§ÛŒ ADAPTIVE Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        
        elif method == RetrievalMethod.INTELLIGENT:
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯
            intelligent_result = self.intelligent_semantic_search(query, max_depth)
            
            # ØªØ¨Ø¯ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ GraphNode
            for node_id, depth, score, reason in intelligent_result[:max_nodes]:
                nodes.append(GraphNode(
                    id=node_id,
                    name=self.G.nodes[node_id]['name'],
                    kind=self.G.nodes[node_id]['kind'],
                    depth=depth,
                    score=score
                ))
            
            # ÛŒØ§ÙØªÙ† Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø·ÛŒ Ø¨ÛŒÙ† Ù†ÙˆØ¯Ù‡Ø§
            if len(nodes) >= 2:
                node_ids = [node.id for node in nodes]
                for i in range(len(node_ids)):
                    for j in range(i+1, len(node_ids)):
                        spaths = self.get_shortest_paths(node_ids[i], node_ids[j])
                        if not spaths:
                            continue
                        paths.extend(spaths)
                        # Ø§ÙØ²ÙˆØ¯Ù† Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ù…Ø³ÛŒØ±
                        for path in spaths:
                            for k, pid in enumerate(path):
                                if pid not in [n.id for n in nodes]:
                                    nodes.append(GraphNode(
                                        id=pid,
                                        name=self.G.nodes[pid]['name'],
                                        kind=self.G.nodes[pid]['kind'],
                                        depth=k
                                    ))
                            # Ø§ÙØ²ÙˆØ¯Ù† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø³ÛŒØ±
                            for k in range(len(path) - 1):
                                ed = self.G.get_edge_data(path[k], path[k+1])
                                if ed:
                                    edges.append(GraphEdge(
                                        source=path[k],
                                        target=path[k+1],
                                        relation=ed.get('metaedge', 'related'),
                                        weight=ed.get('weight', 1.0)
                                    ))
            
            # ÛŒØ§ÙØªÙ† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
            for node in nodes:
                for neighbor in self.G.neighbors(node.id):
                    if any(n.id == neighbor for n in nodes):
                        edge_data = self.G.get_edge_data(node.id, neighbor)
                        if edge_data:
                            edges.append(GraphEdge(
                                source=node.id,
                                target=neighbor,
                                relation=edge_data.get('metaedge', 'related'),
                                weight=edge_data.get('weight', 1.0)
                            ))
        
        elif method == RetrievalMethod.KG_SEARCH:
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¯Ø§Ù†Ø´â€ŒÚ¯Ø±Ø§Ù (Knowledge Graph Search)
            print("ğŸ” Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… KG_SEARCH")
            # Intent-aware: Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ Ù‡Ù…â€ŒÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ú˜Ù† Ø§Ø³ØªØŒ ÙÙ‚Ø· GcG Ø¨Ø§ Ø®Ø±ÙˆØ¬ÛŒ Ù…ÛŒÙ†ÛŒÙ…Ø§Ù„ Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
            intent = self.analyze_question_intent(query)
            if intent.get('question_type') == 'gene_covariation':
                # core lock: ÛŒØ§ÙØªÙ† Ù‡Ø³ØªÙ‡ Ú˜Ù† Ø§Ø² ØªÙˆÚ©Ù†â€ŒÙ‡Ø§
                matched_nodes = self.match_tokens_to_nodes(intent.get('keywords', []))
                core_nodes = self._extract_core_nodes(query, matched_nodes, intent)
                core_gene = None
                for nid in core_nodes:
                    if self.G.nodes[nid].get('kind') == 'Gene':
                        core_gene = nid
                        break
                if core_gene is None and matched_nodes:
                    # fallback Ø³Ø§Ø¯Ù‡
                    for nid in matched_nodes.values():
                        if self.G.nodes[nid].get('kind') == 'Gene':
                            core_gene = nid
                            break
                if core_gene:
                    # ÙÙ‚Ø· Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ GcG (Geneâ€“covariesâ€“Gene)
                    covary_genes = []
                    for nbr in self.G.neighbors(core_gene):
                        ed = self.G.get_edge_data(core_gene, nbr) or {}
                        if (ed.get('metaedge') or ed.get('relation')) == 'GcG' and self.G.nodes[nbr].get('kind') == 'Gene':
                            covary_genes.append(nbr)
                    # Ø³Ø§Ø®Øª Ø®Ø±ÙˆØ¬ÛŒ Ù…ÛŒÙ†ÛŒÙ…Ø§Ù„: core + Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ú˜Ù†ÛŒØŒ ÛŒØ§Ù„â€ŒÙ‡Ø§ ÙÙ‚Ø· GcGØŒ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ÛŒÚ©â€ŒÙ¾Ø±Ø´
                    nodes.append(GraphNode(id=core_gene,
                                           name=self.G.nodes[core_gene]['name'],
                                           kind=self.G.nodes[core_gene]['kind'],
                                           depth=0,
                                           score=1.0))
                    for gid in covary_genes[:max_nodes-1]:
                        nodes.append(GraphNode(id=gid,
                                               name=self.G.nodes[gid]['name'],
                                               kind=self.G.nodes[gid]['kind'],
                                               depth=1,
                                               score=1.0))
                        edges.append(GraphEdge(source=core_gene,
                                               target=gid,
                                               relation='GcG',
                                               weight=(self.G.get_edge_data(core_gene, gid) or {}).get('weight', 1.0)))
                        paths.append([core_gene, gid])
                else:
                    # Ø§Ú¯Ø± Ú˜Ù† Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ø¨Ù‡ Ù†Ø³Ø®Ù‡ traceable Ø¬Ø¯ÛŒØ¯ Ø³ÙˆØ¦ÛŒÚ† Ú©Ù†
                    hits, _ = self.kgsearch_traceable(query, top_k=min(10, max_nodes))
                    # ØªØ¨Ø¯ÛŒÙ„ hits Ø¨Ù‡ nodes/edges/paths
                    nid_set = set()
                    for h in hits:
                        seq = h.get('path', [])
                        last_node = None
                        for elem in seq:
                            if 'id' in elem:
                                nid = elem['id']
                                nid_set.add(nid)
                                if not any(n.id == nid for n in nodes):
                                    nodes.append(GraphNode(id=nid,
                                                           name=self.G.nodes[nid].get('name', nid),
                                                           kind=self.G.nodes[nid].get('kind', 'Unknown'),
                                                           depth=0))
                                last_node = nid
                            elif 'edge_id' in elem and last_node is not None:
                                # edge follows between last_node and next node in sequence; will be added when next node arrives
                                pass
                        # Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡
                        path_nodes = [e['id'] for e in seq if 'id' in e]
                        if len(path_nodes) >= 2:
                            paths.append(path_nodes)
                            for i in range(len(path_nodes)-1):
                                ed = self.G.get_edge_data(path_nodes[i], path_nodes[i+1]) or {}
                                edges.append(GraphEdge(source=path_nodes[i],
                                                       target=path_nodes[i+1],
                                                       relation=ed.get('metaedge', ed.get('relation', 'related')),
                                                       weight=ed.get('weight', 1.0)))
            else:
                # Ù…Ø³ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶: Ù†Ø³Ø®Ù‡ traceable Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Schema
                hits, _ = self.kgsearch_traceable(query, top_k=min(10, max_nodes))
                # ØªØ¨Ø¯ÛŒÙ„ hits Ø¨Ù‡ nodes/edges/paths
                nid_set = set()
                for h in hits:
                    seq = h.get('path', [])
                    last_node = None
                    current_path = []
                    for elem in seq:
                        if 'id' in elem:
                            nid = elem['id']
                            current_path.append(nid)
                            if nid not in nid_set:
                                nid_set.add(nid)
                                nodes.append(GraphNode(id=nid,
                                                       name=self.G.nodes[nid].get('name', nid),
                                                       kind=self.G.nodes[nid].get('kind', 'Unknown'),
                                                       depth=0))
                            last_node = nid
                        elif 'edge_id' in elem and last_node is not None:
                            pass
                    if len(current_path) >= 2:
                        paths.append(current_path)
                        for i in range(len(current_path)-1):
                            ed = self.G.get_edge_data(current_path[i], current_path[i+1]) or {}
                            edges.append(GraphEdge(source=current_path[i],
                                                   target=current_path[i+1],
                                                   relation=ed.get('metaedge', ed.get('relation', 'related')),
                                                   weight=ed.get('weight', 1.0)))
        
        elif method == RetrievalMethod.N_HOP_RETRIEVAL:
            # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ú†Ù†Ø¯Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ
            print("ğŸ” Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… N_HOP_RETRIEVAL")
            multi_hop_result = self.multi_hop_search(query, max_depth)
            
            # ØªØ¨Ø¯ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ GraphNode
            for node_id, depth, score, reason, path in multi_hop_result[:max_nodes]:
                nodes.append(GraphNode(
                    id=node_id,
                    name=self.G.nodes[node_id]['name'],
                    kind=self.G.nodes[node_id]['kind'],
                    depth=depth,
                    score=score
                ))
                if path:
                    paths.append(path)
            
            # ÛŒØ§ÙØªÙ† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
            for node in nodes:
                for neighbor in self.G.neighbors(node.id):
                    if any(n.id == neighbor for n in nodes):
                        edge_data = self.G.get_edge_data(node.id, neighbor)
                        if edge_data:
                            edges.append(GraphEdge(
                                source=node.id,
                                target=neighbor,
                                relation=edge_data.get('metaedge', 'related'),
                                weight=edge_data.get('weight', 1.0)
                            ))
        
        elif method == RetrievalMethod.PAGERANK_BASED:
            # Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ PageRank
            print("ğŸ” Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… PAGERANK_BASED")
            try:
                import networkx as nx
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ PageRank
                pagerank_scores = nx.pagerank(self.G, alpha=0.85, max_iter=100)
                
                # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ù†ÙˆØ¯Ù‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ PageRank
                sorted_nodes = sorted(pagerank_scores.items(), key=lambda x: x[1], reverse=True)
                
                # Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ø¨Ø±ØªØ±
                for node_id, score in sorted_nodes[:max_nodes]:
                    if node_id in self.G.nodes:
                        nodes.append(GraphNode(
                            id=node_id,
                            name=self.G.nodes[node_id]['name'],
                            kind=self.G.nodes[node_id]['kind'],
                            depth=0,
                            score=score
                        ))
                
                # ÛŒØ§ÙØªÙ† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
                for node in nodes:
                    for neighbor in self.G.neighbors(node.id):
                        if any(n.id == neighbor for n in nodes):
                            edge_data = self.G.get_edge_data(node.id, neighbor)
                            if edge_data:
                                edges.append(GraphEdge(
                                    source=node.id,
                                    target=neighbor,
                                    relation=edge_data.get('metaedge', 'related'),
                                    weight=edge_data.get('weight', 1.0)
                                ))
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ PageRank: {e}")
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†
                intelligent_result = self.intelligent_semantic_search(query, max_depth)
                for node_id, depth, score, reason in intelligent_result[:max_nodes]:
                    nodes.append(GraphNode(
                        id=node_id,
                        name=self.G.nodes[node_id]['name'],
                        kind=self.G.nodes[node_id]['kind'],
                        depth=depth,
                        score=score
                    ))
        
        elif method == RetrievalMethod.SEMANTIC_SIMILARITY:
            # Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø¨Ø§Ù‡Øª Ù…Ø¹Ù†Ø§ÛŒÛŒ
            print("ğŸ” Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… SEMANTIC_SIMILARITY")
            intelligent_result = self.intelligent_semantic_search(query, max_depth)
            
            # ØªØ¨Ø¯ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ GraphNode
            for node_id, depth, score, reason in intelligent_result[:max_nodes]:
                nodes.append(GraphNode(
                    id=node_id,
                    name=self.G.nodes[node_id]['name'],
                    kind=self.G.nodes[node_id]['kind'],
                    depth=depth,
                    score=score
                ))
            
            # ÛŒØ§ÙØªÙ† Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø·ÛŒ Ø¨ÛŒÙ† Ù†ÙˆØ¯Ù‡Ø§
            if len(nodes) >= 2:
                node_ids = [node.id for node in nodes]
                for i in range(len(node_ids)):
                    for j in range(i+1, len(node_ids)):
                        spaths = self.get_shortest_paths(node_ids[i], node_ids[j])
                        if not spaths:
                            continue
                        paths.extend(spaths)
                        # Ø§ÙØ²ÙˆØ¯Ù† Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ù…Ø³ÛŒØ±
                        for path in spaths:
                            for k, pid in enumerate(path):
                                if pid not in [n.id for n in nodes]:
                                    nodes.append(GraphNode(
                                        id=pid,
                                        name=self.G.nodes[pid]['name'],
                                        kind=self.G.nodes[pid]['kind'],
                                        depth=k
                                    ))
                            # Ø§ÙØ²ÙˆØ¯Ù† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø³ÛŒØ±
                            for k in range(len(path) - 1):
                                ed = self.G.get_edge_data(path[k], path[k+1])
                                if ed:
                                    edges.append(GraphEdge(
                                        source=path[k],
                                        target=path[k+1],
                                        relation=ed.get('metaedge', 'related'),
                                        weight=ed.get('weight', 1.0)
                                    ))
            
            # ÛŒØ§ÙØªÙ† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
            for node in nodes:
                for neighbor in self.G.neighbors(node.id):
                    if any(n.id == neighbor for n in nodes):
                        edge_data = self.G.get_edge_data(node.id, neighbor)
                        if edge_data:
                            edges.append(GraphEdge(
                                source=node.id,
                                target=neighbor,
                                relation=edge_data.get('metaedge', 'related'),
                                weight=edge_data.get('weight', 1.0)
                            ))
        
        elif method == RetrievalMethod.COMMUNITY_DETECTION:
            # ØªØ´Ø®ÛŒØµ Ø¬Ø§Ù…Ø¹Ù‡â€ŒÙ‡Ø§
            print("ğŸ” Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… COMMUNITY_DETECTION")
            try:
                import networkx as nx
                from community import community_louvain
                
                # ØªØ´Ø®ÛŒØµ Ø¬Ø§Ù…Ø¹Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Louvain
                communities = community_louvain.best_partition(self.G)
                
                # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†ÙˆØ¯Ù‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¬Ø§Ù…Ø¹Ù‡
                community_nodes = {}
                for node_id, community_id in communities.items():
                    if community_id not in community_nodes:
                        community_nodes[community_id] = []
                    community_nodes[community_id].append(node_id)
                
                # Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ø¬Ø§Ù…Ø¹Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
                selected_nodes = []
                for community_id, node_list in community_nodes.items():
                    # Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ø¨Ø±ØªØ± Ø§Ø² Ù‡Ø± Ø¬Ø§Ù…Ø¹Ù‡
                    for node_id in node_list[:max(1, max_nodes // len(community_nodes))]:
                        if node_id in self.G.nodes:
                            selected_nodes.append(node_id)
                
                # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ GraphNode
                for node_id in selected_nodes[:max_nodes]:
                    nodes.append(GraphNode(
                        id=node_id,
                        name=self.G.nodes[node_id]['name'],
                        kind=self.G.nodes[node_id]['kind'],
                        depth=0,
                        score=1.0
                    ))
                
                # ÛŒØ§ÙØªÙ† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
                for node in nodes:
                    for neighbor in self.G.neighbors(node.id):
                        if any(n.id == neighbor for n in nodes):
                            edge_data = self.G.get_edge_data(node.id, neighbor)
                            if edge_data:
                                edges.append(GraphEdge(
                                    source=node.id,
                                    target=neighbor,
                                    relation=edge_data.get('metaedge', 'related'),
                                    weight=edge_data.get('weight', 1.0)
                                ))
            except ImportError:
                print("âš ï¸ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ community Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³ØªØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†")
                intelligent_result = self.intelligent_semantic_search(query, max_depth)
                for node_id, depth, score, reason in intelligent_result[:max_nodes]:
                    nodes.append(GraphNode(
                        id=node_id,
                        name=self.G.nodes[node_id]['name'],
                        kind=self.G.nodes[node_id]['kind'],
                        depth=depth,
                        score=score
                    ))
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ´Ø®ÛŒØµ Ø¬Ø§Ù…Ø¹Ù‡â€ŒÙ‡Ø§: {e}")
                intelligent_result = self.intelligent_semantic_search(query, max_depth)
                for node_id, depth, score, reason in intelligent_result[:max_nodes]:
                    nodes.append(GraphNode(
                        id=node_id,
                        name=self.G.nodes[node_id]['name'],
                        kind=self.G.nodes[node_id]['kind'],
                        depth=depth,
                        score=score
                    ))
        
        elif method == RetrievalMethod.ENTITY_RESOLUTION:
            # Ø­Ù„ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
            print("ğŸ” Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… ENTITY_RESOLUTION")
            try:
                if NEW_MODULES_AVAILABLE:
                    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø§Ú˜ÙˆÙ„ Ø¬Ø¯ÛŒØ¯ EntityResolution
                    entity_resolver = EntityResolution()
                    resolved_entities = entity_resolver.resolve_entities(query)
                    
                    # ØªØ·Ø¨ÛŒÙ‚ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø­Ù„ Ø´Ø¯Ù‡ Ø¨Ø§ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ú¯Ø±Ø§Ù
                    for entity in resolved_entities:
                        for node_id, node_attrs in self.G.nodes(data=True):
                            if entity.lower() in node_attrs['name'].lower():
                                nodes.append(GraphNode(
                                    id=node_id,
                                    name=node_attrs['name'],
                                    kind=node_attrs['kind'],
                                    depth=0,
                                    score=1.0
                                ))
                                break
                else:
                    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†
                    intelligent_result = self.intelligent_semantic_search(query, max_depth)
                    for node_id, depth, score, reason in intelligent_result[:max_nodes]:
                        nodes.append(GraphNode(
                            id=node_id,
                            name=self.G.nodes[node_id]['name'],
                            kind=self.G.nodes[node_id]['kind'],
                            depth=depth,
                            score=score
                        ))
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø­Ù„ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§: {e}")
                intelligent_result = self.intelligent_semantic_search(query, max_depth)
                for node_id, depth, score, reason in intelligent_result[:max_nodes]:
                    nodes.append(GraphNode(
                        id=node_id,
                        name=self.G.nodes[node_id]['name'],
                        kind=self.G.nodes[node_id]['kind'],
                        depth=depth,
                        score=score
                    ))
        
        elif method == RetrievalMethod.HYBRID_NEW:
            # ØªØ±Ú©ÛŒØ¨ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ù‚ÙÙ„ Ù…ÙˆØ¬ÙˆØ¯ÛŒØª (Entity Locking) Ùˆ ÙÛŒÙ„ØªØ± Ù†ÙˆÛŒØ²
            print("ğŸ” Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… HYBRID_NEW")

            # ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØª Ø³ÙˆØ§Ù„ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù‚ÙÙ„ Ù…ÙˆØ¬ÙˆØ¯ÛŒØª
            intent = self.analyze_question_intent(query)
            keywords = self.extract_keywords(query)
            matched_nodes = self.match_tokens_to_nodes(keywords)

            # ØªØ´Ø®ÛŒØµ Ø³Ù†Ø§Ø±ÛŒÙˆÛŒ Ú˜Ù†-Ø³Ø±Ø·Ø§Ù† Ùˆ Ø§Ø¹Ù…Ø§Ù„ Ø¹Ù…Ù‚ Ù…Ø­Ø¯ÙˆØ¯ØªØ±
            is_gene_cancer = self._is_gene_cancer_question(query, matched_nodes)
            local_max_depth = 2 if is_gene_cancer else max_depth

            # Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ù‚ÛŒÙ‚ Ù‡Ø³ØªÙ‡â€ŒÙ‡Ø§ Ù…ØªÙ†Ø§Ø³Ø¨ Ø¨Ø§ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„ Ùˆ ØªØ·Ø¨ÛŒÙ‚â€ŒÙ‡Ø§
            try:
                core_candidates = self._extract_core_nodes(query, matched_nodes, intent)
            except Exception:
                core_candidates = []
            core_node_id = core_candidates[0] if core_candidates else None

            # ØªØ±Ú©ÛŒØ¨ Ú†Ù†Ø¯ÛŒÙ† Ø±ÙˆØ´
            methods_results = []

            # 0. Ø§Ú¯Ø± Ù†ÙˆØ¯ Ù‡Ø³ØªÙ‡ ÛŒØ§ÙØª Ø´Ø¯ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ø§ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
            if core_node_id is not None:
                methods_results.append((core_node_id, 0, 100.0, 'Core Entity Lock'))

            # 1. Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ (Ø¨Ø§ Ø¹Ù…Ù‚ Ù…Ø­Ù„ÛŒ)
            intelligent_result = self.intelligent_semantic_search(query, local_max_depth)
            methods_results.extend(intelligent_result)

            # 2. Ø¬Ø³ØªØ¬ÙˆÛŒ Ú†Ù†Ø¯Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ (Ø¨Ø§ Ø¹Ù…Ù‚ Ù…Ø­Ù„ÛŒ)
            multi_hop_result = self.multi_hop_search(query, local_max_depth)
            for node_id, depth, score, reason, path in multi_hop_result:
                methods_results.append((node_id, depth, score, reason))

            # 3. PageRank (Ø§Ú¯Ø± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø¨Ø§Ø´Ø¯)
            try:
                import networkx as nx
                pagerank_scores = nx.pagerank(self.G, alpha=0.85, max_iter=100)
                sorted_nodes = sorted(pagerank_scores.items(), key=lambda x: x[1], reverse=True)
                for node_id, score in sorted_nodes[:max_nodes//3]:
                    if node_id in self.G.nodes:
                        methods_results.append((node_id, 0, score, 'PageRank'))
            except Exception:
                pass

            # Ø¨Ø§Ø²Ù†Ù…Ø±Ù‡â€ŒØ¯Ù‡ÛŒ Ú†Ù†Ø¯Ù…Ø¹ÛŒØ§Ø±Ù‡: Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ø¨Ù‡ Ù†ÙˆØ¯ Ù‡Ø³ØªÙ‡ + Ø§Ù…ØªÛŒØ§Ø² Ù¾Ø§ÛŒÙ‡
            if core_node_id is not None:
                for idx in range(len(methods_results)):
                    node_id, depth, score, reason = methods_results[idx]
                    try:
                        dist = nx.shortest_path_length(self.G, core_node_id, node_id)
                        if dist == 0:
                            score += 20.0
                        elif dist <= 2:
                            score += 5.0
                        else:
                            score += 0.0
                    except Exception:
                        pass
                    methods_results[idx] = (node_id, depth, score, reason)

            # ØªØ±Ú©ÛŒØ¨ Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬
            unique_results = {}
            for node_id, depth, score, reason in methods_results:
                if node_id not in unique_results or score > unique_results[node_id][2]:
                    unique_results[node_id] = (node_id, depth, score, reason)

            final_results = sorted(unique_results.values(), key=lambda x: x[2], reverse=True)

            # ØªØ¨Ø¯ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ GraphNode
            for node_id, depth, score, reason in final_results[:max_nodes]:
                nodes.append(GraphNode(
                    id=node_id,
                    name=self.G.nodes[node_id]['name'],
                    kind=self.G.nodes[node_id]['kind'],
                    depth=depth,
                    score=score
                ))

            # ÛŒØ§ÙØªÙ† Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø·ÛŒ Ø¨ÛŒÙ† Ù†ÙˆØ¯Ù‡Ø§
            if len(nodes) >= 2:
                node_ids = [node.id for node in nodes]
                if core_node_id is not None and core_node_id in node_ids:
                    # ÙÙ‚Ø· Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø§Ø² Ù†ÙˆØ¯ Ù‡Ø³ØªÙ‡ Ø¨Ù‡ Ø³Ø§ÛŒØ± Ù†ÙˆØ¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù†ÙˆÛŒØ²
                    for nid in node_ids:
                        if nid != core_node_id:
                            paths.extend(self.get_shortest_paths(core_node_id, nid))
                else:
                    for i in range(len(node_ids)):
                        for j in range(i+1, len(node_ids)):
                            paths.extend(self.get_shortest_paths(node_ids[i], node_ids[j]))

            # ÛŒØ§ÙØªÙ† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ ÙÛŒÙ„ØªØ± Ù†ÙˆÛŒØ² (Ø­Ø°Ù DrD/CrC Ù…Ú¯Ø± Ø³ÙˆØ§Ù„ Ø´Ø¨Ø§Ù‡Øª Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø¨Ø§Ø´Ø¯)
            disease_similarity = intent.get('question_type') == 'disease_similarity'
            for node in nodes:
                for neighbor in self.G.neighbors(node.id):
                    if any(n.id == neighbor for n in nodes):
                        edge_data = self.G.get_edge_data(node.id, neighbor)
                        if edge_data:
                            metaedge = edge_data.get('metaedge', 'related')
                            if not disease_similarity and metaedge in ['DrD', 'CrC']:
                                continue
                            edges.append(GraphEdge(
                                source=node.id,
                                target=neighbor,
                                relation=metaedge,
                                weight=edge_data.get('weight', 1.0)
                            ))
        
        elif method == RetrievalMethod.NO_RETRIEVAL:
            # Ø¨Ø¯ÙˆÙ† Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ - ÙÙ‚Ø· Ù…Ø¯Ù„
            print("ğŸ” Ø¨Ø¯ÙˆÙ† Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø² Ú¯Ø±Ø§Ù - ÙÙ‚Ø· Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„")
            # Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© Ù†ÙˆØ¯ Ø®Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ Ø³Ø§Ø®ØªØ§Ø±
            nodes.append(GraphNode(
                id="no_retrieval",
                name="Ø¨Ø¯ÙˆÙ† Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ",
                kind="System",
                depth=0
            ))
        
        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§
        unique_nodes = {}
        for node in nodes:
            if node.id not in unique_nodes:
                unique_nodes[node.id] = node
        
        nodes = list(unique_nodes.values())
        
        # Ø§ÛŒØ¬Ø§Ø¯ ÛŒØ§Ù„â€ŒÙ‡Ø§ Ø¨ÛŒÙ† Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
        for i, node1 in enumerate(nodes):
            for j, node2 in enumerate(nodes[i+1:], i+1):
                if self.G.has_edge(node1.id, node2.id):
                    edge_data = self.G.get_edge_data(node1.id, node2.id)
                    edges.append(GraphEdge(
                        source=node1.id,
                        target=node2.id,
                        relation=edge_data['metaedge']
                    ))
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡
        retrieval_result = RetrievalResult(
            nodes=nodes,
            edges=edges,
            paths=paths,
            context_text="",
            method=str(method),
            query=query
        )
        # ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡
        if self.context_generator:
            context_text = self.context_generator.create_enhanced_context_text(retrieval_result, context_type="INTELLIGENT")
        else:
            context_text = self._create_enhanced_context_text(retrieval_result)
        
        return RetrievalResult(
            nodes=nodes,
            edges=edges,
            paths=paths,
            context_text=context_text,
            method=method.value if hasattr(method, 'value') else str(method),
            query=query
        )
    
    def create_context_text(self, nodes: List[GraphNode], edges: List[GraphEdge], 
                           paths: List[List[str]]) -> str:
        """
        ØªØ§Ø¨Ø¹ Ù‚Ø¯ÛŒÙ…ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯
        Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ Ø§Ø² EnhancedContextGenerator Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
        """
        return "Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³ÛŒØ³ØªÙ… Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ØŒ Ø§Ø² IntegratedGraphRAGService Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯"
    
    def _enrich_retrieved_data(self, nodes: List[GraphNode], edges: List[GraphEdge], query: str) -> Dict[str, Any]:
        """
        ØªØ§Ø¨Ø¹ Ù‚Ø¯ÛŒÙ…ÛŒ ØºÙ†ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯
        """
        return {}
    
    def _get_anatomy_significance(self, anatomy_name: str) -> str:
        """
        ØªØ§Ø¨Ø¹ Ù‚Ø¯ÛŒÙ…ÛŒ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯
        """
        return ""
    
    def _create_biological_context(self, enriched_data: Dict, query: str) -> str:
        """
        ØªØ§Ø¨Ø¹ Ù‚Ø¯ÛŒÙ…ÛŒ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯
        """
        return ""
    
    def _create_enhanced_context_text(self, retrieval_result: RetrievalResult) -> str:
        """Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ: Ø§Ú¯Ø± Ú˜Ù†Ø±Ø§ØªÙˆØ± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¨ÙˆØ¯ØŒ Ù…ØªÙ† Ø³Ø§Ø¯Ù‡ Ø¨Ø³Ø§Ø²."""
        parts = []
        if retrieval_result.nodes:
            parts.append("Ù†ÙˆØ¯Ù‡Ø§:")
            parts.extend([f"â€¢ {n.name} ({n.kind})" for n in retrieval_result.nodes[:10]])
        if retrieval_result.edges:
            parts.append("\nØ±ÙˆØ§Ø¨Ø·:")
            parts.extend([f"â€¢ {e.source} â†’ {e.target} ({e.relation})" for e in retrieval_result.edges[:10]])
        return "\n".join(parts) if parts else "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."

    def _create_advanced_context_text(self, retrieval_result: RetrievalResult) -> str:
        """
        ØªØ§Ø¨Ø¹ Ù‚Ø¯ÛŒÙ…ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯
        """
        return "Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³ÛŒØ³ØªÙ… Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ØŒ Ø§Ø² IntegratedGraphRAGService Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯"

    def _targeted_retrieval_for_question(self, query: str, intent: Dict) -> Dict[str, Any]:
        """
        Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù‡Ø¯ÙÙ…Ù†Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„ Ùˆ metaedge Ù‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
        """
        matched_nodes = self.match_tokens_to_nodes(self.extract_keywords(query))
        question_type = intent.get('question_type', 'general')
        
        retrieval_data = {
            'primary_genes': [],
            'secondary_genes': [],
            'biological_processes': [],
            'pathways': [],
            'diseases': [],
            'drugs': [],
            'anatomy': [],
            'metaedges_used': [],
            'relationships': []
        }
        
        # ØªØ¹ÛŒÛŒÙ† metaedge Ù‡Ø§ÛŒ Ù‡Ø¯Ù Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„
        target_metaedges = self._get_target_metaedges_for_question(question_type, query)
        retrieval_data['metaedges_used'] = target_metaedges
        
        print(f"ğŸ¯ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù‡Ø¯ÙÙ…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„: {question_type}")
        print(f"ğŸ“‹ Metaedge Ù‡Ø§ÛŒ Ù‡Ø¯Ù: {target_metaedges}")
        
        # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ metaedge Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
        for metaedge in target_metaedges:
            results = self._search_by_metaedges(matched_nodes, intent, [metaedge], max_depth=2)
            
            for node_id, depth, score, explanation in results:
                node_name = self.G.nodes[node_id]['name']
                node_kind = self.G.nodes[node_id]['kind']
                
                # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†ØªØ§ÛŒØ¬ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹
                if node_kind == 'Gene':
                    if metaedge in ['AeG', 'AuG', 'AdG', 'DaG', 'DuG', 'DdG']:
                        retrieval_data['primary_genes'].append({
                            'name': node_name,
                            'metaedge': metaedge,
                            'score': score,
                            'explanation': explanation
                        })
                    else:
                        retrieval_data['secondary_genes'].append({
                            'name': node_name,
                            'metaedge': metaedge,
                            'score': score,
                            'explanation': explanation
                        })
                elif node_kind == 'Biological Process':
                    retrieval_data['biological_processes'].append({
                        'name': node_name,
                        'metaedge': metaedge,
                        'score': score
                    })
                elif node_kind == 'Pathway':
                    retrieval_data['pathways'].append({
                        'name': node_name,
                        'metaedge': metaedge,
                        'score': score
                    })
                elif node_kind == 'Disease':
                    retrieval_data['diseases'].append({
                        'name': node_name,
                        'metaedge': metaedge,
                        'score': score
                    })
                elif node_kind == 'Compound':
                    retrieval_data['compound'].append({
                        'name': node_name,
                        'metaedge': metaedge,
                        'score': score
                    })
                elif node_kind == 'Anatomy':
                    retrieval_data['anatomy'].append({
                        'name': node_name,
                        'metaedge': metaedge,
                        'score': score
                    })
        
        # ØºÙ†ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
        retrieval_data = self._enrich_primary_genes(retrieval_data)
        
        # Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§Ø«Ø± Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¨Ø± Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ØŒ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
        if 'DlA' in target_metaedges:
            retrieval_data = self._add_tissue_disease_paths(retrieval_data, matched_nodes)
        
        # Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¯Ø±Ù…Ø§Ù† Ø¨ÛŒÙ…Ø§Ø±ÛŒØŒ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†ÛŒ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
        if 'CtD' in target_metaedges:
            retrieval_data = self._add_treatment_paths(retrieval_data, matched_nodes)
        
        return retrieval_data
    
    def _add_tissue_disease_paths(self, retrieval_data: Dict[str, Any], matched_nodes: Dict[str, str]) -> Dict[str, Any]:
        """
        Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ†’Ø¨Ø§ÙØªâ†’Ú˜Ù† Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§Ø«Ø± Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¨Ø± Ø¨Ø§ÙØªâ€ŒÙ‡Ø§
        """
        tissue_disease_paths = []
        
        # ÛŒØ§ÙØªÙ† Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± matched_nodes
        disease_nodes = []
        for token, node_id in matched_nodes.items():
            node_attrs = self.G.nodes[node_id]
            if node_attrs.get('kind') == 'Disease':
                disease_nodes.append((node_id, node_attrs['name']))
        
        # Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¨ÛŒÙ…Ø§Ø±ÛŒØŒ Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ùˆ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ§Ù† Ø´Ø¯Ù‡ Ø¯Ø± Ø¢Ù† Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†
        for disease_id, disease_name in disease_nodes:
            # ÛŒØ§ÙØªÙ† Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¨ÛŒÙ…Ø§Ø±ÛŒ (DlA)
            for neighbor in self.G.neighbors(disease_id):
                neighbor_attrs = self.G.nodes[neighbor]
                edge_data = self.G.get_edge_data(disease_id, neighbor)
                
                if edge_data and edge_data.get('metaedge') == 'DlA' and neighbor_attrs.get('kind') == 'Anatomy':
                    tissue_name = neighbor_attrs['name']
                    tissue_id = neighbor
                    
                    # ÛŒØ§ÙØªÙ† Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ§Ù† Ø´Ø¯Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø§ÙØª (AeG)
                    tissue_genes = []
                    for gene_neighbor in self.G.neighbors(tissue_id):
                        gene_attrs = self.G.nodes[gene_neighbor]
                        gene_edge_data = self.G.get_edge_data(tissue_id, gene_neighbor)
                        
                        if gene_edge_data and gene_edge_data.get('metaedge') == 'AeG' and gene_attrs.get('kind') == 'Gene':
                            gene_name = gene_attrs['name']
                            
                            # ÛŒØ§ÙØªÙ† ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø§ÛŒÙ† Ú˜Ù† (GpBP)
                            biological_processes = []
                            for bp_neighbor in self.G.neighbors(gene_neighbor):
                                bp_attrs = self.G.nodes[bp_neighbor]
                                bp_edge_data = self.G.get_edge_data(gene_neighbor, bp_neighbor)
                                
                                if bp_edge_data and bp_edge_data.get('metaedge') == 'GpBP' and bp_attrs.get('kind') == 'Biological Process':
                                    biological_processes.append(bp_attrs['name'])
                            
                            tissue_genes.append({
                                'gene_name': gene_name,
                                'biological_processes': biological_processes[:2]  # Ø­Ø¯Ø§Ú©Ø«Ø± 2 ÙØ±Ø¢ÛŒÙ†Ø¯
                            })
                    
                    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± Ú©Ø§Ù…Ù„
                    if tissue_genes:
                        tissue_disease_paths.append({
                            'disease': disease_name,
                            'tissue': tissue_name,
                            'genes': tissue_genes[:3]  # Ø­Ø¯Ø§Ú©Ø«Ø± 3 Ú˜Ù†
                        })
        
        retrieval_data['tissue_disease_paths'] = tissue_disease_paths
        return retrieval_data
    
    def _add_treatment_paths(self, retrieval_data: Dict[str, Any], matched_nodes: Dict[str, str]) -> Dict[str, Any]:
        """
        Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†ÛŒ Compoundâ†’Diseaseâ†’Gene Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¯Ø±Ù…Ø§Ù†
        """
        treatment_paths = []
        
        # ÛŒØ§ÙØªÙ† Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± matched_nodes
        disease_nodes = []
        for token, node_id in matched_nodes.items():
            node_attrs = self.G.nodes[node_id]
            if node_attrs.get('kind') == 'Disease':
                disease_nodes.append((node_id, node_attrs['name']))
        
        # Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¨ÛŒÙ…Ø§Ø±ÛŒØŒ Ø¯Ø§Ø±ÙˆÙ‡Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†ÛŒ Ùˆ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†
        for disease_id, disease_name in disease_nodes:
            # ÛŒØ§ÙØªÙ† Ø¯Ø§Ø±ÙˆÙ‡Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†ÛŒ (CtD)
            for neighbor in self.G.neighbors(disease_id):
                neighbor_attrs = self.G.nodes[neighbor]
                edge_data = self.G.get_edge_data(disease_id, neighbor)
                
                if edge_data and edge_data.get('metaedge') == 'CtD' and neighbor_attrs.get('kind') == 'Compound':
                    drug_name = neighbor_attrs['name']
                    drug_id = neighbor
                    
                    # ÛŒØ§ÙØªÙ† Ú˜Ù†â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡ ØªÙˆØ³Ø· Ø§ÛŒÙ† Ø¯Ø§Ø±Ùˆ (CuG, CdG)
                    drug_genes = []
                    for gene_neighbor in self.G.neighbors(drug_id):
                        gene_attrs = self.G.nodes[gene_neighbor]
                        gene_edge_data = self.G.get_edge_data(drug_id, gene_neighbor)
                        
                        if gene_edge_data and gene_edge_data.get('metaedge') in ['CuG', 'CdG'] and gene_attrs.get('kind') == 'Gene':
                            gene_name = gene_attrs['name']
                            
                            # ÛŒØ§ÙØªÙ† ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø§ÛŒÙ† Ú˜Ù† (GpBP)
                            biological_processes = []
                            for bp_neighbor in self.G.neighbors(gene_neighbor):
                                bp_attrs = self.G.nodes[bp_neighbor]
                                bp_edge_data = self.G.get_edge_data(gene_neighbor, bp_neighbor)
                                
                                if bp_edge_data and bp_edge_data.get('metaedge') == 'GpBP' and bp_attrs.get('kind') == 'Biological Process':
                                    biological_processes.append(bp_attrs['name'])
                            
                            drug_genes.append({
                                'gene_name': gene_name,
                                'regulation': gene_edge_data.get('metaedge'),
                                'biological_processes': biological_processes[:2]  # Ø­Ø¯Ø§Ú©Ø«Ø± 2 ÙØ±Ø¢ÛŒÙ†Ø¯
                            })
                    
                    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± Ú©Ø§Ù…Ù„
                    if drug_genes:
                        treatment_paths.append({
                            'disease': disease_name,
                            'drug': drug_name,
                            'genes': drug_genes[:3]  # Ø­Ø¯Ø§Ú©Ø«Ø± 3 Ú˜Ù†
                        })
        
        retrieval_data['treatment_paths'] = treatment_paths
        return retrieval_data
    
    def _get_target_metaedges_for_question(self, question_type: str, query: str) -> List[str]:
        """
        ØªØ¹ÛŒÛŒÙ† metaedge Ù‡Ø§ÛŒ Ù‡Ø¯Ù Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„
        """
        query_lower = query.lower()
        
        # Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¨ÛŒØ§Ù† Ú˜Ù† Ø¯Ø± Ø¨Ø§ÙØªâ€ŒÙ‡Ø§
        if any(word in query_lower for word in ['expressed', 'express', 'expression']):
            if any(word in query_lower for word in ['heart', 'cardiac', 'myocardium']):
                return ['AeG', 'AuG', 'AdG']  # Ø¨ÛŒØ§Ù†ØŒ ØªÙ†Ø¸ÛŒÙ… Ù…Ø«Ø¨ØªØŒ ØªÙ†Ø¸ÛŒÙ… Ù…Ù†ÙÛŒ
            elif any(word in query_lower for word in ['brain', 'neural', 'cerebral']):
                return ['AeG', 'AuG', 'AdG']
            elif any(word in query_lower for word in ['liver', 'hepatic']):
                return ['AeG', 'AuG', 'AdG']
            else:
                return ['AeG', 'AuG', 'AdG']
        
        # Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú˜Ù†â€ŒÙ‡Ø§ Ùˆ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§
        elif any(word in query_lower for word in ['disease', 'cancer', 'diabetes', 'alzheimer']):
            # Ø¨Ø±Ø±Ø³ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§Ø«Ø± Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¨Ø± Ø¨Ø§ÙØªâ€ŒÙ‡Ø§
            if any(word in query_lower for word in ['tissue', 'tissues', 'affect', 'effect', 'localize']):
                return ['DlA', 'DuG', 'DdG', 'AeG', 'AuG', 'AdG', 'GpBP']  # Ø¨ÛŒÙ…Ø§Ø±ÛŒâ†’Ø¨Ø§ÙØªØŒ ØªÙ†Ø¸ÛŒÙ… Ú˜Ù†ØŒ Ø¨ÛŒØ§Ù† Ú˜Ù†ØŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø²ÛŒØ³ØªÛŒ
            else:
                return ['DaG', 'DuG', 'DdG']  # Ù…Ø±ØªØ¨Ø·ØŒ ØªÙ†Ø¸ÛŒÙ… Ù…Ø«Ø¨ØªØŒ ØªÙ†Ø¸ÛŒÙ… Ù…Ù†ÙÛŒ
        
        # Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¯Ø§Ø±ÙˆÙ‡Ø§ Ùˆ Ø¯Ø±Ù…Ø§Ù†
        elif any(word in query_lower for word in ['drug', 'treat', 'compound', 'medication']):
            return ['CtD', 'CuG', 'CdG', 'CbG']  # Ø¯Ø±Ù…Ø§Ù†ØŒ ØªÙ†Ø¸ÛŒÙ… Ù…Ø«Ø¨ØªØŒ ØªÙ†Ø¸ÛŒÙ… Ù…Ù†ÙÛŒØŒ Ø§ØªØµØ§Ù„
        
        # Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ
        elif any(word in query_lower for word in ['process', 'function', 'biological']):
            return ['GpBP', 'GpMF', 'GpCC']  # ÙØ±Ø¢ÛŒÙ†Ø¯ØŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ØŒ Ø§Ø¬Ø²Ø§ÛŒ Ø³Ù„ÙˆÙ„ÛŒ
        
        # Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ
        elif any(word in query_lower for word in ['pathway', 'signaling', 'metabolism']):
            return ['GpPW']  # Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ
        
        # Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ØªØ¹Ø§Ù…Ù„ Ú˜Ù†â€ŒÙ‡Ø§
        elif any(word in query_lower for word in ['interact', 'regulate', 'covary']):
            return ['GiG', 'Gr>G', 'GcG']  # ØªØ¹Ø§Ù…Ù„ØŒ ØªÙ†Ø¸ÛŒÙ…ØŒ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
        
        # Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¹Ù„Ø§Ø¦Ù… Ùˆ Ø¹ÙˆØ§Ø±Ø¶
        elif any(word in query_lower for word in ['symptom', 'side effect', 'adverse']):
            return ['DpS', 'CcSE']  # Ø¹Ù„Ø§Ø¦Ù… Ø¨ÛŒÙ…Ø§Ø±ÛŒØŒ Ø¹ÙˆØ§Ø±Ø¶ Ø¬Ø§Ù†Ø¨ÛŒ
        
        # Ø³ÙˆØ§Ù„Ø§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ùˆ Ú†Ù†Ø¯Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ
        else:
            return ['AeG', 'DaG', 'GpBP', 'GpPW', 'GiG']  # ØªØ±Ú©ÛŒØ¨ÛŒ Ø§Ø² Ø±ÙˆØ§Ø¨Ø· Ù…Ù‡Ù…
    
    def _enrich_primary_genes(self, retrieval_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ØºÙ†ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø¶Ø§ÙÛŒ
        """
        enriched_genes = []
        
        for gene_info in retrieval_data['primary_genes']:
            gene_name = gene_info['name']
            gene_id = None
            
            # ÛŒØ§ÙØªÙ† ID Ú˜Ù†
            for node_id, attrs in self.G.nodes(data=True):
                if attrs.get('name') == gene_name and attrs.get('kind') == 'Gene':
                    gene_id = node_id
                    break
            
            if gene_id:
                enriched_gene = {
                    **gene_info,
                    'biological_processes': [],
                    'pathways': [],
                    'diseases': [],
                    'interacting_genes': [],
                    'molecular_functions': [],
                    'cellular_components': []
                }
                
                # ÛŒØ§ÙØªÙ† ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ù…Ø±ØªØ¨Ø·
                for neighbor in self.G.neighbors(gene_id):
                    neighbor_attrs = self.G.nodes[neighbor]
                    edge_data = self.G.get_edge_data(gene_id, neighbor)
                    
                    if edge_data:
                        metaedge = edge_data.get('metaedge', '')
                        
                        if metaedge == 'GpBP' and neighbor_attrs.get('kind') == 'Biological Process':
                            enriched_gene['biological_processes'].append(neighbor_attrs['name'])
                        elif metaedge == 'GpPW' and neighbor_attrs.get('kind') == 'Pathway':
                            enriched_gene['pathways'].append(neighbor_attrs['name'])
                        elif metaedge == 'DaG' and neighbor_attrs.get('kind') == 'Disease':
                            enriched_gene['diseases'].append(neighbor_attrs['name'])
                        elif metaedge == 'GiG' and neighbor_attrs.get('kind') == 'Gene':
                            enriched_gene['interacting_genes'].append(neighbor_attrs['name'])
                        elif metaedge == 'GpMF' and neighbor_attrs.get('kind') == 'Molecular Function':
                            enriched_gene['molecular_functions'].append(neighbor_attrs['name'])
                        elif metaedge == 'GpCC' and neighbor_attrs.get('kind') == 'Cellular Component':
                            enriched_gene['cellular_components'].append(neighbor_attrs['name'])
                
                enriched_genes.append(enriched_gene)
        
        retrieval_data['primary_genes'] = enriched_genes
        return retrieval_data
    
    def _create_structured_text_for_model(self, retrieval_data: Dict[str, Any], query: str) -> str:
        """
        Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù†ÛŒ
        """
        context_parts = []
        
        # 1. Ø³ÙˆØ§Ù„ Ø§ØµÙ„ÛŒ
        context_parts.append(f"**Query:** {query}")
        context_parts.append("")
        
        # 2. Ø®Ù„Ø§ØµÙ‡ Ø¢Ù…Ø§Ø±ÛŒ Ø¯Ù‚ÛŒÙ‚
        total_genes_in_graph = 14010  # ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ú˜Ù†â€ŒÙ‡Ø§ Ø¯Ø± Hetionet
        primary_genes = len(retrieval_data['primary_genes'])
        secondary_genes = len(retrieval_data['secondary_genes'])
        total_found = primary_genes + secondary_genes
        
        context_parts.append("**Graph Summary:**")
        context_parts.append(f"â€¢ Total genes in Hetionet: {total_genes_in_graph:,}")
        context_parts.append(f"â€¢ Genes found for this query: {total_found}")
        context_parts.append(f"â€¢ Primary genes (direct relationships): {primary_genes}")
        context_parts.append(f"â€¢ Secondary genes (indirect relationships): {secondary_genes}")
        
        # Ù†Ù…Ø§ÛŒØ´ Ø±ÙˆØ§Ø¨Ø· Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡
        if retrieval_data['metaedges_used']:
            metaedge_descriptions = {
                'AeG': 'Anatomyâ€“expressesâ€“Gene',
                'AuG': 'Anatomyâ€“upregulatesâ€“Gene',
                'AdG': 'Anatomyâ€“downregulatesâ€“Gene',
                'DaG': 'Diseaseâ€“associatesâ€“Gene',
                'DuG': 'Diseaseâ€“upregulatesâ€“Gene',
                'DdG': 'Diseaseâ€“downregulatesâ€“Gene',
                'CtD': 'Compoundâ€“treatsâ€“Disease',
                'CuG': 'Compoundâ€“upregulatesâ€“Gene',
                'CdG': 'Compoundâ€“downregulatesâ€“Gene',
                'CbG': 'Compoundâ€“bindsâ€“Gene',
                'GpBP': 'Geneâ€“participatesâ€“Biological Process',
                'GpPW': 'Geneâ€“participatesâ€“Pathway',
                'GpMF': 'Geneâ€“participatesâ€“Molecular Function',
                'GpCC': 'Geneâ€“participatesâ€“Cellular Component',
                'GiG': 'Geneâ€“interactsâ€“Gene',
                'Gr>G': 'Geneâ€“regulatesâ€“Gene',
                'GcG': 'Geneâ€“covariesâ€“Gene',
                'DpS': 'Diseaseâ€“presentsâ€“Symptom',
                'DlA': 'Diseaseâ€“localizesâ€“Anatomy',
                'CcSE': 'Compoundâ€“causesâ€“Side Effect'
            }
            
            relationships_used = []
            for metaedge in retrieval_data['metaedges_used']:
                desc = metaedge_descriptions.get(metaedge, metaedge)
                relationships_used.append(f"{metaedge}: {desc}")
            
            context_parts.append(f"â€¢ Relationships used: {len(retrieval_data['metaedges_used'])} ({', '.join(relationships_used)})")
        
        context_parts.append("")
        
        # 3. Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØºÙ†ÛŒ (Ø­Ø¯Ø§Ú©Ø«Ø± 3 Ú˜Ù†)
        if retrieval_data['primary_genes']:
            context_parts.append("**Key Results:**")
            context_parts.append("The following genes were identified:")
            context_parts.append("")
            
            for gene in retrieval_data['primary_genes'][:3]:  # Ø­Ø¯Ø§Ú©Ø«Ø± 3 Ú˜Ù†
                relation_desc = {
                    'AeG': 'expressed in',
                    'AuG': 'upregulated in',
                    'AdG': 'downregulated in',
                    'DaG': 'associated with disease',
                    'DuG': 'upregulated in disease',
                    'DdG': 'downregulated in disease'
                }.get(gene['metaedge'], gene['metaedge'])
                
                # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ØµÙ„ÛŒ Ú˜Ù† (Ø®Ù„Ø§ØµÙ‡â€ŒØªØ±)
                gene_info = f"â€¢ **{gene['name']}** â€“ {relation_desc}"
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ³ØªÛŒ
                if gene.get('biological_processes'):
                    gene_info += f" ({gene['biological_processes'][0]})"
                elif gene.get('diseases'):
                    gene_info += f" ({gene['diseases'][0]})"
                elif gene.get('pathways'):
                    gene_info += f" ({gene['pathways'][0]})"
                
                context_parts.append(gene_info)
            context_parts.append("")
        
        # 4. ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ù…Ø±ØªØ¨Ø·
        if retrieval_data['biological_processes']:
            context_parts.append("**Related Biological Processes:**")
            for process in retrieval_data['biological_processes'][:3]:
                context_parts.append(f"â€¢ {process['name']}")
            context_parts.append("")
        
        # 5. Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ù…Ø±ØªØ¨Ø·
        if retrieval_data['pathways']:
            context_parts.append("**Related Pathways:**")
            for pathway in retrieval_data['pathways'][:3]:
                context_parts.append(f"â€¢ {pathway['name']}")
            context_parts.append("")
        
        # 6. Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
        if retrieval_data['diseases']:
            context_parts.append("**Related Diseases:**")
            for disease in retrieval_data['diseases'][:3]:
                context_parts.append(f"â€¢ {disease['name']}")
            context_parts.append("")
        
        # 7. Ø¯Ø§Ø±ÙˆÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
        if retrieval_data['compound']:
            context_parts.append("**Related Drugs/Compounds:**")
            for drug in retrieval_data['compound'][:3]:
                context_parts.append(f"â€¢ {drug['name']}")
            context_parts.append("")
        
        # 8. Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ†’Ø¨Ø§ÙØªâ†’Ú˜Ù† (Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§Ø«Ø± Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¨Ø± Ø¨Ø§ÙØªâ€ŒÙ‡Ø§)
        if retrieval_data.get('tissue_disease_paths'):
            context_parts.append("**Disease-Tissue-Gene Pathways:**")
            context_parts.append("The following pathways show how diseases affect specific tissues and their genes:")
            context_parts.append("")
            
            for path in retrieval_data['tissue_disease_paths'][:3]:  # Ø­Ø¯Ø§Ú©Ø«Ø± 3 Ù…Ø³ÛŒØ±
                context_parts.append(f"â€¢ **{path['disease']}** â†’ affects â†’ **{path['tissue']}**")
                for gene_info in path['genes']:
                    gene_desc = f"  - **{gene_info['gene_name']}**"
                    if gene_info['biological_processes']:
                        gene_desc += f" ({gene_info['biological_processes'][0]})"
                    context_parts.append(gene_desc)
                context_parts.append("")
        
        # 9. Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†ÛŒ Ø¯Ø§Ø±Ùˆâ†’Ø¨ÛŒÙ…Ø§Ø±ÛŒâ†’Ú˜Ù† (Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¯Ø±Ù…Ø§Ù†)
        if retrieval_data.get('treatment_paths'):
            context_parts.append("**Treatment-Disease-Gene Pathways:**")
            context_parts.append("The following pathways show how drugs treat diseases by regulating genes:")
            context_parts.append("")
            
            for path in retrieval_data['treatment_paths'][:3]:  # Ø­Ø¯Ø§Ú©Ø«Ø± 3 Ù…Ø³ÛŒØ±
                context_parts.append(f"â€¢ **{path['drug']}** â†’ treats â†’ **{path['disease']}**")
                for gene_info in path['genes']:
                    regulation = "upregulates" if gene_info['regulation'] == 'CuG' else "downregulates"
                    gene_desc = f"  - **{gene_info['gene_name']}** ({regulation})"
                    if gene_info['biological_processes']:
                        gene_desc += f" ({gene_info['biological_processes'][0]})"
                    context_parts.append(gene_desc)
                context_parts.append("")
        
        # 10. Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ú©ÙˆØªØ§Ù‡ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ
        context_parts.append("**Instructions:** Analyze biological relevance and clinical importance of these genes.")
        
        # Ø­Ø°Ù Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ø§Ø² Ù…ØªÙ† Ù†Ù‡Ø§ÛŒÛŒ
        final_text = "\n".join(context_parts)
        return remove_emojis(final_text)
    
    def test_targeted_retrieval(self, query: str) -> Dict[str, Any]:
        """
        ØªØ³Øª Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù‡Ø¯ÙÙ…Ù†Ø¯ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
        """
        print(f"ØªØ³Øª Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù‡Ø¯ÙÙ…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„: {query}")
        print("=" * 60)
        
        # ØªØ­Ù„ÛŒÙ„ Ø³ÙˆØ§Ù„
        intent = self.analyze_question_intent(query)
        print(f"Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡: {intent.get('question_type', 'unknown')}")
        
        # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù‡Ø¯ÙÙ…Ù†Ø¯
        retrieval_data = self._targeted_retrieval_for_question(query, intent)
        
        # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
        print(f"\nÙ†ØªØ§ÛŒØ¬ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ:")
        print(f"â€¢ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ: {len(retrieval_data['primary_genes'])}")
        print(f"â€¢ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø«Ø§Ù†ÙˆÛŒÙ‡: {len(retrieval_data['secondary_genes'])}")
        print(f"â€¢ ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ: {len(retrieval_data['biological_processes'])}")
        print(f"â€¢ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ: {len(retrieval_data['pathways'])}")
        print(f"â€¢ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§: {len(retrieval_data['diseases'])}")
        print(f"â€¢ Ø¯Ø§Ø±ÙˆÙ‡Ø§: {len(retrieval_data['compound'])}")
        print(f"â€¢ Ø¨Ø§ÙØªâ€ŒÙ‡Ø§: {len(retrieval_data['anatomy'])}")
        
        # Ù†Ù…Ø§ÛŒØ´ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª
        if retrieval_data['primary_genes']:
            print(f"\nÚ˜Ù†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡:")
            for i, gene in enumerate(retrieval_data['primary_genes'][:5], 1):
                print(f"{i}. {gene['name']} ({gene['metaedge']}) - Ø§Ù…ØªÛŒØ§Ø²: {gene['score']:.2f}")
                
                if gene.get('biological_processes'):
                    print(f"   ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ: {', '.join(gene['biological_processes'][:2])}")
                if gene.get('pathways'):
                    print(f"   Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ: {', '.join(gene['pathways'][:2])}")
                if gene.get('diseases'):
                    print(f"   Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·: {', '.join(gene['diseases'][:2])}")
                if gene.get('interacting_genes'):
                    print(f"   Ú˜Ù†â€ŒÙ‡Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ: {', '.join(gene['interacting_genes'][:3])}")
                print()
        
        # Ù†Ù…Ø§ÛŒØ´ Ù…ØªÙ† Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡
        structured_text = self._create_structured_text_for_model(retrieval_data, query)
        print(f"ğŸ“ Ù…ØªÙ† Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„:")
        print("-" * 40)
        print(structured_text)
        print("-" * 40)
        
        return {
            'query': query,
            'intent': intent,
            'retrieval_data': retrieval_data,
            'structured_text': structured_text
        }
    
    def test_compact_retrieval(self, query: str) -> Dict[str, Any]:
        """
        ØªØ³Øª Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø®Ù„Ø§ØµÙ‡ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù…ØªÙ† Ú©ÙˆØªØ§Ù‡
        """
        print(f"ğŸ§ª ØªØ³Øª Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø®Ù„Ø§ØµÙ‡ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„: {query}")
        print("=" * 50)
        
        # ØªØ­Ù„ÛŒÙ„ Ø³ÙˆØ§Ù„
        intent = self.analyze_question_intent(query)
        print(f"ğŸ“‹ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„: {intent.get('question_type', 'unknown')}")
        
        # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù‡Ø¯ÙÙ…Ù†Ø¯
        retrieval_data = self._targeted_retrieval_for_question(query, intent)
        
        # Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬
        print(f"\nğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬:")
        print(f"â€¢ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ: {len(retrieval_data['primary_genes'])}")
        print(f"â€¢ ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ: {len(retrieval_data['biological_processes'])}")
        print(f"â€¢ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ: {len(retrieval_data['pathways'])}")
        print(f"â€¢ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§: {len(retrieval_data['diseases'])}")
        print(f"â€¢ Ø¯Ø§Ø±ÙˆÙ‡Ø§: {len(retrieval_data['compound'])}")
        
        # Ù†Ù…Ø§ÛŒØ´ Ù…ØªÙ† Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡
        structured_text = self._create_structured_text_for_model(retrieval_data, query)
        print(f"\nğŸ“ Ù…ØªÙ† Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„:")
        print("-" * 50)
        print(structured_text)
        print("-" * 50)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø·ÙˆÙ„ Ù…ØªÙ†
        text_length = len(structured_text)
        print(f"\nğŸ“ Ø·ÙˆÙ„ Ù…ØªÙ†: {text_length} Ú©Ø§Ø±Ø§Ú©ØªØ±")
        
        # ØªØ­Ù„ÛŒÙ„ Ú©ÛŒÙÛŒØª Ù…ØªÙ†
        if text_length > 1500:
            print("âš ï¸ Ù…ØªÙ† Ø®ÛŒÙ„ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø§Ø³Øª!")
        elif text_length > 800:
            print("âš ï¸ Ù…ØªÙ† Ù…ØªÙˆØ³Ø· Ø§Ø³Øª")
        elif text_length > 400:
            print("âœ… Ù…ØªÙ† Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª")
        else:
            print("âœ… Ù…ØªÙ† Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¹Ø§Ù„ÛŒ Ø§Ø³Øª")
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ú©ÛŒÙÛŒØª Ù…Ø­ØªÙˆØ§
        if retrieval_data['primary_genes']:
            genes_with_info = sum(1 for gene in retrieval_data['primary_genes'] 
                                if gene.get('biological_processes') or gene.get('pathways') or gene.get('diseases'))
            print(f"ğŸ“Š Ú©ÛŒÙÛŒØª Ù…Ø­ØªÙˆØ§: {genes_with_info}/{len(retrieval_data['primary_genes'])} Ú˜Ù† Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ³ØªÛŒ")
        
        if retrieval_data['metaedges_used']:
            print(f"ğŸ”— Ø±ÙˆØ§Ø¨Ø· Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡: {len(retrieval_data['metaedges_used'])} Ù†ÙˆØ¹")
        
        return {
            'query': query,
            'intent': intent,
            'retrieval_data': retrieval_data,
            'structured_text': structured_text,
            'text_length': text_length
        }
    
    def generate_answer(self, retrieval_result: RetrievalResult, 
                       model: GenerationModel, text_generation_type: str = 'INTELLIGENT') -> GenerationResult:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ØªØ§ÛŒØ¬ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ"""
        print(f"ğŸ¤– ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ Ù…Ø¯Ù„ {model.value} Ùˆ Ù†ÙˆØ¹ {text_generation_type}...")
        # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø¢Ù…Ø§Ø¯Ù‡ Ø¨ÙˆØ¯Ù† PageRank Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø¶Ù…Ù†ÛŒ
        self._ensure_pagerank()
        
        # Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ†
        if text_generation_type == 'SIMPLE':
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡
            if model == GenerationModel.GENERAL_SIMPLE:
                answer = self.general_simple_generation(retrieval_result)
                confidence = 0.8
            elif model == GenerationModel.SIMPLE:
                answer = self.simple_template_generation(retrieval_result)
                confidence = 0.7
            elif model == GenerationModel.GPT_SIMULATION:
                answer = self.gpt_simulation_generation(retrieval_result)
                confidence = 0.85
            elif model == GenerationModel.CUSTOM:
                answer = self.custom_generation(retrieval_result)
                confidence = 0.9
            elif model == GenerationModel.HUGGINGFACE:
                answer = self.huggingface_generation(retrieval_result)
                confidence = 0.92
            # OpenAI GPT Models
            elif model in [GenerationModel.OPENAI_GPT_4O, GenerationModel.OPENAI_GPT_4O_MINI, 
                          GenerationModel.OPENAI_GPT_4_TURBO, GenerationModel.OPENAI_GPT_4,
                          GenerationModel.OPENAI_GPT_3_5_TURBO, GenerationModel.OPENAI_GPT_3_5_TURBO_16K,
                          GenerationModel.OPENAI_GPT]:  # Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ Ù…Ø¯Ù„ Ù‚Ø¯ÛŒÙ…ÛŒ
                answer = self.openai_gpt_generation(retrieval_result, model)
                confidence = 0.95
            # Anthropic Claude Models
            elif model in [GenerationModel.ANTHROPIC_CLAUDE_3_5_SONNET, GenerationModel.ANTHROPIC_CLAUDE_3_5_HAIKU,
                          GenerationModel.ANTHROPIC_CLAUDE_3_OPUS, GenerationModel.ANTHROPIC_CLAUDE_3_SONNET,
                          GenerationModel.ANTHROPIC_CLAUDE_3_HAIKU, GenerationModel.ANTHROPIC_CLAUDE]:  # Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ
                answer = self.anthropic_claude_generation(retrieval_result, model)
                confidence = 0.94
            # Google Gemini Models
            elif model in [GenerationModel.GOOGLE_GEMINI_1_5_PRO, GenerationModel.GOOGLE_GEMINI_1_5_FLASH,
                          GenerationModel.GOOGLE_GEMINI_1_0_PRO, GenerationModel.GOOGLE_GEMINI_1_0_FLASH,
                          GenerationModel.GOOGLE_GEMINI]:  # Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ
                answer = self.google_gemini_generation(retrieval_result, model)
                confidence = 0.93
            # Ø³Ø§ÛŒØ± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
            elif model == GenerationModel.META_LLAMA_3_1:
                answer = self.meta_llama_generation(retrieval_result)
                confidence = 0.91
            elif model == GenerationModel.MISTRAL_AI:
                answer = self.mistral_ai_generation(retrieval_result)
                confidence = 0.90
            elif model == GenerationModel.COHERE_COMMAND:
                answer = self.cohere_command_generation(retrieval_result)
                confidence = 0.89
            elif model == GenerationModel.PERPLEXITY_SONAR:
                answer = self.perplexity_sonar_generation(retrieval_result)
                confidence = 0.88
            else:
                answer = "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."
                confidence = 0.0
        else:  # INTELLIGENT
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ùˆ ØªØ®ØµØµÛŒ (Ù‡Ù…Ø§Ù† Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ø¯ÛŒ Ø¨Ø§ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯)
            if model == GenerationModel.GENERAL_SIMPLE:
                answer = self.general_simple_generation(retrieval_result)
                confidence = 0.85
            elif model == GenerationModel.SIMPLE:
                answer = self.simple_template_generation(retrieval_result)
                confidence = 0.8
            elif model == GenerationModel.GPT_SIMULATION:
                answer = self.gpt_simulation_generation(retrieval_result)
                confidence = 0.9
            elif model == GenerationModel.CUSTOM:
                answer = self.custom_generation(retrieval_result)
                confidence = 0.95
            elif model == GenerationModel.HUGGINGFACE:
                answer = self.huggingface_generation(retrieval_result)
                confidence = 0.92
            # OpenAI GPT Models (Intelligent)
            elif model in [GenerationModel.OPENAI_GPT_4O, GenerationModel.OPENAI_GPT_4O_MINI, 
                          GenerationModel.OPENAI_GPT_4_TURBO, GenerationModel.OPENAI_GPT_4,
                          GenerationModel.OPENAI_GPT_3_5_TURBO, GenerationModel.OPENAI_GPT_3_5_TURBO_16K,
                          GenerationModel.OPENAI_GPT]:  # Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ Ù…Ø¯Ù„ Ù‚Ø¯ÛŒÙ…ÛŒ
                answer = self.openai_gpt_generation(retrieval_result, model)
                confidence = 0.97
            # Anthropic Claude Models (Intelligent)
            elif model in [GenerationModel.ANTHROPIC_CLAUDE_3_5_SONNET, GenerationModel.ANTHROPIC_CLAUDE_3_5_HAIKU,
                          GenerationModel.ANTHROPIC_CLAUDE_3_OPUS, GenerationModel.ANTHROPIC_CLAUDE_3_SONNET,
                          GenerationModel.ANTHROPIC_CLAUDE_3_HAIKU, GenerationModel.ANTHROPIC_CLAUDE]:  # Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ
                answer = self.anthropic_claude_generation(retrieval_result, model)
                confidence = 0.96
            # Google Gemini Models (Intelligent)
            elif model in [GenerationModel.GOOGLE_GEMINI_1_5_PRO, GenerationModel.GOOGLE_GEMINI_1_5_FLASH,
                          GenerationModel.GOOGLE_GEMINI_1_0_PRO, GenerationModel.GOOGLE_GEMINI_1_0_FLASH,
                          GenerationModel.GOOGLE_GEMINI]:  # Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ
                answer = self.google_gemini_generation(retrieval_result, model)
                confidence = 0.95
            # Ø³Ø§ÛŒØ± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ (Intelligent)
            elif model == GenerationModel.META_LLAMA_3_1:
                answer = self.meta_llama_generation(retrieval_result)
                confidence = 0.93
            elif model == GenerationModel.MISTRAL_AI:
                answer = self.mistral_ai_generation(retrieval_result)
                confidence = 0.92
            elif model == GenerationModel.COHERE_COMMAND:
                answer = self.cohere_command_generation(retrieval_result)
                confidence = 0.91
            elif model == GenerationModel.PERPLEXITY_SONAR:
                answer = self.perplexity_sonar_generation(retrieval_result)
                confidence = 0.90
            else:
                answer = "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."
                confidence = 0.0
        
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ context_text Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ†
        if text_generation_type == 'SIMPLE':
            retrieval_result.context_text = self._create_simple_context_text(retrieval_result)
        elif text_generation_type == 'ADVANCED':
            retrieval_result.context_text = self._create_advanced_context_text(retrieval_result)
        elif text_generation_type == 'SCIENTIFIC_ANALYTICAL':
            retrieval_result.context_text = self._create_scientific_analytical_context(retrieval_result)
        elif text_generation_type == 'NARRATIVE_DESCRIPTIVE':
            retrieval_result.context_text = self._create_narrative_context(retrieval_result)
        elif text_generation_type == 'DATA_DRIVEN':
            retrieval_result.context_text = self._create_data_driven_context(retrieval_result)
        elif text_generation_type == 'STEP_BY_STEP':
            retrieval_result.context_text = self._create_step_by_step_context(retrieval_result)
        elif text_generation_type == 'CONCISE_DIRECT':
            retrieval_result.context_text = self._create_compact_direct_context(retrieval_result)
        else:  # INTELLIGENT
            retrieval_result.context_text = self._create_intelligent_context_text(retrieval_result)
        
        return GenerationResult(
            answer=answer,
            model=model.value,
            context_used=retrieval_result.context_text,
            confidence=confidence
        )
    
    def general_simple_generation(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø³Ø§Ø¯Ù‡ Ùˆ Ø¹Ù…ÙˆÙ…ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„Ø§Øª"""
        query = retrieval_result.query
        context = retrieval_result.context_text
        method = retrieval_result.method
        
        # Ø§Ú¯Ø± Ø¨Ø¯ÙˆÙ† Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¨Ø§Ø´Ø¯
        if method == "Ø¨Ø¯ÙˆÙ† Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ (ÙÙ‚Ø· Ù…Ø¯Ù„)":
            return f"""ğŸ¤– **Ù¾Ø§Ø³Ø® Ø¹Ù…ÙˆÙ…ÛŒ Ø¨Ù‡ Ø³ÙˆØ§Ù„ Ø´Ù…Ø§:**

**Ø³ÙˆØ§Ù„:** {query}

Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ù†Ø´ Ø¹Ù…ÙˆÙ…ÛŒ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø²ÛŒØ³Øªâ€ŒÙ¾Ø²Ø´Ú©ÛŒØŒ Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø¨Ù‡ Ø´Ø±Ø­ Ø²ÛŒØ± Ø§Ø³Øª:

{self._generate_general_knowledge_answer(query)}

---
ğŸ’¡ **Ù†Ú©ØªÙ‡:** Ø§ÛŒÙ† Ù¾Ø§Ø³Ø® Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ù†Ø´ Ø¹Ù…ÙˆÙ…ÛŒ Ù…Ø¯Ù„ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ùˆ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ø§ÙØŒ Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."""

        # Ø§Ú¯Ø± Ø¨Ø§ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¨Ø§Ø´Ø¯
        if not context or context.strip() == "":
            return f"""âŒ **Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯**

**Ø³ÙˆØ§Ù„:** {query}

Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø³ÙˆØ§Ù„ Ø´Ù…Ø§ Ø¯Ø± Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯. 

ğŸ’¡ **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª:**
â€¢ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯
â€¢ Ø§Ø² Ø±ÙˆØ´ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
â€¢ Ø³ÙˆØ§Ù„ Ø±Ø§ Ø¨Ù‡ Ø´Ú©Ù„ Ø¯ÛŒÚ¯Ø±ÛŒ Ù…Ø·Ø±Ø­ Ú©Ù†ÛŒØ¯"""

        # Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ø³Ø§Ø¯Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡
        simple_context = self._create_simple_context_text(retrieval_result)
        
        # ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø® Ù…Ù†Ø§Ø³Ø¨
        query_lower = query.lower()
        
        # ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„
        if any(word in query_lower for word in ["cancer", "tumor", "malignant"]):
            return self._generate_cancer_related_answer(retrieval_result)
        elif any(word in query_lower for word in ["gene", "protein", "express"]):
            return self._generate_gene_related_answer(retrieval_result)
        elif any(word in query_lower for word in ["drug", "medicine", "treatment", "therapy"]):
            return self._generate_drug_related_answer(retrieval_result)
        elif any(word in query_lower for word in ["disease", "disorder", "condition"]):
            return self._generate_disease_related_answer(retrieval_result)
        elif any(word in query_lower for word in ["tissue", "organ", "anatomy", "heart", "brain", "liver"]):
            return self._generate_tissue_related_answer(retrieval_result)
        else:
            return self._generate_general_structured_answer(retrieval_result)

    def _create_simple_context_text(self, retrieval_result: RetrievalResult) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ø³Ø§Ø¯Ù‡ Ùˆ Ø¹Ù…ÙˆÙ…ÛŒ"""
        nodes = retrieval_result.nodes
        edges = retrieval_result.edges
        query = retrieval_result.query
        
        if not nodes:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        
        # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†ÙˆØ¯Ù‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹
        gene_nodes = [n for n in nodes if n.kind == 'Gene']
        disease_nodes = [n for n in nodes if n.kind == 'Disease']
        drug_nodes = [n for n in nodes if n.kind == 'Drug']
        anatomy_nodes = [n for n in nodes if n.kind == 'Anatomy']
        
        context_parts = []
        
        if gene_nodes:
            gene_names = [n.name for n in gene_nodes]
            context_parts.append(f"Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·: {', '.join(gene_names)}")
        
        if disease_nodes:
            disease_names = [n.name for n in disease_nodes]
            context_parts.append(f"Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·: {', '.join(disease_names)}")
        
        if drug_nodes:
            drug_names = [n.name for n in drug_nodes]
            context_parts.append(f"Ø¯Ø§Ø±ÙˆÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·: {', '.join(drug_names)}")
        
        if anatomy_nodes:
            anatomy_names = [n.name for n in anatomy_nodes]
            context_parts.append(f"Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·: {', '.join(anatomy_names)}")
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…
        if edges:
            important_edges = edges[:5]  # Ø­Ø¯Ø§Ú©Ø«Ø± 5 ÛŒØ§Ù„
            edge_descriptions = []
            for edge in important_edges:
                sdisp = self._display_node(edge.source)
                tdisp = self._display_node(edge.target)
                edge_descriptions.append(f"{sdisp} â†’ {tdisp} ({edge.relation})")
            if edge_descriptions:
                context_parts.append(f"Ø±Ø§Ø¨Ø·Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…: {'; '.join(edge_descriptions)}")
        
        context_text = "\n".join(context_parts) if context_parts else "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        return remove_emojis(context_text)

    def _create_scientific_analytical_context(self, retrieval_result: RetrievalResult) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ø¹Ù„Ù…ÛŒ-ØªØ­Ù„ÛŒÙ„ÛŒ (ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ)"""
        nodes = retrieval_result.nodes
        edges = retrieval_result.edges
        query = retrieval_result.query
        
        if not nodes:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¹Ù„Ù…ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        
        # ØªØ­Ù„ÛŒÙ„ Ø¹Ù„Ù…ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
        gene_nodes = [n for n in nodes if n.kind == 'Gene']
        disease_nodes = [n for n in nodes if n.kind == 'Disease']
        
        context_parts = []
        
        if gene_nodes and disease_nodes:
            context_parts.append("ØªØ­Ù„ÛŒÙ„ Ø¹Ù„Ù…ÛŒ Ø±Ø§Ø¨Ø·Ù‡ Ú˜Ù†-Ø¨ÛŒÙ…Ø§Ø±ÛŒ:")
            for gene in gene_nodes[:3]:  # Ø­Ø¯Ø§Ú©Ø«Ø± 3 Ú˜Ù†
                for disease in disease_nodes[:3]:  # Ø­Ø¯Ø§Ú©Ø«Ø± 3 Ø¨ÛŒÙ…Ø§Ø±ÛŒ
                    context_parts.append(f"â€¢ Ú˜Ù† {gene.name} Ø¨Ø§ Ø¨ÛŒÙ…Ø§Ø±ÛŒ {disease.name} Ù…Ø±ØªØ¨Ø· Ø§Ø³Øª")
        
        # ØªØ­Ù„ÛŒÙ„ ÛŒØ§Ù„â€ŒÙ‡Ø§
        if edges:
            context_parts.append("\nØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ§Ø¨Ø·:")
            for edge in edges[:5]:
                sdisp = self._display_node(edge.source)
                tdisp = self._display_node(edge.target)
                context_parts.append(f"â€¢ {sdisp} {edge.relation} {tdisp}")
        
        context_text = "\n".join(context_parts) if context_parts else "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¹Ù„Ù…ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        return remove_emojis(context_text)

    def _create_narrative_context(self, retrieval_result: RetrievalResult) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ø±ÙˆØ§ÛŒÛŒ (Ø³Ø§Ø¯Ù‡ Ùˆ ØªÙˆØµÛŒÙÛŒ)"""
        nodes = retrieval_result.nodes
        edges = retrieval_result.edges
        query = retrieval_result.query
        
        if not nodes:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªÙˆØµÛŒÙ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø³ØªØ§Ù† Ø±ÙˆØ§ÛŒÛŒ
        gene_nodes = [n for n in nodes if n.kind == 'Gene']
        disease_nodes = [n for n in nodes if n.kind == 'Disease']
        drug_nodes = [n for n in nodes if n.kind == 'Drug']
        
        narrative_parts = []
        
        if gene_nodes and disease_nodes:
            gene_names = [n.name for n in gene_nodes[:2]]
            disease_names = [n.name for n in disease_nodes[:2]]
            narrative_parts.append(f"Ú˜Ù†â€ŒÙ‡Ø§ÛŒ {', '.join(gene_names)} Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ {', '.join(disease_names)} Ù‡Ø³ØªÙ†Ø¯.")
        
        if drug_nodes:
            drug_names = [n.name for n in drug_nodes[:2]]
            narrative_parts.append(f"Ø¯Ø§Ø±ÙˆÙ‡Ø§ÛŒ {', '.join(drug_names)} Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù† Ø§ÛŒÙ† Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.")
        
        if edges:
            narrative_parts.append("Ø§ÛŒÙ† Ø±ÙˆØ§Ø¨Ø· Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø´Ø¨Ú©Ù‡ Ù¾ÛŒÚ†ÛŒØ¯Ù‡â€ŒØ§ÛŒ Ø§Ø² ØªØ¹Ø§Ù…Ù„Ø§Øª Ø²ÛŒØ³ØªÛŒ Ø§Ø³Øª.")
        
        context_text = " ".join(narrative_parts) if narrative_parts else "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªÙˆØµÛŒÙ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        return remove_emojis(context_text)

    def _create_data_driven_context(self, retrieval_result: RetrievalResult) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ…Ø­ÙˆØ± (Ø±Ø§Ø¨Ø·Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù„ÛŒØ³Øª)"""
        nodes = retrieval_result.nodes
        edges = retrieval_result.edges
        query = retrieval_result.query
        
        if not nodes and not edges:
            return "Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        
        data_parts = []
        
        # Ù„ÛŒØ³Øª Ù†ÙˆØ¯Ù‡Ø§
        if nodes:
            data_parts.append("Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡:")
            for node in nodes:
                data_parts.append(f"â€¢ {node.name} ({node.kind})")
        
        # Ù„ÛŒØ³Øª ÛŒØ§Ù„â€ŒÙ‡Ø§
        if edges:
            data_parts.append("\nØ±Ø§Ø¨Ø·Ù‡â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡:")
            for edge in edges:
                data_parts.append(f"â€¢ {edge.source} â†’ {edge.target} ({edge.relation})")
        
        context_text = "\n".join(data_parts) if data_parts else "Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        return remove_emojis(context_text)

    def _create_step_by_step_context(self, retrieval_result: RetrievalResult) -> str:
        """
        Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† ØªÙˆØ¶ÛŒØ­ Ù‚Ø¨Ù„ Ø§Ø² Ø³Ø¤Ø§Ù„ (Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ú¯Ø§Ù… Ø¨Ù‡ Ú¯Ø§Ù…)
        Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ù‡ Ø¯Ù†Ø¨Ø§Ù„ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø®Ø·ÛŒ Ù‡Ø³ØªÙ†Ø¯
        """
        nodes = retrieval_result.nodes
        edges = retrieval_result.edges
        paths = retrieval_result.paths
        query = retrieval_result.query
        
        context_parts = []
        
        # 1. Ù…Ù‚Ø¯Ù…Ù‡ Ø§Ø³ØªØ¯Ù„Ø§Ù„ÛŒ
        context_parts.append(f"**Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ú¯Ø§Ù… Ø¨Ù‡ Ú¯Ø§Ù… Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„:** {query}")
        context_parts.append("")
        context_parts.append("Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ØŒ Ù…Ø±Ø§Ø­Ù„ Ø²ÛŒØ± Ø±Ø§ Ø¯Ù†Ø¨Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…:")
        context_parts.append("")
        
        # 2. Ú¯Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ¯Ù„Ø§Ù„
        context_parts.append("**Ù…Ø±Ø§Ø­Ù„ Ø§Ø³ØªØ¯Ù„Ø§Ù„:**")
        
        if paths:
            main_path = paths[0] if paths else []
            if len(main_path) >= 2:
                context_parts.append("**Ú¯Ø§Ù… 1: Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…Ø³ÛŒØ± Ø§ØµÙ„ÛŒ**")
                path_elements = []
                from node_lookup_system import NodeLookupSystem
                lookup = NodeLookupSystem()
                for i, node in enumerate(main_path):
                    if i < len(main_path) - 1:
                        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø±Ø§Ø¨Ø·Ù‡ Ø¨ÛŒÙ† Ø§ÛŒÙ† Ù†ÙˆØ¯ Ùˆ Ù†ÙˆØ¯ Ø¨Ø¹Ø¯ÛŒ
                        relation = "â†’"
                        for edge in edges:
                            if edge.source == node and edge.target == main_path[i + 1]:
                                relation = edge.relation
                                break
                        # ØªØ¨Ø¯ÛŒÙ„ Ø¢ÛŒØ¯ÛŒ Ù†ÙˆØ¯ Ø¨Ù‡ Ù†Ø§Ù… Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±
                        node_info = lookup.get_node_info(node)
                        node_display = f"{node_info.name} ({node_info.kind})" if node_info else node
                        path_elements.append(f"{i+1}. {node_display}")
                        path_elements.append(f"   â†“ {relation}")
                    else:
                        # ØªØ¨Ø¯ÛŒÙ„ Ø¢ÛŒØ¯ÛŒ Ù†ÙˆØ¯ Ø¨Ù‡ Ù†Ø§Ù… Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±
                        node_info = lookup.get_node_info(node)
                        node_display = f"{node_info.name} ({node_info.kind})" if node_info else node
                        path_elements.append(f"{i+1}. {node_display}")
                
                context_parts.append("\n".join(path_elements))
                context_parts.append("")
        
        # 3. Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ù†Ø·Ù‚ÛŒ
        context_parts.append("**Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ù†Ø·Ù‚ÛŒ:**")
        context_parts.append("Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† Ù…Ø³ÛŒØ±ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø²ÛŒØ³ØªÛŒ Ø±Ø§ Ø¯Ø±Ú© Ú©Ù†ÛŒÙ….")
        context_parts.append("")
        
        # 4. Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ø§Ø³ØªØ¯Ù„Ø§Ù„ÛŒ
        context_parts.append("**Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„:**")
        context_parts.append("Ù…Ø±Ø§Ø­Ù„ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø±Ø§ Ø¯Ù†Ø¨Ø§Ù„ Ú©Ø±Ø¯Ù‡ Ùˆ Ù¾Ø§Ø³Ø® Ù…Ù†Ø·Ù‚ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.")
        
        # Ø­Ø°Ù Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ø§Ø² Ù…ØªÙ† Ù†Ù‡Ø§ÛŒÛŒ
        final_text = "\n".join(context_parts)
        return remove_emojis(final_text)

    def _create_compact_direct_context(self, retrieval_result: RetrievalResult) -> str:
        """
        Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† ÙØ´Ø±Ø¯Ù‡ Ùˆ Ù…Ø³ØªÙ‚ÛŒÙ…
        Ù…ÙÛŒØ¯ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡ ÙˆÙ„ÛŒ Ø¯Ù‚ÛŒÙ‚ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
        """
        nodes = retrieval_result.nodes
        edges = retrieval_result.edges
        paths = retrieval_result.paths
        query = retrieval_result.query
        
        context_parts = []
        
        # 1. Ù…Ù‚Ø¯Ù…Ù‡ ÙØ´Ø±Ø¯Ù‡
        context_parts.append(f"**Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ´Ø±Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ:** {query}")
        context_parts.append("")
        
        # 2. Ù…Ø³ÛŒØ± Ù…Ø³ØªÙ‚ÛŒÙ…
        if paths:
            main_path = paths[0] if paths else []
            if len(main_path) >= 2:
                context_parts.append("**Ù…Ø³ÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ:**")
                from node_lookup_system import NodeLookupSystem
                lookup = NodeLookupSystem()
                path_elements = []
                for node in main_path:
                    node_info = lookup.get_node_info(node)
                    node_display = f"{node_info.name} ({node_info.kind})" if node_info else node
                    path_elements.append(node_display)
                path_str = " â†’ ".join(path_elements)
                context_parts.append(f"â€¢ {path_str}")
                context_parts.append("")
        
        # 3. Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ ÙØ´Ø±Ø¯Ù‡
        context_parts.append("**Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„:** Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.")
        
        # Ø­Ø°Ù Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ø§Ø² Ù…ØªÙ† Ù†Ù‡Ø§ÛŒÛŒ
        final_text = "\n".join(context_parts)
        return remove_emojis(final_text)

    def _create_biological_pathway_context(self, retrieval_result: RetrievalResult) -> str:
        """
        Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ù…Ø³ÛŒØ± Ø²ÛŒØ³ØªÛŒ (ØªØ®ØµØµÛŒ)
        Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ Ø²ÛŒØ³ØªÛŒ
        """
        nodes = retrieval_result.nodes
        edges = retrieval_result.edges
        paths = retrieval_result.paths
        query = retrieval_result.query
        
        context_parts = []
        
        # 1. Ù…Ù‚Ø¯Ù…Ù‡ ØªØ®ØµØµÛŒ Ø¨Ø§ ØªÙ…Ø±Ú©Ø² Ø±ÙˆÛŒ Ú˜Ù† Ù…Ø±Ú©Ø²ÛŒ
        context_parts.append(f"ğŸ§¬ **ØªØ­Ù„ÛŒÙ„ Ù…Ø³ÛŒØ± Ø²ÛŒØ³ØªÛŒ Ø¨Ø±Ø§ÛŒ:** {query}")
        context_parts.append("")
        
        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú˜Ù† Ù…Ø±Ú©Ø²ÛŒ
        central_gene = self._identify_central_gene(nodes, query)
        if central_gene:
            biological_role = BIOLOGICAL_ROLES.get(central_gene, "Ú˜Ù† Ù…Ù‡Ù… Ø²ÛŒØ³ØªÛŒ")
            context_parts.append(f"ğŸ”¬ **Ú˜Ù† Ù…Ø±Ú©Ø²ÛŒ:** {central_gene} - {biological_role}")
            context_parts.append("")
        
        context_parts.append("**Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡ Ø¯Ø± Hetionet:**")
        context_parts.append("")
        
        # 2. ØªØ­Ù„ÛŒÙ„ Ù…Ø³ÛŒØ±Ù‡Ø§ Ø¨Ø§ ØªÙˆØ¶ÛŒØ­Ø§Øª ØªÙˆØµÛŒÙÛŒ
        if paths:
            context_parts.append("ğŸ›¤ï¸ **Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ:**")
            for i, path in enumerate(paths[:3]):
                context_parts.append(f"**Ù…Ø³ÛŒØ± {i+1}:**")
                for j, node in enumerate(path):
                    if j < len(path) - 1:
                        context_parts.append(f"  {self._display_node(node)} â†’")
                    else:
                        context_parts.append(f"  {self._display_node(node)}")
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØ¶ÛŒØ­ ØªÙˆØµÛŒÙÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø³ÛŒØ±
                path_description = self._create_path_description(path, edges)
                if path_description:
                    context_parts.append(f"  **ØªÙˆØ¶ÛŒØ­ Ø²ÛŒØ³ØªÛŒ:** {path_description}")
                context_parts.append("")
        else:
            context_parts.append("âš ï¸ **Ù‡Ø´Ø¯Ø§Ø±:** Ù‡ÛŒÚ† Ù…Ø³ÛŒØ± Ø²ÛŒØ³ØªÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            context_parts.append("Ø§ÛŒÙ† Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¹Ù…Ù‚ Ø¬Ø³ØªØ¬Ùˆ ÛŒØ§ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù…Ø³ÛŒØ± Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ø§Ø´Ø¯.")
            context_parts.append("")
        
        # 3. Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ø¨Ø§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ù…Ù„
        context_parts.append("âš™ï¸ **Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ:**")
        if edges:
            edge_types = {}
            for edge in edges:
                if edge.relation not in edge_types:
                    edge_types[edge.relation] = []
                edge_types[edge.relation].append(f"{self._display_node(edge.source)} â†’ {self._display_node(edge.target)}")
            
            for relation, connections in sorted(edge_types.items(), key=lambda x: len(x[1]), reverse=True)[:3]:
                desc = METAEDGE_DESCRIPTIONS.get(relation, relation)
                context_parts.append(f"â€¢ {desc} ({len(connections)} Ù…ÙˆØ±Ø¯)")
                
                # Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø±ÙˆØ§Ø¨Ø·
                for connection in connections[:2]:
                    context_parts.append(f"  - {connection}")
        context_parts.append("")
        
        # 4. ØªØ­Ù„ÛŒÙ„ Ø²ÛŒØ³ØªÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
        biological_inference = self._create_biological_inference(nodes, edges, paths, query)
        if biological_inference:
            context_parts.append("ğŸ”¬ **ØªØ­Ù„ÛŒÙ„ Ø²ÛŒØ³ØªÛŒ:**")
            context_parts.append(biological_inference)
            context_parts.append("")
        
        # 5. Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ ØªØ®ØµØµÛŒ
        context_parts.append("ğŸ”¬ **Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ ØªØ®ØµØµÛŒ:**")
        context_parts.append("ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ùˆ Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ„Ú©ÙˆÙ„ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.")
        context_parts.append("ØªÙ…Ø±Ú©Ø² Ø¨Ø±:")
        context_parts.append("â€¢ Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…ÛŒ")
        context_parts.append("â€¢ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ÛŒÙ†Ú¯")
        context_parts.append("â€¢ Ø§Ù‡Ù…ÛŒØª Ø¨Ø§Ù„ÛŒÙ†ÛŒ")
        
        context_text = "\n".join(context_parts)
        return remove_emojis(context_text)

    def _create_clinical_relevance_context(self, retrieval_result: RetrievalResult) -> str:
        """
        Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§Ù„ÛŒÙ†ÛŒ
        Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù¾Ø²Ø´Ú©ÛŒ Ùˆ Ø¯Ø±Ù…Ø§Ù†
        """
        nodes = retrieval_result.nodes
        edges = retrieval_result.edges
        paths = retrieval_result.paths
        query = retrieval_result.query
        
        context_parts = []
        
        # 1. Ù…Ù‚Ø¯Ù…Ù‡ Ø¨Ø§Ù„ÛŒÙ†ÛŒ
        context_parts.append(f"ğŸ¥ **ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ù„ÛŒÙ†ÛŒ Ø¨Ø±Ø§ÛŒ:** {query}")
        context_parts.append("")
        context_parts.append("**Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø§Ù„ÛŒÙ†ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡:**")
        context_parts.append("")
        
        # 2. Ø¹Ù†Ø§ØµØ± Ø¨Ø§Ù„ÛŒÙ†ÛŒ
        clinical_elements = []
        for node in nodes:
            if node.kind in ['Disease', 'Compound', 'Gene', 'Anatomy']:
                clinical_elements.append(f"â€¢ {node.kind}: {node.name}")
        
        if clinical_elements:
            context_parts.append("ğŸ¥ **Ø¹Ù†Ø§ØµØ± Ø¨Ø§Ù„ÛŒÙ†ÛŒ:**")
            context_parts.extend(clinical_elements[:5])
            context_parts.append("")
        
        # 3. Ø±ÙˆØ§Ø¨Ø· Ø¯Ø±Ù…Ø§Ù†ÛŒ
        therapeutic_relations = []
        for edge in edges:
            if edge.relation in ['CtD', 'CuG', 'CdG', 'DaG']:
                therapeutic_relations.append(f"â€¢ {edge.source} â†’ {edge.relation} â†’ {edge.target}")
        
        if therapeutic_relations:
            context_parts.append("ğŸ’Š **Ø±ÙˆØ§Ø¨Ø· Ø¯Ø±Ù…Ø§Ù†ÛŒ:**")
            context_parts.extend(therapeutic_relations[:3])
            context_parts.append("")
        
        # 4. Ø§Ù‡Ù…ÛŒØª Ø¨Ø§Ù„ÛŒÙ†ÛŒ
        context_parts.append("ğŸ“‹ **Ø§Ù‡Ù…ÛŒØª Ø¨Ø§Ù„ÛŒÙ†ÛŒ:**")
        context_parts.append("Ø§ÛŒÙ† Ø±ÙˆØ§Ø¨Ø· Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ú© Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†ÛŒ Ù…ÙÛŒØ¯ Ø¨Ø§Ø´Ø¯.")
        context_parts.append("")
        
        # 5. Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø§Ù„ÛŒÙ†ÛŒ
        context_parts.append("ğŸ¯ **Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø§Ù„ÛŒÙ†ÛŒ:**")
        context_parts.append("ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ù„ÛŒÙ†ÛŒ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†ÛŒ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
        
        context_text = "\n".join(context_parts)
        return remove_emojis(context_text)

    def _create_mechanistic_detailed_context(self, retrieval_result: RetrievalResult) -> str:
        """
        Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ ØªÙØµÛŒÙ„ÛŒ
        Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÛŒÙ‚ Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ
        """
        nodes = retrieval_result.nodes
        edges = retrieval_result.edges
        paths = retrieval_result.paths
        query = retrieval_result.query
        
        context_parts = []
        
        # 1. Ù…Ù‚Ø¯Ù…Ù‡ Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ Ø¨Ø§ ØªÙ…Ø±Ú©Ø² Ø±ÙˆÛŒ Ú˜Ù† Ù…Ø±Ú©Ø²ÛŒ
        context_parts.append(f"âš™ï¸ **ØªØ­Ù„ÛŒÙ„ Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ ØªÙØµÛŒÙ„ÛŒ Ø¨Ø±Ø§ÛŒ:** {query}")
        context_parts.append("")
        
        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú˜Ù† Ù…Ø±Ú©Ø²ÛŒ
        central_gene = self._identify_central_gene(nodes, query)
        if central_gene:
            biological_role = BIOLOGICAL_ROLES.get(central_gene, "Ú˜Ù† Ù…Ù‡Ù… Ø²ÛŒØ³ØªÛŒ")
            context_parts.append(f"ğŸ”¬ **Ú˜Ù† Ù…Ø±Ú©Ø²ÛŒ:** {central_gene} - {biological_role}")
            context_parts.append("")
        
        context_parts.append("**Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡:**")
        context_parts.append("")
        
        # 2. ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ Ø±ÙˆØ§Ø¨Ø· Ø¨Ø§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ù…Ù„
        if edges:
            context_parts.append("ğŸ”¬ **ØªØ­Ù„ÛŒÙ„ Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ Ø±ÙˆØ§Ø¨Ø·:**")
            edge_analysis = {}
            for edge in edges:
                if edge.relation not in edge_analysis:
                    edge_analysis[edge.relation] = []
                edge_analysis[edge.relation].append(f"{edge.source} â†’ {edge.target}")
            
            for relation, connections in edge_analysis.items():
                desc = METAEDGE_DESCRIPTIONS.get(relation, relation)
                context_parts.append(f"**Ù…Ú©Ø§Ù†ÛŒØ³Ù… {desc}:**")
                for connection in connections[:3]:  # Ø­Ø¯Ø§Ú©Ø«Ø± 3 Ù†Ù…ÙˆÙ†Ù‡
                    context_parts.append(f"  - {connection}")
                context_parts.append("")
        
        # 3. Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ Ø¨Ø§ ØªÙˆØ¶ÛŒØ­Ø§Øª ØªÙˆØµÛŒÙÛŒ
        if paths:
            context_parts.append("ğŸ›¤ï¸ **Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ:**")
            for i, path in enumerate(paths[:3]):
                context_parts.append(f"**Ù…Ø³ÛŒØ± Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ {i+1}:**")
                for j, node in enumerate(path):
                    if j < len(path) - 1:
                        context_parts.append(f"  {node} â†’")
                    else:
                        context_parts.append(f"  {node}")
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØ¶ÛŒØ­ Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø³ÛŒØ±
                path_description = self._create_path_description(path, edges)
                if path_description:
                    context_parts.append(f"  **Ù…Ú©Ø§Ù†ÛŒØ³Ù…:** {path_description}")
                context_parts.append("")
        else:
            context_parts.append("âš ï¸ **Ù‡Ø´Ø¯Ø§Ø±:** Ù‡ÛŒÚ† Ù…Ø³ÛŒØ± Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            context_parts.append("")
        
        # 4. ØªØ­Ù„ÛŒÙ„ Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
        biological_inference = self._create_biological_inference(nodes, edges, paths, query)
        if biological_inference:
            context_parts.append("ğŸ”¬ **ØªØ­Ù„ÛŒÙ„ Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ:**")
            context_parts.append(biological_inference)
            context_parts.append("")
        
        # 5. Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ
        context_parts.append("ğŸ”¬ **Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ:**")
        context_parts.append("ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ„Ú©ÙˆÙ„ÛŒ Ùˆ Ø²ÛŒØ³ØªÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.")
        context_parts.append("ØªÙ…Ø±Ú©Ø² Ø¨Ø±:")
        context_parts.append("â€¢ Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…ÛŒ")
        context_parts.append("â€¢ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ÛŒÙ†Ú¯")
        context_parts.append("â€¢ ØªØ¹Ø§Ù…Ù„Ø§Øª Ù¾Ø±ÙˆØªØ¦ÛŒÙ†-Ù¾Ø±ÙˆØªØ¦ÛŒÙ†")
        context_parts.append("â€¢ Ø§Ù‡Ù…ÛŒØª Ø¨Ø§Ù„ÛŒÙ†ÛŒ")
        
        context_text = "\n".join(context_parts)
        return remove_emojis(context_text)

    def _create_intelligent_context_text(self, retrieval_result: RetrievalResult) -> str:
        """
        Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ Ùˆ Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ø²ÛŒØ³ØªÛŒ
        """
        nodes = retrieval_result.nodes
        edges = retrieval_result.edges
        paths = retrieval_result.paths
        query = retrieval_result.query
        
        context_parts = []
        
        # 1. Ù…Ù‚Ø¯Ù…Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ ØªÙ…Ø±Ú©Ø² Ø±ÙˆÛŒ Ú¯Ø±Ù‡ Ù…Ø±Ú©Ø²ÛŒ
        context_parts.append(f"ğŸ§  **Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„. Ø§Ø² Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† Ùˆ Ø¯Ø± Ù†Ù‡Ø§ÛŒØª Ù¾Ø§Ø³Ø® Ø³ÙˆØ§Ù„ Ø±Ø§ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ú©Ù‡ Ø¨Ù‡ Ù†Ø¸Ø±Øª Ø¨Ù‡ Ø¬ÙˆØ§Ø¨ Ø³ÙˆØ§Ù„ Ú©Ù…Ú© Ù…ÛŒÚ©Ù†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† Ùˆ Ø³ÙˆØ§Ù„ Ø±Ùˆ Ø¨Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ø´Ú©Ù„ Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù‡** {query}")
        context_parts.append("")
        
        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú¯Ø±Ù‡ Ù…Ø±Ú©Ø²ÛŒ Ùˆ Ù†Ù‚Ø´ Ø²ÛŒØ³ØªÛŒ Ø¢Ù†
        central_gene = self._identify_central_gene(nodes, query)
        if central_gene:
            biological_role = BIOLOGICAL_ROLES.get(central_gene, "Ú˜Ù† Ù…Ù‡Ù… Ø²ÛŒØ³ØªÛŒ")
            context_parts.append(f"ğŸ”¬ **Ú˜Ù† Ù…Ø±Ú©Ø²ÛŒ:** {central_gene} - {biological_role}")
            context_parts.append("")
        
        context_parts.append("ğŸ”¬ **ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ø§Ù:**")
        context_parts.append("Ø§ÛŒÙ† Ù…ØªÙ† Ø´Ø§Ù…Ù„ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ØŒ Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ø²ÛŒØ³ØªÛŒ Ùˆ Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹Ù†Ø§Ø¯Ø§Ø± Ø§Ø³Øª.")
        context_parts.append("")
        
        # 2. ØªØ­Ù„ÛŒÙ„ Ø¢Ù…Ø§Ø±ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ ØªÙˆØ¶ÛŒØ­Ø§Øª
        context_parts.append("ğŸ“Š **ØªØ­Ù„ÛŒÙ„ Ø¢Ù…Ø§Ø±ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡:**")
        context_parts.append(f"â€¢ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯Ù‡: {len(nodes)}")
        context_parts.append(f"â€¢ ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯Ù‡: {len(edges)}")
        context_parts.append(f"â€¢ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯Ù‡: {len(paths)}")
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ±Ø§Ú©Ù… Ø±ÙˆØ§Ø¨Ø·
        if nodes and edges:
            avg_connections = len(edges) / len(nodes)
            context_parts.append(f"â€¢ ØªØ±Ø§Ú©Ù… Ù…ØªÙˆØ³Ø· Ø±ÙˆØ§Ø¨Ø·: {avg_connections:.2f} ÛŒØ§Ù„ Ø¨Ù‡ Ø§Ø²Ø§ÛŒ Ù‡Ø± Ù†ÙˆØ¯")
        
        # 3. ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ¹â€ŒØ´Ù†Ø§Ø³ÛŒ Ù†ÙˆØ¯Ù‡Ø§ Ø¨Ø§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø²ÛŒØ³ØªÛŒ
        if nodes:
            context_parts.append("")
            context_parts.append("ğŸ·ï¸ **ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ¹â€ŒØ´Ù†Ø§Ø³ÛŒ Ù†ÙˆØ¯Ù‡Ø§:**")
            node_kinds = {}
            for node in nodes:
                if node.kind not in node_kinds:
                    node_kinds[node.kind] = []
                node_kinds[node.kind].append(node.name)
            
            for kind, names in node_kinds.items():
                context_parts.append(f"â€¢ {kind}: {len(names)} Ù†ÙˆØ¯")
                # Ù†Ù…Ø§ÛŒØ´ ØªÙ…Ø§Ù… Ù†ÙˆØ¯Ù‡Ø§
                for i, name in enumerate(names):
                    context_parts.append(f"  {i+1}. {name}")
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØ¶ÛŒØ­Ø§Øª Ø²ÛŒØ³ØªÛŒ Ø¨Ø±Ø§ÛŒ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…
                if kind == "Gene":
                    for gene_name in names:
                        if gene_name in BIOLOGICAL_ROLES:
                            context_parts.append(f"    - {gene_name}: {BIOLOGICAL_ROLES[gene_name]}")
        
        # 4. ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹Ù†Ø§Ø¯Ø§Ø± Ø¨Ø§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ù…Ù„
        if edges:
            context_parts.append("")
            context_parts.append("ğŸ”— **ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±:**")
            from node_lookup_system import NodeLookupSystem
            lookup = NodeLookupSystem()
            edge_analysis = {}
            for edge in edges:
                if edge.relation not in edge_analysis:
                    edge_analysis[edge.relation] = []
                source_info = lookup.get_node_info(edge.source)
                target_info = lookup.get_node_info(edge.target)
                source_display = f"{source_info.name} ({source_info.kind})" if source_info else edge.source
                target_display = f"{target_info.name} ({target_info.kind})" if target_info else edge.target
                edge_analysis[edge.relation].append(f"{source_display} â†’ {target_display}")
            
            # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØ±Ø§ÙˆØ§Ù†ÛŒ
            sorted_relations = sorted(edge_analysis.items(), key=lambda x: len(x[1]), reverse=True)
            for relation, connections in sorted_relations[:5]:  # 5 Ø±Ø§Ø¨Ø·Ù‡ Ø¨Ø±ØªØ±
                desc = METAEDGE_DESCRIPTIONS.get(relation, relation)
                context_parts.append(f"â€¢ {desc} ({len(connections)} Ø±Ø§Ø¨Ø·Ù‡)")
                
                # Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø±ÙˆØ§Ø¨Ø·
                for connection in connections[:2]:  # Ø­Ø¯Ø§Ú©Ø«Ø± 2 Ù†Ù…ÙˆÙ†Ù‡
                    context_parts.append(f"  - {connection}")
        
        # 5. ØªØ­Ù„ÛŒÙ„ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ø¨Ø§ ØªÙˆØ¶ÛŒØ­Ø§Øª ØªÙˆØµÛŒÙÛŒ
        if paths:
            context_parts.append("")
            context_parts.append("ğŸ›¤ï¸ **ØªØ­Ù„ÛŒÙ„ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ:**")
            context_parts.append("Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø±ÙˆØ§Ø¨Ø· Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø²ÛŒØ³ØªÛŒ Ù‡Ø³ØªÙ†Ø¯:")
            
            for i, path in enumerate(paths[:3]):
                path_length = len(path)
                context_parts.append(f"â€¢ Ù…Ø³ÛŒØ± {i+1}: {path_length} Ú¯Ø§Ù… Ø²ÛŒØ³ØªÛŒ")
                context_parts.append(f"  Ù…Ø³ÛŒØ±: {' â†’ '.join([self._display_node(n) for n in path])}")
                
                # ØªÙˆÙ„ÛŒØ¯ ØªÙˆØ¶ÛŒØ­ ØªÙˆØµÛŒÙÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø³ÛŒØ±
                path_description = self._create_path_description(path, edges)
                if path_description:
                    context_parts.append(f"  ØªÙˆØ¶ÛŒØ­: {path_description}")
        else:
            context_parts.append("")
            context_parts.append("âš ï¸ **Ù‡Ø´Ø¯Ø§Ø±:** Ù‡ÛŒÚ† Ù…Ø³ÛŒØ± Ù…Ø³ØªÙ‚ÛŒÙ…ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            context_parts.append("Ø§ÛŒÙ† Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¹Ù…Ù‚ Ø¬Ø³ØªØ¬Ùˆ ÛŒØ§ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù…Ø³ÛŒØ± Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ø§Ø´Ø¯.")
            context_parts.append("Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Ø§ÙØ²Ø§ÛŒØ´ Ø¹Ù…Ù‚ Ø¬Ø³ØªØ¬Ùˆ ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¯ÛŒÚ¯Ø±")
        
        # 6. Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ø²ÛŒØ³ØªÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
        context_parts.append("")
        context_parts.append("ğŸ§¬ **Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ø²ÛŒØ³ØªÛŒ:**")
        
        # ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„ Ùˆ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ù†Ø§Ø³Ø¨
        query_lower = query.lower()
        if any(word in query_lower for word in ["gene", "express", "protein"]):
            context_parts.append("â€¢ Ø³ÙˆØ§Ù„ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¨ÛŒØ§Ù† Ú˜Ù† Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù¾Ø±ÙˆØªØ¦ÛŒÙ†â€ŒÙ‡Ø§")
            context_parts.append("â€¢ ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø±ÙˆØ§Ø¨Ø·:")
            context_parts.append(f"  - {METAEDGE_DESCRIPTIONS.get('AeG', 'AeG')}")
            context_parts.append(f"  - {METAEDGE_DESCRIPTIONS.get('AuG', 'AuG')}")
            context_parts.append(f"  - {METAEDGE_DESCRIPTIONS.get('GpBP', 'GpBP')}")
        elif any(word in query_lower for word in ["disease", "cancer", "disorder"]):
            context_parts.append("â€¢ Ø³ÙˆØ§Ù„ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ØªÙˆÙ„ÙˆÚ˜ÛŒÚ©")
            context_parts.append("â€¢ ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø±ÙˆØ§Ø¨Ø·:")
            context_parts.append(f"  - {METAEDGE_DESCRIPTIONS.get('DaG', 'DaG')}")
            context_parts.append(f"  - {METAEDGE_DESCRIPTIONS.get('DuG', 'DuG')}")
            context_parts.append(f"  - {METAEDGE_DESCRIPTIONS.get('DlA', 'DlA')}")
        elif any(word in query_lower for word in ["drug", "treatment", "therapy"]):
            context_parts.append("â€¢ Ø³ÙˆØ§Ù„ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¯Ø±Ù…Ø§Ù† Ùˆ Ø¯Ø§Ø±ÙˆÙ‡Ø§")
            context_parts.append("â€¢ ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø±ÙˆØ§Ø¨Ø·:")
            context_parts.append(f"  - {METAEDGE_DESCRIPTIONS.get('CtD', 'CtD')}")
            context_parts.append(f"  - {METAEDGE_DESCRIPTIONS.get('CuG', 'CuG')}")
            context_parts.append(f"  - {METAEDGE_DESCRIPTIONS.get('CdG', 'CdG')}")
        elif any(word in query_lower for word in ["tissue", "anatomy", "organ"]):
            context_parts.append("â€¢ Ø³ÙˆØ§Ù„ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ Ùˆ Ø¢Ù†Ø§ØªÙˆÙ…ÛŒ")
            context_parts.append("â€¢ ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø±ÙˆØ§Ø¨Ø·:")
            context_parts.append(f"  - {METAEDGE_DESCRIPTIONS.get('AeG', 'AeG')}")
            context_parts.append(f"  - {METAEDGE_DESCRIPTIONS.get('AuG', 'AuG')}")
        else:
            context_parts.append("â€¢ Ø³ÙˆØ§Ù„ Ø¹Ù…ÙˆÙ…ÛŒ - ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ØªÙ…Ø§Ù… Ø±ÙˆØ§Ø¨Ø·")
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø²ÛŒØ³ØªÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ
        biological_inference = self._create_biological_inference(nodes, edges, paths, query)
        if biological_inference:
            context_parts.append("")
            context_parts.append("ğŸ”¬ **Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø²ÛŒØ³ØªÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:**")
            context_parts.append(biological_inference)
        
        # 7. Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ù‡ÙˆØ´Ù…Ù†Ø¯
        context_parts.append("")
        context_parts.append("ğŸ¯ **Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ù‡ÙˆØ´Ù…Ù†Ø¯:**")
        context_parts.append("Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ø§Ù Ùˆ Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ø²ÛŒØ³ØªÛŒØŒ")
        context_parts.append("Ù¾Ø§Ø³Ø® Ø¬Ø§Ù…Ø¹ Ùˆ ØªØ®ØµØµÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ú©Ù‡ Ø´Ø§Ù…Ù„:")
        context_parts.append("â€¢ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±")
        context_parts.append("â€¢ Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ø²ÛŒØ³ØªÛŒ")
        context_parts.append("â€¢ Ø§Ù‡Ù…ÛŒØª Ø¨Ø§Ù„ÛŒÙ†ÛŒ")
        context_parts.append("â€¢ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ")
        
        context_text = "\n".join(context_parts)
        return remove_emojis(context_text)

    def _identify_central_gene(self, nodes: List[GraphNode], query: str) -> Optional[str]:
        """
        Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú˜Ù† Ù…Ø±Ú©Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³ÙˆØ§Ù„ Ùˆ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒâ€ŒØ´Ø¯Ù‡
        """
        query_lower = query.lower()
        
        # Ø¬Ø³ØªØ¬ÙˆÛŒ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ø¯Ø± Ø³ÙˆØ§Ù„
        for gene in BIOLOGICAL_ROLES.keys():
            if gene.lower() in query_lower:
                return gene
        
        # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒâ€ŒØ´Ø¯Ù‡
        gene_nodes = [node for node in nodes if node.kind == "Gene"]
        if gene_nodes:
            # Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ù‡ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…
            for gene_node in gene_nodes:
                if gene_node.name in BIOLOGICAL_ROLES:
                    return gene_node.name
            # Ø§Ú¯Ø± Ú˜Ù† Ù…Ù‡Ù…ÛŒ Ù†Ø¨ÙˆØ¯ØŒ Ø§ÙˆÙ„ÛŒÙ† Ú˜Ù† Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
            return gene_nodes[0].name
        
        return None

    def _create_path_description(self, path: List[str], edges: List[GraphEdge]) -> str:
        """
        ØªÙˆÙ„ÛŒØ¯ ØªÙˆØ¶ÛŒØ­ ØªÙˆØµÛŒÙÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù…Ø³ÛŒØ±
        """
        if len(path) < 2:
            return ""
        
        from node_lookup_system import NodeLookupSystem
        lookup = NodeLookupSystem()
        descriptions = []
        for i in range(len(path) - 1):
            source = path[i]
            target = path[i + 1]
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¢ÛŒØ¯ÛŒ Ù†ÙˆØ¯Ù‡Ø§ Ø¨Ù‡ Ù†Ø§Ù… Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±
            source_info = lookup.get_node_info(source)
            target_info = lookup.get_node_info(target)
            source_display = f"{source_info.name} ({source_info.kind})" if source_info else source
            target_display = f"{target_info.name} ({target_info.kind})" if target_info else target
            
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø±Ø§Ø¨Ø·Ù‡ Ø¨ÛŒÙ† Ø§ÛŒÙ† Ø¯Ùˆ Ù†ÙˆØ¯
            relation = None
            for edge in edges:
                if edge.source == source and edge.target == target:
                    relation = edge.relation
                    break
            
            if relation:
                desc = METAEDGE_DESCRIPTIONS.get(relation, relation)
                descriptions.append(f"{source_display} {desc} {target_display}")
            else:
                descriptions.append(f"{source_display} â†’ {target_display}")
        
        if descriptions:
            return " Ùˆ ".join(descriptions)
        return ""

    def _create_biological_inference(self, nodes: List[GraphNode], edges: List[GraphEdge], 
                                   paths: List[List[str]], query: str) -> str:
        """
        ØªÙˆÙ„ÛŒØ¯ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø²ÛŒØ³ØªÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ
        """
        query_lower = query.lower()
        inferences = []
        
        # ØªØ­Ù„ÛŒÙ„ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…
        gene_nodes = [node for node in nodes if node.kind == "Gene"]
        important_genes = [gene for gene in gene_nodes if gene.name in BIOLOGICAL_ROLES]
        
        if important_genes:
            gene_names = [gene.name for gene in important_genes[:3]]
            gene_roles = [BIOLOGICAL_ROLES[gene.name] for gene in important_genes[:3]]
            
            if len(gene_names) == 1:
                inferences.append(f"Ú˜Ù† {gene_names[0]} Ú©Ù‡ {gene_roles[0]} Ø§Ø³ØªØŒ Ø¯Ø± Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ Ù†Ù‚Ø´ Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø§Ø±Ø¯.")
            else:
                gene_list = "ØŒ ".join(gene_names)
                inferences.append(f"Ú˜Ù†â€ŒÙ‡Ø§ÛŒ {gene_list} Ú©Ù‡ Ù†Ù‚Ø´â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ù…Ù‡Ù…ÛŒ Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø¯Ø± Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù†Ø¯.")
        
        # ØªØ­Ù„ÛŒÙ„ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
        disease_nodes = [node for node in nodes if node.kind == "Disease"]
        if disease_nodes:
            disease_names = [node.name for node in disease_nodes[:3]]
            disease_desc = [DISEASE_SIGNIFICANCE.get(name, name) for name in disease_names]
            
            if len(disease_names) == 1:
                inferences.append(f"Ø¨ÛŒÙ…Ø§Ø±ÛŒ {disease_names[0]} ({disease_desc[0]}) Ø¯Ø± Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ±Ø¯ Ø¨Ø±Ø±Ø³ÛŒ Ù‚Ø±Ø§Ø± Ú¯Ø±ÙØªÙ‡ Ø§Ø³Øª.")
            else:
                disease_list = "ØŒ ".join(disease_names)
                inferences.append(f"Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ {disease_list} Ø¯Ø± Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù†Ø¯.")
        
        # ØªØ­Ù„ÛŒÙ„ Ù…Ø³ÛŒØ±Ù‡Ø§
        if paths:
            path_count = len(paths)
            if path_count == 1:
                inferences.append("ÛŒÚ© Ù…Ø³ÛŒØ± Ø²ÛŒØ³ØªÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨ÛŒÙ† Ø§Ø¬Ø²Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯.")
            else:
                inferences.append(f"{path_count} Ù…Ø³ÛŒØ± Ø²ÛŒØ³ØªÛŒ Ù…Ø®ØªÙ„Ù Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯ Ú©Ù‡ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ø±ÙˆØ§Ø¨Ø· Ø²ÛŒØ³ØªÛŒ Ø§Ø³Øª.")
        
        # ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ§Ø¨Ø· ØºØ§Ù„Ø¨
        if edges:
            relation_counts = {}
            for edge in edges:
                relation_counts[edge.relation] = relation_counts.get(edge.relation, 0) + 1
            
            most_common_relation = max(relation_counts.items(), key=lambda x: x[1])
            relation_desc = METAEDGE_DESCRIPTIONS.get(most_common_relation[0], most_common_relation[0])
            inferences.append(f"Ø±Ø§Ø¨Ø·Ù‡ ØºØ§Ù„Ø¨ Ø¯Ø± Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ {relation_desc} Ø§Ø³Øª Ú©Ù‡ {most_common_relation[1]} Ø¨Ø§Ø± Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        
        if inferences:
            return " ".join(inferences)
        return ""



    def simple_template_generation(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø³Ø§Ø¯Ù‡ Ø¨Ø§ Ù‚Ø§Ù„Ø¨ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡"""
        query_lower = retrieval_result.query.lower()
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ø³Ø§Ø¯Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡
        simple_context = self._create_simple_context_text(retrieval_result)
        
        # ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„
        question_type = self._analyze_question_type(query_lower)
        
        if question_type == "relationship":
            return self._generate_relationship_answer(retrieval_result)
        elif question_type == "drug_treatment":
            return self._generate_drug_treatment_answer(retrieval_result)
        elif question_type == "gene_function":
            return self._generate_gene_function_answer(retrieval_result)
        elif question_type == "disease_info":
            return self._generate_disease_info_answer(retrieval_result)
        elif question_type == "anatomy_expression":
            return self._generate_anatomy_expression_answer(retrieval_result)
        else:
            return self._generate_general_answer(retrieval_result)
    
    def _analyze_question_type(self, query_lower: str) -> str:
        """ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„"""
        if any(word in query_lower for word in ["relationship", "relation", "connect", "link"]):
            return "relationship"
        elif any(word in query_lower for word in ["drug", "treat", "medicine", "therapy"]):
            return "drug_treatment"
        elif any(word in query_lower for word in ["gene", "function", "regulate", "express"]):
            return "gene_function"
        elif any(word in query_lower for word in ["disease", "disorder", "condition", "symptom"]):
            return "disease_info"
        elif any(word in query_lower for word in ["anatomy", "organ", "tissue", "heart", "brain", "liver"]):
            return "anatomy_expression"
        else:
            return "general"
    
    def _generate_relationship_answer(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø±Ø§Ø¨Ø·Ù‡"""
        if not retrieval_result.edges:
            return "âŒ No direct relationships found between the specified entities in the knowledge graph."
        
        answer_parts = ["ğŸ”— RELATIONSHIPS FOUND:"]
        
        # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø±ÙˆØ§Ø¨Ø·
        relations_by_type = {}
        for edge in retrieval_result.edges:
            if edge.relation not in relations_by_type:
                relations_by_type[edge.relation] = []
            relations_by_type[edge.relation].append(edge)
        
        for relation, edges in relations_by_type.items():
            answer_parts.append(f"\nğŸ“Œ {relation.upper()} ({len(edges)} connections):")
            for edge in edges:  # Ù†Ù…Ø§ÛŒØ´ ØªÙ…Ø§Ù… Ø±ÙˆØ§Ø¨Ø·
                answer_parts.append(f"  â€¢ {self._display_node(edge.source)} â†’ {self._display_node(edge.target)}")
        
        return "\n".join(answer_parts)
    
    def _generate_drug_treatment_answer(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¯Ø±Ù…Ø§Ù† Ø¯Ø§Ø±ÙˆÛŒÛŒ"""
        drug_nodes = [n for n in retrieval_result.nodes if n.kind in ['Drug', 'Compound']]
        disease_nodes = [n for n in retrieval_result.nodes if n.kind == 'Disease']
        
        if not drug_nodes and not disease_nodes:
            return "âŒ No drug or disease information found in the retrieved context."
        
        answer_parts = ["ğŸ’Š DRUG-DISEASE RELATIONSHIPS:"]
        
        # Ø±ÙˆØ§Ø¨Ø· Ø¯Ø±Ù…Ø§Ù†
        treatment_edges = [e for e in retrieval_result.edges if 'treat' in e.relation.lower() or 'therapy' in e.relation.lower()]
        if treatment_edges:
            answer_parts.append(f"\nâœ… TREATMENT RELATIONSHIPS ({len(treatment_edges)} found):")
            for edge in treatment_edges:
                answer_parts.append(f"  â€¢ {self._display_node(edge.source)} treats {self._display_node(edge.target)}")
        
        # Ø¯Ø§Ø±ÙˆÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡
        if drug_nodes:
            answer_parts.append(f"\nğŸ’Š DRUGS FOUND ({len(drug_nodes)}):")
            for drug in drug_nodes:
                answer_parts.append(f"  â€¢ {drug.name}")
        
        # Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡
        if disease_nodes:
            answer_parts.append(f"\nğŸ¥ DISEASES FOUND ({len(disease_nodes)}):")
            for disease in disease_nodes:
                answer_parts.append(f"  â€¢ {disease.name}")
        
        return "\n".join(answer_parts)
    
    def _generate_gene_function_answer(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¹Ù…Ù„Ú©Ø±Ø¯ Ú˜Ù†"""
        gene_nodes = [n for n in retrieval_result.nodes if n.kind == 'Gene']
        process_nodes = [n for n in retrieval_result.nodes if n.kind == 'Biological Process']
        
        if not gene_nodes:
            return "âŒ No gene information found in the retrieved context."
        
        answer_parts = ["ğŸ§¬ GENE FUNCTION ANALYSIS:"]
        
        # Ú˜Ù†â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡
        answer_parts.append(f"\nğŸ§¬ GENES FOUND ({len(gene_nodes)}):")
        for gene in gene_nodes:
            answer_parts.append(f"  â€¢ {gene.name}")
        
        # ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ù…Ø±ØªØ¨Ø·
        if process_nodes:
            answer_parts.append(f"\nâš™ï¸ BIOLOGICAL PROCESSES ({len(process_nodes)}):")
            for process in process_nodes:
                answer_parts.append(f"  â€¢ {process.name}")
        
        # Ø±ÙˆØ§Ø¨Ø· Ú˜Ù†-ÙØ±Ø¢ÛŒÙ†Ø¯
        gene_process_edges = [e for e in retrieval_result.edges if 'participate' in e.relation.lower() or 'regulate' in e.relation.lower()]
        if gene_process_edges:
            answer_parts.append(f"\nğŸ”— GENE-PROCESS RELATIONSHIPS ({len(gene_process_edges)}):")
            for edge in gene_process_edges:
                answer_parts.append(f"  â€¢ {self._display_node(edge.source)} â†’ {self._display_node(edge.target)}")
        
        return "\n".join(answer_parts)
    
    def _generate_disease_info_answer(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒÙ…Ø§Ø±ÛŒ"""
        disease_nodes = [n for n in retrieval_result.nodes if n.kind == 'Disease']
        gene_nodes = [n for n in retrieval_result.nodes if n.kind == 'Gene']
        symptom_nodes = [n for n in retrieval_result.nodes if n.kind == 'Symptom']
        
        if not disease_nodes:
            return "âŒ No disease information found in the retrieved context."
        
        answer_parts = ["ğŸ¥ DISEASE ANALYSIS:"]
        
        # Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡
        answer_parts.append(f"\nğŸ¥ DISEASES FOUND ({len(disease_nodes)}):")
        for disease in disease_nodes:
            answer_parts.append(f"  â€¢ {disease.name}")
        
        # Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
        if gene_nodes:
            answer_parts.append(f"\nğŸ§¬ ASSOCIATED GENES ({len(gene_nodes)}):")
            for gene in gene_nodes:
                answer_parts.append(f"  â€¢ {gene.name}")
        
        # Ø¹Ù„Ø§Ø¦Ù… Ù…Ø±ØªØ¨Ø·
        if symptom_nodes:
            answer_parts.append(f"\nğŸ¤’ ASSOCIATED SYMPTOMS ({len(symptom_nodes)}):")
            for symptom in symptom_nodes:
                answer_parts.append(f"  â€¢ {symptom.name}")
        
        return "\n".join(answer_parts)
    
    def _generate_anatomy_expression_answer(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¨ÛŒØ§Ù† Ú˜Ù† Ø¯Ø± Ø¢Ù†Ø§ØªÙˆÙ…ÛŒ"""
        anatomy_nodes = [n for n in retrieval_result.nodes if n.kind == 'Anatomy']
        gene_nodes = [n for n in retrieval_result.nodes if n.kind == 'Gene']
        
        if not anatomy_nodes:
            return "âŒ No anatomy information found in the retrieved context."
        
        answer_parts = ["ğŸ«€ ANATOMY-GENE EXPRESSION:"]
        
        # Ø§Ù†Ø¯Ø§Ù…â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡
        answer_parts.append(f"\nğŸ«€ ANATOMICAL STRUCTURES ({len(anatomy_nodes)}):")
        for anatomy in anatomy_nodes:
            answer_parts.append(f"  â€¢ {anatomy.name}")
        
        # Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ§Ù† Ø´Ø¯Ù‡
        if gene_nodes:
            answer_parts.append(f"\nğŸ§¬ EXPRESSED GENES ({len(gene_nodes)}):")
            for gene in gene_nodes:
                answer_parts.append(f"  â€¢ {gene.name}")
        
        # Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒØ§Ù†
        expression_edges = [e for e in retrieval_result.edges if 'express' in e.relation.lower()]
        if expression_edges:
            answer_parts.append(f"\nğŸ”— EXPRESSION RELATIONSHIPS ({len(expression_edges)}):")
            for edge in expression_edges:
                source_name = next(n.name for n in retrieval_result.nodes if n.id == edge.source)
                target_name = next(n.name for n in retrieval_result.nodes if n.id == edge.target)
                answer_parts.append(f"  â€¢ {source_name} expresses {target_name}")
        
        return "\n".join(answer_parts)
    
    def _generate_general_answer(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¹Ù…ÙˆÙ…ÛŒ"""
        if not retrieval_result.nodes:
            return "âŒ No relevant information found in the knowledge graph for your query."
        
        answer_parts = ["ğŸ“Š GENERAL INFORMATION FOUND:"]
        
        # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†ÙˆØ¯Ù‡Ø§
        nodes_by_type = {}
        for node in retrieval_result.nodes:
            if node.kind not in nodes_by_type:
                nodes_by_type[node.kind] = []
            nodes_by_type[node.kind].append(node)
        
        for kind, nodes in nodes_by_type.items():
            answer_parts.append(f"\nğŸ”¹ {kind.upper()} ({len(nodes)} entities):")
            for node in nodes:
                answer_parts.append(f"  â€¢ {node.name}")
        
        # Ø±ÙˆØ§Ø¨Ø· Ù…Ù‡Ù…
        if retrieval_result.edges:
            answer_parts.append(f"\nğŸ”— KEY RELATIONSHIPS ({len(retrieval_result.edges)}):")
            for edge in retrieval_result.edges:
                answer_parts.append(f"  â€¢ {self._display_node(edge.source)} â†’ {self._display_node(edge.target)} ({edge.relation})")
        
        return "\n".join(answer_parts)
    
    def gpt_simulation_generation(self, retrieval_result: RetrievalResult) -> str:
        """Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® GPT Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡"""
        query = retrieval_result.query
        query_lower = query.lower()
        
        # ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„
        question_type = self._analyze_question_type(query_lower)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù‡Ù… Ø§Ø² Ù†ØªØ§ÛŒØ¬ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ
        gene_nodes = [n for n in retrieval_result.nodes if n.kind == 'Gene']
        disease_nodes = [n for n in retrieval_result.nodes if n.kind == 'Disease']
        drug_nodes = [n for n in retrieval_result.nodes if n.kind in ['Drug', 'Compound']]
        anatomy_nodes = [n for n in retrieval_result.nodes if n.kind == 'Anatomy']
        process_nodes = [n for n in retrieval_result.nodes if n.kind == 'Biological Process']
        
        # ØªØ´Ø®ÛŒØµ Ø³ÙˆØ§Ù„Ø§Øª Ú˜Ù†-Ø³Ø±Ø·Ø§Ù†
        if self._is_gene_cancer_question_from_context(retrieval_result):
            return self._generate_gene_cancer_answer(retrieval_result, gene_nodes, disease_nodes)
        
        # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„
        if question_type == "relationship":
            return self._generate_intelligent_relationship_answer(retrieval_result, gene_nodes, disease_nodes, drug_nodes)
        elif question_type == "drug_treatment":
            return self._generate_intelligent_drug_answer(retrieval_result, drug_nodes, disease_nodes)
        elif question_type == "gene_function":
            return self._generate_intelligent_gene_answer(retrieval_result, gene_nodes, process_nodes)
        elif question_type == "disease_info":
            return self._generate_intelligent_disease_answer(retrieval_result, disease_nodes, gene_nodes)
        elif question_type == "anatomy_expression":
            return self._generate_intelligent_anatomy_answer(retrieval_result, anatomy_nodes, gene_nodes)
        else:
            return self._generate_intelligent_general_answer(retrieval_result, gene_nodes, disease_nodes, drug_nodes, anatomy_nodes, process_nodes)
    
    def _generate_intelligent_relationship_answer(self, retrieval_result: RetrievalResult, gene_nodes, disease_nodes, drug_nodes) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø±Ø§Ø¨Ø·Ù‡"""
        if not retrieval_result.edges:
            return "ğŸ” **ØªØ­Ù„ÛŒÙ„ Ø±Ø§Ø¨Ø·Ù‡:**\n\nÙ…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø±Ø§Ø¨Ø·Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ…ÛŒ Ø¨ÛŒÙ† Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¯Ø± Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§ÛŒÙ† Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ø¯Ù„ÛŒÙ„:\nâ€¢ ÙØ§ØµÙ„Ù‡ Ø²ÛŒØ§Ø¯ Ø¨ÛŒÙ† Ù†ÙˆØ¯Ù‡Ø§ Ø¯Ø± Ú¯Ø±Ø§Ù\nâ€¢ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¹Ù…ÛŒÙ‚â€ŒØªØ±\nâ€¢ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø±Ø§Ø¨Ø·Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯"
        
        answer_parts = ["ğŸ” **ØªØ­Ù„ÛŒÙ„ Ø±Ø§Ø¨Ø·Ù‡:**\n"]
        
        # ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ§Ø¨Ø· Ù…Ù‡Ù…
        important_relations = {}
        for edge in retrieval_result.edges:
            if edge.relation not in important_relations:
                important_relations[edge.relation] = []
            important_relations[edge.relation].append(edge)
        
        # Ù†Ù…Ø§ÛŒØ´ Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ø±ÙˆØ§Ø¨Ø·
        answer_parts.append("**Ø±ÙˆØ§Ø¨Ø· Ù…Ù‡Ù… ÛŒØ§ÙØª Ø´Ø¯Ù‡:**\n")
        for relation, edges in sorted(important_relations.items(), key=lambda x: len(x[1]), reverse=True):
            answer_parts.append(f"â€¢ **{relation}** ({len(edges)} Ø±Ø§Ø¨Ø·Ù‡):")
            for edge in edges:
                source_name = next(n.name for n in retrieval_result.nodes if n.id == edge.source)
                target_name = next(n.name for n in retrieval_result.nodes if n.id == edge.target)
                answer_parts.append(f"  - {self._display_node(edge.source)} â†’ {self._display_node(edge.target)}")
            answer_parts.append("")
        
        # ØªØ­Ù„ÛŒÙ„ Ø¢Ù…Ø§Ø±ÛŒ
        answer_parts.append("**Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ:**")
        answer_parts.append(f"â€¢ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø±ÙˆØ§Ø¨Ø·: {len(retrieval_result.edges)}")
        answer_parts.append(f"â€¢ Ø§Ù†ÙˆØ§Ø¹ Ø±ÙˆØ§Ø¨Ø·: {len(important_relations)}")
        answer_parts.append(f"â€¢ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·: {len(retrieval_result.nodes)}")
        
        return "\n".join(answer_parts)
    
    def _generate_intelligent_drug_answer(self, retrieval_result: RetrievalResult, drug_nodes, disease_nodes) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¯Ø§Ø±ÙˆÛŒÛŒ"""
        answer_parts = ["ğŸ’Š **ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ:**\n"]
        
        if drug_nodes:
            answer_parts.append("**Ø¯Ø§Ø±ÙˆÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡:**")
            for drug in drug_nodes:
                score_info = f" (Ø§Ù…ØªÛŒØ§Ø²: {drug.score:.2f})" if hasattr(drug, 'score') and drug.score != 1.0 else ""
                answer_parts.append(f"â€¢ {drug.name}{score_info}")
            answer_parts.append("")
        
        if disease_nodes:
            answer_parts.append("**Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·:**")
            for disease in disease_nodes:
                answer_parts.append(f"â€¢ {disease.name}")
            answer_parts.append("")
        
        # Ø±ÙˆØ§Ø¨Ø· Ø¯Ø±Ù…Ø§Ù†
        treatment_edges = [e for e in retrieval_result.edges if 'treat' in e.relation.lower() or 'therapy' in e.relation.lower()]
        if treatment_edges:
            answer_parts.append("**Ø±ÙˆØ§Ø¨Ø· Ø¯Ø±Ù…Ø§Ù†ÛŒ:**")
            for edge in treatment_edges[:5]:
                answer_parts.append(f"â€¢ {self._display_node(edge.source)} Ø¯Ø±Ù…Ø§Ù† Ù…ÛŒâ€ŒÚ©Ù†Ø¯: {self._display_node(edge.target)}")
        
        if not drug_nodes and not disease_nodes:
            answer_parts.append("âŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ø±ÙˆÛŒÛŒ ÛŒØ§ Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¯Ø± Ù†ØªØ§ÛŒØ¬ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        
        return "\n".join(answer_parts)
    
    def _generate_intelligent_gene_answer(self, retrieval_result: RetrievalResult, gene_nodes, process_nodes) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ú˜Ù†"""
        answer_parts = ["ğŸ§¬ **ØªØ­Ù„ÛŒÙ„ Ú˜Ù†ØªÛŒÚ©ÛŒ:**\n"]
        
        if gene_nodes:
            answer_parts.append("**Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… ÛŒØ§ÙØª Ø´Ø¯Ù‡:**")
            # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø²
            sorted_genes = sorted(gene_nodes, key=lambda x: getattr(x, 'score', 1.0), reverse=True)
            
            for gene in sorted_genes[:5]:
                score_info = f" (Ø§Ù…ØªÛŒØ§Ø²: {gene.score:.2f})" if hasattr(gene, 'score') and gene.score != 1.0 else ""
                answer_parts.append(f"â€¢ **{gene.name}**{score_info}")
            answer_parts.append("")
        
        if process_nodes:
            answer_parts.append("**ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ù…Ø±ØªØ¨Ø·:**")
            for process in process_nodes[:5]:
                answer_parts.append(f"â€¢ {process.name}")
            answer_parts.append("")
        
        # Ø±ÙˆØ§Ø¨Ø· Ú˜Ù†-ÙØ±Ø¢ÛŒÙ†Ø¯
        gene_process_edges = [e for e in retrieval_result.edges 
                            if any(n.id == e.source for n in gene_nodes) and 
                               any(n.id == e.target for n in process_nodes)]
        
        if gene_process_edges:
            answer_parts.append("**Ø±ÙˆØ§Ø¨Ø· Ú˜Ù†-ÙØ±Ø¢ÛŒÙ†Ø¯:**")
            for edge in gene_process_edges[:5]:
                answer_parts.append(f"â€¢ {self._display_node(edge.source)} â†’ {self._display_node(edge.target)} ({edge.relation})")
            answer_parts.append("")
        
        # ØªØ­Ù„ÛŒÙ„ Ø¢Ù…Ø§Ø±ÛŒ
        total_genes = len(gene_nodes)
        total_processes = len(process_nodes)
        total_relationships = len(retrieval_result.edges)
        
        answer_parts.append("**Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ:**")
        answer_parts.append(f"â€¢ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡: {total_genes}")
        answer_parts.append(f"â€¢ ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ: {total_processes}")
        answer_parts.append(f"â€¢ Ø±ÙˆØ§Ø¨Ø· Ú©Ù„: {total_relationships}")
        
        if not gene_nodes:
            answer_parts.append("\nâŒ Ú˜Ù† Ù…Ø±ØªØ¨Ø·ÛŒ Ø¯Ø± Ù†ØªØ§ÛŒØ¬ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        
        return "\n".join(answer_parts)
    
    def _generate_intelligent_disease_answer(self, retrieval_result: RetrievalResult, disease_nodes, gene_nodes) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¨ÛŒÙ…Ø§Ø±ÛŒ"""
        answer_parts = ["ğŸ¥ **ØªØ­Ù„ÛŒÙ„ Ø¨ÛŒÙ…Ø§Ø±ÛŒ:**\n"]
        
        if disease_nodes:
            answer_parts.append("**Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡:**")
            for disease in disease_nodes[:5]:
                answer_parts.append(f"â€¢ {disease.name}")
            answer_parts.append("")
        
        if gene_nodes:
            answer_parts.append("**Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·:**")
            for gene in gene_nodes[:5]:
                answer_parts.append(f"â€¢ {gene.name}")
            answer_parts.append("")
        
        # Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒÙ…Ø§Ø±ÛŒ-Ú˜Ù†
        disease_gene_edges = [e for e in retrieval_result.edges if 'cause' in e.relation.lower() or 'associate' in e.relation.lower()]
        if disease_gene_edges:
            answer_parts.append("**Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒÙ…Ø§Ø±ÛŒ-Ú˜Ù†:**")
            for edge in disease_gene_edges[:5]:
                answer_parts.append(f"â€¢ {self._display_node(edge.source)} â†’ {self._display_node(edge.target)}")
        
        if not disease_nodes:
            answer_parts.append("âŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¯Ø± Ù†ØªØ§ÛŒØ¬ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        
        return "\n".join(answer_parts)
    
    def _generate_intelligent_anatomy_answer(self, retrieval_result: RetrievalResult, anatomy_nodes, gene_nodes) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø´ÙˆØ§Ù‡Ø¯ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¢Ù†Ø§ØªÙˆÙ…ÛŒ"""
        answer_parts = []
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… Ø¢Ù†Ø§ØªÙˆÙ…ÛŒ
        anatomy_name = "unknown anatomy"
        if anatomy_nodes:
            anatomy_name = anatomy_nodes[0].name
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ§Ù† Ø´Ø¯Ù‡
        gene_names = [gene.name for gene in gene_nodes if gene.kind == 'Gene']
        
        if not gene_names:
            return "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù‡ÛŒÚ† Ú˜Ù† Ø¨ÛŒØ§Ù† Ø´Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¢Ù†Ø§ØªÙˆÙ…ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        
        # ğŸ“Œ Ø¨Ø®Ø´ 1: Ù¾Ø±Ø³Ø´ Ø§ØµÙ„ÛŒ
        answer_parts.append(f"**ğŸ“Œ Ù¾Ø±Ø³Ø´:** {retrieval_result.query}")
        answer_parts.append("")
        
        # âœ… Ø¨Ø®Ø´ 2: Ù¾Ø§Ø³Ø® Ú©Ù„ÛŒØ¯ÛŒ
        answer_parts.append(f"**âœ… Ù¾Ø§Ø³Ø® Ú©Ù„ÛŒØ¯ÛŒ:**")
        answer_parts.append(f"Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒØŒ {len(gene_names)} Ú˜Ù† Ø¯Ø± Ø¨Ø§ÙØª {anatomy_name} Ø¨ÛŒØ§Ù† Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯:")
        
        for i, gene_name in enumerate(gene_names[:10], 1):  # Ø­Ø¯Ø§Ú©Ø«Ø± 10 Ú˜Ù†
            answer_parts.append(f"â€¢ {gene_name}")
        
        if len(gene_names) > 10:
            answer_parts.append(f"â€¢ Ùˆ {len(gene_names) - 10} Ú˜Ù† Ø¯ÛŒÚ¯Ø±")
        
            answer_parts.append("")
        
        # ğŸ” Ø¨Ø®Ø´ 3: Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø§Ø³ØªÙ†Ø§Ø¯
        answer_parts.append("**ğŸ” Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø§Ø³ØªÙ†Ø§Ø¯:**")
        
        # ÛŒØ§ÙØªÙ† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ AeG
        aeG_edges = [e for e in retrieval_result.edges if e.relation == 'AeG']
        if aeG_edges:
            answer_parts.append("Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒØ§Ù† Ù…Ø³ØªÙ‚ÛŒÙ… (Anatomy â†’ expresses â†’ Gene):")
            for edge in aeG_edges[:5]:  # Ø­Ø¯Ø§Ú©Ø«Ø± 5 Ø±Ø§Ø¨Ø·Ù‡
                source_name = next((n.name for n in retrieval_result.nodes if n.id == edge.source), edge.source)
                target_name = next((n.name for n in retrieval_result.nodes if n.id == edge.target), edge.target)
                answer_parts.append(f"â€¢ {source_name} â†’ {target_name} (AeG)")
        else:
            answer_parts.append("â€¢ Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒØ§Ù† Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯")
        
        # ÛŒØ§ÙØªÙ† ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ AuG Ùˆ AdG
        auG_edges = [e for e in retrieval_result.edges if e.relation == 'AuG']
        adG_edges = [e for e in retrieval_result.edges if e.relation == 'AdG']
        
        if auG_edges:
            answer_parts.append("Ø±ÙˆØ§Ø¨Ø· ØªÙ†Ø¸ÛŒÙ… Ù…Ø«Ø¨Øª (Anatomy â†’ upregulates â†’ Gene):")
            for edge in auG_edges[:3]:
                source_name = next((n.name for n in retrieval_result.nodes if n.id == edge.source), edge.source)
                target_name = next((n.name for n in retrieval_result.nodes if n.id == edge.target), edge.target)
                answer_parts.append(f"â€¢ {source_name} â†’ {target_name} (AuG)")
        
        if adG_edges:
            answer_parts.append("Ø±ÙˆØ§Ø¨Ø· ØªÙ†Ø¸ÛŒÙ… Ù…Ù†ÙÛŒ (Anatomy â†’ downregulates â†’ Gene):")
            for edge in adG_edges[:3]:
                source_name = next((n.name for n in retrieval_result.nodes if n.id == edge.source), edge.source)
                target_name = next((n.name for n in retrieval_result.nodes if n.id == edge.target), edge.target)
                answer_parts.append(f"â€¢ {source_name} â†’ {target_name} (AdG)")
        
        answer_parts.append("")
        
        # ğŸ“š Ø¨Ø®Ø´ 4: Ù…Ù†Ø¨Ø¹ Ø¯Ø§Ø¯Ù‡
        answer_parts.append("**ğŸ“š Ù…Ù†Ø¨Ø¹ Ø¯Ø§Ø¯Ù‡:**")
        answer_parts.append("â€¢ **Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ§Ù† Ú˜Ù†:** Ù¾Ø§ÛŒÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Bgee Ùˆ TISSUES")
        answer_parts.append("â€¢ **Ø±ÙˆØ§Ø¨Ø· Ø²ÛŒØ³ØªÛŒ:** Hetionet (Ø´Ø¨Ú©Ù‡ Ø¯Ø§Ù†Ø´ Ø²ÛŒØ³ØªÛŒ)")
        answer_parts.append("â€¢ **Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¢Ù†Ø§ØªÙˆÙ…ÛŒÚ©ÛŒ:** Uberon (Ø¢Ù†Ø§ØªÙˆÙ…ÛŒ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡)")
        answer_parts.append("â€¢ **Ø±ÙˆØ´ Ø¬Ø³ØªØ¬Ùˆ:** Intelligent Semantic Search Ø¨Ø§ ÙÛŒÙ„ØªØ± metaedge")
        answer_parts.append("")
        
        # ğŸ’¬ Ø¨Ø®Ø´ 5: ØªØ­Ù„ÛŒÙ„ Ø²ÛŒØ³ØªÛŒ
        answer_parts.append("**ğŸ’¬ ØªØ­Ù„ÛŒÙ„ Ø²ÛŒØ³ØªÛŒ:**")
        answer_parts.append(f"â€¢ **Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø·Ø¨ÛŒØ¹ÛŒ:** Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ§Ù† Ø´Ø¯Ù‡ Ø¯Ø± {anatomy_name} Ø¯Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ ÙÛŒØ²ÛŒÙˆÙ„ÙˆÚ˜ÛŒÚ© Ø§ÛŒÙ† Ø§Ù†Ø¯Ø§Ù… Ù†Ù‚Ø´ Ø¯Ø§Ø±Ù†Ø¯.")
        answer_parts.append(f"â€¢ **Ø§Ù‡Ù…ÛŒØª Ø¨Ø§Ù„ÛŒÙ†ÛŒ:** ØªØºÛŒÛŒØ±Ø§Øª Ø¯Ø± Ø¨ÛŒØ§Ù† Ø§ÛŒÙ† Ú˜Ù†â€ŒÙ‡Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ {anatomy_name} Ù…Ø±ØªØ¨Ø· Ø¨Ø§Ø´Ø¯.")
        answer_parts.append("â€¢ **Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø¯Ø±Ù…Ø§Ù†ÛŒ:** Ø§ÛŒÙ† Ú˜Ù†â€ŒÙ‡Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø§Ù‡Ø¯Ø§Ù Ø¯Ø±Ù…Ø§Ù†ÛŒ Ø¬Ø¯ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§Ø´Ù†Ø¯.")
        answer_parts.append("â€¢ **Ù†Ø´Ø§Ù†Ú¯Ø± Ø²ÛŒØ³ØªÛŒ:** Ø¨Ø±Ø®ÛŒ Ø§Ø² Ø§ÛŒÙ† Ú˜Ù†â€ŒÙ‡Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù†Ø´Ø§Ù†Ú¯Ø±Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆÙ†Ø¯.")
        answer_parts.append("")
        
        # ğŸ”¬ Ø¨Ø®Ø´ 6: Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ù¾Ú˜ÙˆÙ‡Ø´ÛŒ
        answer_parts.append("**ğŸ”¬ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ù¾Ú˜ÙˆÙ‡Ø´ÛŒ:**")
        answer_parts.append("â€¢ Ù…Ø·Ø§Ù„Ø¹Ù‡ Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø¨ÛŒØ§Ù† Ø§ÛŒÙ† Ú˜Ù†â€ŒÙ‡Ø§ Ø¯Ø± Ø´Ø±Ø§ÛŒØ· Ù…Ø®ØªÙ„Ù")
        answer_parts.append("â€¢ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÛŒÙ† ØªØºÛŒÛŒØ±Ø§Øª Ø¨ÛŒØ§Ù† Ùˆ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·")
        answer_parts.append("â€¢ ØªÙˆØ³Ø¹Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± ØªÙ†Ø¸ÛŒÙ… Ø¨ÛŒØ§Ù† Ú˜Ù†")
        answer_parts.append("â€¢ Ù¾Ú˜ÙˆÙ‡Ø´ Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡ Ù†Ø´Ø§Ù†Ú¯Ø±Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø²ÙˆØ¯Ù‡Ù†Ú¯Ø§Ù…")
        
        return "\n".join(answer_parts)
    
    def _generate_intelligent_general_answer(self, retrieval_result: RetrievalResult, gene_nodes, disease_nodes, drug_nodes, anatomy_nodes, process_nodes) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¹Ù…ÙˆÙ…ÛŒ"""
        query_lower = retrieval_result.query.lower()
        
        # ØªØ´Ø®ÛŒØµ Ø³ÙˆØ§Ù„Ø§Øª Ú˜Ù†-Ø³Ø±Ø·Ø§Ù†
        if self._is_gene_cancer_question_from_context(retrieval_result):
            return self._generate_gene_cancer_answer(retrieval_result, gene_nodes, disease_nodes)
        
        answer_parts = ["ğŸ“Š **ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹:**\n"]
        
        # Ø®Ù„Ø§ØµÙ‡ Ø¢Ù…Ø§Ø±ÛŒ
        total_entities = len(retrieval_result.nodes)
        total_relationships = len(retrieval_result.edges)
        
        answer_parts.append(f"**Ø®Ù„Ø§ØµÙ‡ Ø¢Ù…Ø§Ø±ÛŒ:**")
        answer_parts.append(f"â€¢ Ú©Ù„ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§: {total_entities}")
        answer_parts.append(f"â€¢ Ú©Ù„ Ø±ÙˆØ§Ø¨Ø·: {total_relationships}")
        answer_parts.append("")
        
        # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
        if gene_nodes:
            answer_parts.append(f"**Ú˜Ù†â€ŒÙ‡Ø§ ({len(gene_nodes)}):**")
            for gene in gene_nodes[:3]:
                score_info = f" (Ø§Ù…ØªÛŒØ§Ø²: {gene.score:.2f})" if hasattr(gene, 'score') and gene.score != 1.0 else ""
                answer_parts.append(f"â€¢ {gene.name}{score_info}")
            answer_parts.append("")
        
        if disease_nodes:
            answer_parts.append(f"**Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ ({len(disease_nodes)}):**")
            for disease in disease_nodes[:3]:
                answer_parts.append(f"â€¢ {disease.name}")
            answer_parts.append("")
        
        if drug_nodes:
            answer_parts.append(f"**Ø¯Ø§Ø±ÙˆÙ‡Ø§ ({len(drug_nodes)}):**")
            for drug in drug_nodes[:3]:
                answer_parts.append(f"â€¢ {drug.name}")
            answer_parts.append("")
        
        if anatomy_nodes:
            answer_parts.append(f"**Ø³Ø§Ø®ØªØ§Ø±Ù‡Ø§ÛŒ Ø¢Ù†Ø§ØªÙˆÙ…ÛŒÚ© ({len(anatomy_nodes)}):**")
            for anatomy in anatomy_nodes[:3]:
                answer_parts.append(f"â€¢ {anatomy.name}")
            answer_parts.append("")
        
        if process_nodes:
            answer_parts.append(f"**ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ ({len(process_nodes)}):**")
            for process in process_nodes[:3]:
                answer_parts.append(f"â€¢ {process.name}")
            answer_parts.append("")
        
        # Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ø±ÙˆØ§Ø¨Ø·
        if retrieval_result.edges:
            answer_parts.append("**Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ø±ÙˆØ§Ø¨Ø·:**")
            # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø±Ø§Ø¨Ø·Ù‡
            relations_count = {}
            for edge in retrieval_result.edges:
                relations_count[edge.relation] = relations_count.get(edge.relation, 0) + 1
            
            for relation, count in sorted(relations_count.items(), key=lambda x: x[1], reverse=True)[:3]:
                answer_parts.append(f"â€¢ {relation}: {count} Ø±Ø§Ø¨Ø·Ù‡")
        
        if not retrieval_result.nodes:
            answer_parts.append("âŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø·ÛŒ Ø¯Ø± Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        
        return "\n".join(answer_parts)
    
    def _is_gene_cancer_question_from_context(self, retrieval_result: RetrievalResult) -> bool:
        """ØªØ´Ø®ÛŒØµ Ø³ÙˆØ§Ù„Ø§Øª Ú˜Ù†-Ø³Ø±Ø·Ø§Ù† Ø§Ø² Ù…Ø­ØªÙˆØ§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯Ù‡"""
        query_lower = retrieval_result.query.lower()
        cancer_keywords = ['cancer', 'tumor', 'malignancy', 'oncology', 'carcinoma', 'sarcoma', 'leukemia', 'lymphoma']
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ú©Ù„Ù…Ø§Øª Ø³Ø±Ø·Ø§Ù† Ø¯Ø± Ø³ÙˆØ§Ù„
        has_cancer_in_query = any(keyword in query_lower for keyword in cancer_keywords)
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ú˜Ù†â€ŒÙ‡Ø§ Ùˆ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø±Ø·Ø§Ù† Ø¯Ø± Ù†ØªØ§ÛŒØ¬
        gene_nodes = [n for n in retrieval_result.nodes if n.kind == 'Gene']
        disease_nodes = [n for n in retrieval_result.nodes if n.kind == 'Disease']
        
        has_genes = len(gene_nodes) > 0
        has_cancer_diseases = any(
            any(keyword in disease.name.lower() for keyword in cancer_keywords)
            for disease in disease_nodes
        )
        
        return has_cancer_in_query and has_genes and has_cancer_diseases
    
    def _generate_gene_cancer_answer(self, retrieval_result: RetrievalResult, gene_nodes, disease_nodes) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® ØªØ®ØµØµÛŒ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ú˜Ù†-Ø³Ø±Ø·Ø§Ù†"""
        answer_parts = ["ğŸ§¬ **ØªØ­Ù„ÛŒÙ„ ØªØ®ØµØµÛŒ Ú˜Ù†-Ø³Ø±Ø·Ø§Ù†:**\n"]
        
        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
        primary_genes = []
        for gene in gene_nodes:
            gene_name_lower = gene.name.lower()
            # Ø¨Ø±Ø±Ø³ÛŒ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ù‡ÙˆØ±
            famous_genes = ['tp53', 'p53', 'brca1', 'brca2', 'apoe', 'cftr', 'mmp9', 'bid', 'kcnq2', 'hmgb3']
            if any(famous in gene_name_lower for famous in famous_genes):
                primary_genes.append(gene)
        
        if primary_genes:
            answer_parts.append("**Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡:**")
            for gene in primary_genes:
                score_info = f" (Ø§Ù…ØªÛŒØ§Ø²: {gene.score:.2f})" if hasattr(gene, 'score') and gene.score != 1.0 else ""
                answer_parts.append(f"â€¢ **{gene.name}**{score_info}")
            answer_parts.append("")
        
        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø³Ø±Ø·Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
        cancer_diseases = []
        other_diseases = []
        
        for disease in disease_nodes:
            disease_name_lower = disease.name.lower()
            cancer_keywords = ['cancer', 'tumor', 'malignancy', 'carcinoma', 'sarcoma', 'leukemia', 'lymphoma']
            if any(keyword in disease_name_lower for keyword in cancer_keywords):
                cancer_diseases.append(disease)
            else:
                other_diseases.append(disease)
        
        if cancer_diseases:
            answer_parts.append("**Ø³Ø±Ø·Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·:**")
            for cancer in cancer_diseases:
                answer_parts.append(f"â€¢ {cancer.name}")
            answer_parts.append("")
        
        if other_diseases:
            answer_parts.append("**Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ù…Ø±ØªØ¨Ø·:**")
            for disease in other_diseases[:3]:
                answer_parts.append(f"â€¢ {disease.name}")
            answer_parts.append("")
        
        # ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ§Ø¨Ø·
        if retrieval_result.edges:
            answer_parts.append("**Ø±ÙˆØ§Ø¨Ø· Ù…Ù‡Ù… ÛŒØ§ÙØª Ø´Ø¯Ù‡:**")
            relations_count = {}
            for edge in retrieval_result.edges:
                relations_count[edge.relation] = relations_count.get(edge.relation, 0) + 1
            
            for relation, count in sorted(relations_count.items(), key=lambda x: x[1], reverse=True)[:5]:
                answer_parts.append(f"â€¢ {relation}: {count} Ø±Ø§Ø¨Ø·Ù‡")
            answer_parts.append("")
        
        # ØªØ­Ù„ÛŒÙ„ Ø¢Ù…Ø§Ø±ÛŒ
        total_entities = len(retrieval_result.nodes)
        total_relationships = len(retrieval_result.edges)
        
        answer_parts.append("**Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ:**")
        answer_parts.append(f"â€¢ Ú©Ù„ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§: {total_entities}")
        answer_parts.append(f"â€¢ Ú©Ù„ Ø±ÙˆØ§Ø¨Ø·: {total_relationships}")
        answer_parts.append(f"â€¢ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ: {len(primary_genes)}")
        answer_parts.append(f"â€¢ Ø³Ø±Ø·Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·: {len(cancer_diseases)}")
        
        # ØªØ­Ù„ÛŒÙ„ ØªØ®ØµØµÛŒ Ø¨Ø±Ø§ÛŒ TP53
        if any('tp53' in gene.name.lower() for gene in primary_genes):
            answer_parts.append("\nğŸ”¬ **ØªØ­Ù„ÛŒÙ„ ØªØ®ØµØµÛŒ TP53:**")
            answer_parts.append("TP53 (Tumor Protein P53) ÛŒÚ©ÛŒ Ø§Ø² Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø³Ø±Ú©ÙˆØ¨Ú¯Ø± ØªÙˆÙ…ÙˆØ± Ø§Ø³Øª Ú©Ù‡:")
            answer_parts.append("â€¢ Ø¯Ø± Ø¨ÛŒØ´ Ø§Ø² 50% Ø³Ø±Ø·Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø§Ù†Ø³Ø§Ù†ÛŒ Ø¬Ù‡Ø´ ÛŒØ§ÙØªÙ‡ Ø§Ø³Øª")
            answer_parts.append("â€¢ Ù†Ù‚Ø´ Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ… Ú†Ø±Ø®Ù‡ Ø³Ù„ÙˆÙ„ÛŒ Ùˆ Ø¢Ù¾ÙˆÙ¾ØªÙˆØ² Ø¯Ø§Ø±Ø¯")
            answer_parts.append("â€¢ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† 'Ù†Ú¯Ù‡Ø¨Ø§Ù† Ú˜Ù†ÙˆÙ…' Ø´Ù†Ø§Ø®ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
            answer_parts.append("â€¢ Ø§Ø®ØªÙ„Ø§Ù„ Ø¯Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¢Ù† Ù…Ù†Ø¬Ø± Ø¨Ù‡ ØªÚ©Ø«ÛŒØ± ØºÛŒØ±Ù‚Ø§Ø¨Ù„ Ú©Ù†ØªØ±Ù„ Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
            answer_parts.append("")
        
        # ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ§Ø¨Ø· Ø®Ø§Øµ
        if retrieval_result.edges:
            answer_parts.append("**ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ§Ø¨Ø· ÛŒØ§ÙØª Ø´Ø¯Ù‡:**")
            gene_cancer_edges = []
            for edge in retrieval_result.edges:
                source_node = next((n for n in retrieval_result.nodes if n.id == edge.source), None)
                target_node = next((n for n in retrieval_result.nodes if n.id == edge.target), None)
                if source_node and target_node:
                    if (source_node.kind == 'Gene' and target_node.kind == 'Disease') or \
                       (source_node.kind == 'Disease' and target_node.kind == 'Gene'):
                        gene_cancer_edges.append((source_node, target_node, edge.relation))
            
            if gene_cancer_edges:
                answer_parts.append("Ø±ÙˆØ§Ø¨Ø· Ú˜Ù†-Ø³Ø±Ø·Ø§Ù† ÛŒØ§ÙØª Ø´Ø¯Ù‡:")
                for source, target, relation in gene_cancer_edges[:5]:
                    answer_parts.append(f"â€¢ {source.name} â†’ {target.name} ({relation})")
                answer_parts.append("")
        
        # Ù¾ÛŒØ§Ù… Ø±Ø§Ù‡Ù†Ù…Ø§
        answer_parts.append("ğŸ“Œ **Ø±Ø§Ù‡Ù†Ù…Ø§:** ØªØ­Ù„ÛŒÙ„ Ø§Ù‡Ù…ÛŒØª Ø²ÛŒØ³ØªÛŒ Ùˆ Ø¨Ø§Ù„ÛŒÙ†ÛŒ Ø§ÛŒÙ† Ú˜Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
        
        return "\n".join(answer_parts)
    
    def custom_generation(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø³ÙØ§Ø±Ø´ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        query = retrieval_result.query
        query_lower = query.lower()
        
        # ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚â€ŒØªØ± Ø³ÙˆØ§Ù„
        question_type = self._analyze_question_type(query_lower)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ±
        gene_nodes = [n for n in retrieval_result.nodes if n.kind == 'Gene']
        disease_nodes = [n for n in retrieval_result.nodes if n.kind == 'Disease']
        drug_nodes = [n for n in retrieval_result.nodes if n.kind in ['Drug', 'Compound']]
        anatomy_nodes = [n for n in retrieval_result.nodes if n.kind == 'Anatomy']
        process_nodes = [n for n in retrieval_result.nodes if n.kind == 'Biological Process']
        symptom_nodes = [n for n in retrieval_result.nodes if n.kind == 'Symptom']
        
        # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø³ÙØ§Ø±Ø´ÛŒ Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚
        answer_parts = ["ğŸ¯ **ØªØ­Ù„ÛŒÙ„ Ø³ÙØ§Ø±Ø´ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡:**\n"]
        
        # ØªØ­Ù„ÛŒÙ„ Ú©ÛŒÙÛŒØª Ù†ØªØ§ÛŒØ¬
        total_score = sum(getattr(n, 'score', 1.0) for n in retrieval_result.nodes)
        avg_score = total_score / len(retrieval_result.nodes) if retrieval_result.nodes else 0
        
        answer_parts.append(f"**Ú©ÛŒÙÛŒØª Ù†ØªØ§ÛŒØ¬:**")
        answer_parts.append(f"â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø²: {avg_score:.2f}")
        answer_parts.append(f"â€¢ ØªØ¹Ø¯Ø§Ø¯ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ø¨Ø§ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§: {len([n for n in retrieval_result.nodes if getattr(n, 'score', 1.0) > 2.0])}")
        answer_parts.append("")
        
        # ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„
        if question_type == "relationship":
            answer_parts.extend(self._custom_relationship_analysis(retrieval_result, gene_nodes, disease_nodes, drug_nodes))
        elif question_type == "drug_treatment":
            answer_parts.extend(self._custom_drug_analysis(retrieval_result, drug_nodes, disease_nodes))
        elif question_type == "gene_function":
            answer_parts.extend(self._custom_gene_analysis(retrieval_result, gene_nodes, process_nodes))
        elif question_type == "disease_info":
            answer_parts.extend(self._custom_disease_analysis(retrieval_result, disease_nodes, gene_nodes, symptom_nodes))
        elif question_type == "anatomy_expression":
            answer_parts.extend(self._custom_anatomy_analysis(retrieval_result, anatomy_nodes, gene_nodes))
        else:
            answer_parts.extend(self._custom_general_analysis(retrieval_result, gene_nodes, disease_nodes, drug_nodes, anatomy_nodes, process_nodes))
        
        # ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ
        answer_parts.append("**ğŸ’¡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ:**")
        if len(retrieval_result.nodes) < 5:
            answer_parts.append("â€¢ Ø§ÙØ²Ø§ÛŒØ´ Ø¹Ù…Ù‚ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ù†ØªØ§ÛŒØ¬ Ø¨ÛŒØ´ØªØ±")
        if len(retrieval_result.edges) < 3:
            answer_parts.append("â€¢ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒØ´ØªØ±")
        if avg_score < 2.0:
            answer_parts.append("â€¢ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ Ensemble Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ú©ÛŒÙÛŒØª Ù†ØªØ§ÛŒØ¬")
        
        return "\n".join(answer_parts)
    
    def _custom_relationship_analysis(self, retrieval_result: RetrievalResult, gene_nodes, disease_nodes, drug_nodes) -> List[str]:
        """ØªØ­Ù„ÛŒÙ„ Ø³ÙØ§Ø±Ø´ÛŒ Ø±ÙˆØ§Ø¨Ø·"""
        parts = []
        parts.append("**ğŸ” ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ§Ø¨Ø·:**")
        
        if retrieval_result.edges:
            # ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ø±ÙˆØ§Ø¨Ø·
            edge_types = {}
            for edge in retrieval_result.edges:
                edge_types[edge.relation] = edge_types.get(edge.relation, 0) + 1
            
            parts.append(f"â€¢ Ø§Ù†ÙˆØ§Ø¹ Ø±ÙˆØ§Ø¨Ø· ÛŒØ§ÙØª Ø´Ø¯Ù‡: {len(edge_types)}")
            parts.append(f"â€¢ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ø´Ø¨Ú©Ù‡: {len(retrieval_result.edges)} / {len(retrieval_result.nodes)} = {len(retrieval_result.edges)/len(retrieval_result.nodes):.2f}")
            
            # Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ø±ÙˆØ§Ø¨Ø·
            most_common = max(edge_types.items(), key=lambda x: x[1])
            parts.append(f"â€¢ Ø±Ø§ÛŒØ¬â€ŒØªØ±ÛŒÙ† Ø±Ø§Ø¨Ø·Ù‡: {most_common[0]} ({most_common[1]} Ø¨Ø§Ø±)")
        else:
            parts.append("â€¢ Ù‡ÛŒÚ† Ø±Ø§Ø¨Ø·Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ…ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
        
        return parts
    
    def _custom_drug_analysis(self, retrieval_result: RetrievalResult, drug_nodes, disease_nodes) -> List[str]:
        """ØªØ­Ù„ÛŒÙ„ Ø³ÙØ§Ø±Ø´ÛŒ Ø¯Ø§Ø±ÙˆÛŒÛŒ"""
        parts = []
        parts.append("**ğŸ’Š ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ:**")
        
        if drug_nodes:
            # ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø±ÙˆÙ‡Ø§ÛŒ Ù…Ù‡Ù…
            high_score_drugs = [d for d in drug_nodes if getattr(d, 'score', 1.0) > 2.0]
            parts.append(f"â€¢ Ø¯Ø§Ø±ÙˆÙ‡Ø§ÛŒ Ø¨Ø§ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§: {len(high_score_drugs)}")
            
            if high_score_drugs:
                parts.append("â€¢ Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ø¯Ø§Ø±ÙˆÙ‡Ø§:")
                for drug in high_score_drugs[:3]:
                    parts.append(f"  - {drug.name} (Ø§Ù…ØªÛŒØ§Ø²: {drug.score:.2f})")
        
        if disease_nodes:
            parts.append(f"â€¢ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·: {len(disease_nodes)}")
        
        return parts
    
    def _custom_gene_analysis(self, retrieval_result: RetrievalResult, gene_nodes, process_nodes) -> List[str]:
        """ØªØ­Ù„ÛŒÙ„ Ø³ÙØ§Ø±Ø´ÛŒ Ú˜Ù†ØªÛŒÚ©ÛŒ"""
        parts = []
        parts.append("**ğŸ§¬ ØªØ­Ù„ÛŒÙ„ Ú˜Ù†ØªÛŒÚ©ÛŒ:**")
        
        if gene_nodes:
            # ØªØ­Ù„ÛŒÙ„ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…
            sorted_genes = sorted(gene_nodes, key=lambda x: getattr(x, 'score', 1.0), reverse=True)
            parts.append(f"â€¢ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡: {len(gene_nodes)}")
            parts.append("â€¢ Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ú˜Ù†â€ŒÙ‡Ø§:")
            for gene in sorted_genes[:3]:
                parts.append(f"  - {gene.name} (Ø§Ù…ØªÛŒØ§Ø²: {gene.score:.2f})")
        
        if process_nodes:
            parts.append(f"â€¢ ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ: {len(process_nodes)}")
        
        return parts
    
    def _custom_disease_analysis(self, retrieval_result: RetrievalResult, disease_nodes, gene_nodes, symptom_nodes) -> List[str]:
        """ØªØ­Ù„ÛŒÙ„ Ø³ÙØ§Ø±Ø´ÛŒ Ø¨ÛŒÙ…Ø§Ø±ÛŒ"""
        parts = []
        parts.append("**ğŸ¥ ØªØ­Ù„ÛŒÙ„ Ø¨ÛŒÙ…Ø§Ø±ÛŒ:**")
        
        if disease_nodes:
            parts.append(f"â€¢ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡: {len(disease_nodes)}")
        
        if gene_nodes:
            parts.append(f"â€¢ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·: {len(gene_nodes)}")
        
        if symptom_nodes:
            parts.append(f"â€¢ Ø¹Ù„Ø§Ø¦Ù… Ù…Ø±ØªØ¨Ø·: {len(symptom_nodes)}")
        
        return parts
    
    def _custom_anatomy_analysis(self, retrieval_result: RetrievalResult, anatomy_nodes, gene_nodes) -> List[str]:
        """ØªØ­Ù„ÛŒÙ„ Ø³ÙØ§Ø±Ø´ÛŒ Ø¢Ù†Ø§ØªÙˆÙ…ÛŒÚ©"""
        parts = []
        parts.append("**ğŸ«€ ØªØ­Ù„ÛŒÙ„ Ø¢Ù†Ø§ØªÙˆÙ…ÛŒÚ©:**")
        
        if anatomy_nodes:
            parts.append(f"â€¢ Ø³Ø§Ø®ØªØ§Ø±Ù‡Ø§ÛŒ Ø¢Ù†Ø§ØªÙˆÙ…ÛŒÚ©: {len(anatomy_nodes)}")
        
        if gene_nodes:
            parts.append(f"â€¢ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ§Ù† Ø´Ø¯Ù‡: {len(gene_nodes)}")
        
        return parts
    
    def _custom_general_analysis(self, retrieval_result: RetrievalResult, gene_nodes, disease_nodes, drug_nodes, anatomy_nodes, process_nodes) -> List[str]:
        """ØªØ­Ù„ÛŒÙ„ Ø³ÙØ§Ø±Ø´ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ"""
        parts = []
        parts.append("**ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹:**")
        
        # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
        parts.append(f"â€¢ Ú©Ù„ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§: {len(retrieval_result.nodes)}")
        parts.append(f"â€¢ Ú©Ù„ Ø±ÙˆØ§Ø¨Ø·: {len(retrieval_result.edges)}")
        parts.append(f"â€¢ ØªØ±Ø§Ú©Ù… Ø´Ø¨Ú©Ù‡: {len(retrieval_result.edges)/max(len(retrieval_result.nodes), 1):.2f}")
        
        # ØªÙˆØ²ÛŒØ¹ Ø§Ù†ÙˆØ§Ø¹
        type_distribution = {}
        for node in retrieval_result.nodes:
            type_distribution[node.kind] = type_distribution.get(node.kind, 0) + 1
        
        parts.append("â€¢ ØªÙˆØ²ÛŒØ¹ Ø§Ù†ÙˆØ§Ø¹:")
        for kind, count in sorted(type_distribution.items(), key=lambda x: x[1], reverse=True):
            parts.append(f"  - {kind}: {count}")
        
        return parts
    
    def process_query(self, query: str, retrieval_method: RetrievalMethod, 
                     generation_model: GenerationModel, text_generation_type: str = 'INTELLIGENT', 
                     max_depth: int = 2) -> Dict[str, Any]:
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ ÛŒÚ© Ø³ÙˆØ§Ù„"""
        print(f"ğŸš€ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³ÙˆØ§Ù„: {query}")
        print(f"ğŸ“ Ù†ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ†: {text_generation_type}")
        
        # Ù…Ø±Ø­Ù„Ù‡ 1: Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ
        retrieval_result = self.retrieve_information(query, retrieval_method, max_depth)
        
        # Ù…Ø±Ø­Ù„Ù‡ 2: ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®
        generation_result = self.generate_answer(retrieval_result, generation_model, text_generation_type)
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†ØªÛŒØ¬Ù‡
        result = {
            "query": query,
            "retrieval_method": retrieval_method.value,
            "generation_model": generation_model.value,
            "keywords": self.extract_keywords(query),
            "matched_nodes": {k: self.G.nodes[v]['name'] for k, v in self.match_tokens_to_nodes(self.extract_keywords(query)).items()},
            "retrieved_nodes": [
                {
                    "id": node.id,
                    "name": node.name,
                    "kind": node.kind,
                    "depth": node.depth,
                    "score": node.score
                } for node in retrieval_result.nodes
            ],
            "retrieved_edges": [
                {
                    "source": edge.source,
                    "target": edge.target,
                    "relation": edge.relation,
                    "weight": edge.weight
                } for edge in retrieval_result.edges
            ],
            "paths": retrieval_result.paths,
            "context_text": retrieval_result.context_text,
            "answer": generation_result.answer,
            "confidence": generation_result.confidence,
            "process_steps": [
                "1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø§Ø² Ø³ÙˆØ§Ù„",
                "2. ØªØ·Ø¨ÛŒÙ‚ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø§ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ú¯Ø±Ø§Ù",
                f"3. Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø§ Ø±ÙˆØ´ {retrieval_method.value}",
                "4. Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ø§Ø² Ù†ØªØ§ÛŒØ¬",
                f"5. ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ Ù…Ø¯Ù„ {generation_model.value}"
            ]
        }
        
        return result
    
    def huggingface_generation(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ HuggingFace (Ø±Ø§ÛŒÚ¯Ø§Ù†)"""
        try:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† HuggingFace
            from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
            import torch
            
            # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯
            models = [
                "microsoft/DialoGPT-medium",  # Ú†Øªâ€ŒØ¨Ø§Øª
                "gpt2",  # GPT-2
                "distilgpt2",  # GPT-2 Ø³Ø¨Ú©
                "EleutherAI/gpt-neo-125M",  # GPT-Neo Ú©ÙˆÚ†Ú©
                "microsoft/DialoGPT-small"  # Ú†Øªâ€ŒØ¨Ø§Øª Ú©ÙˆÚ†Ú©
            ]
            
            # Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ù…ÙˆØ¬ÙˆØ¯
            selected_model = None
            for model_name in models:
                try:
                    tokenizer = AutoTokenizer.from_pretrained(model_name)
                    model = AutoModelForCausalLM.from_pretrained(model_name)
                    selected_model = model_name
                    break
                except:
                    continue
            
            if selected_model is None:
                return self._fallback_generation(retrieval_result, "HuggingFace")
            
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
            prompt = self._create_advanced_prompt(retrieval_result)
            
            # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®
            inputs = tokenizer.encode(prompt, return_tensors="pt", max_length=512, truncation=True)
            
            with torch.no_grad():
                outputs = model.generate(
                    inputs,
                    max_length=300,
                    num_return_sequences=1,
                    temperature=0.7,
                    do_sample=True,
                    pad_token_id=tokenizer.eos_token_id
                )
            
            response = tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾Ø§Ø³Ø® Ø§Ø² Ø®Ø±ÙˆØ¬ÛŒ
            if len(response) > len(prompt):
                answer = response[len(prompt):].strip()
            else:
                answer = response.strip()
            
            return answer if answer else self._fallback_generation(retrieval_result, "HuggingFace")
            
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± HuggingFace: {e}")
            return self._fallback_generation(retrieval_result, "HuggingFace")
    
    def openai_gpt_generation(self, retrieval_result: RetrievalResult, model: GenerationModel = None) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ OpenAI GPT (Ù†ÛŒØ§Ø² Ø¨Ù‡ API Key)"""
        try:
            from openai import OpenAI
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ API Key
            if not hasattr(self, 'openai_api_key') or not self.openai_api_key:
                return "ğŸ”‘ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² OpenAI GPTØŒ Ù„Ø·ÙØ§Ù‹ API Key Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.\n\n" + self._fallback_generation(retrieval_result, "OpenAI")
            
            # ØªØ¹ÛŒÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±
            model_mapping = {
                GenerationModel.OPENAI_GPT_4O: "gpt-4o",
                GenerationModel.OPENAI_GPT_4O_MINI: "gpt-4o-mini",
                GenerationModel.OPENAI_GPT_4_TURBO: "gpt-4-turbo",
                GenerationModel.OPENAI_GPT_4: "gpt-4",
                GenerationModel.OPENAI_GPT_3_5_TURBO: "gpt-3.5-turbo",
                GenerationModel.OPENAI_GPT_3_5_TURBO_16K: "gpt-3.5-turbo-16k",
                GenerationModel.OPENAI_GPT: "gpt-4o"  # Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ†
            }
            
            model_choice = model_mapping.get(model, "gpt-4o")  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù…Ø¯Ù„
            max_tokens = 1500 if "4o" in model_choice else 1000
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù„Ø§ÛŒÙ†Øª OpenAI
            client = OpenAI(api_key=self.openai_api_key)
            
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
            prompt = self._create_advanced_prompt(retrieval_result)
            
            # Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ OpenAI
            response = client.chat.completions.create(
                model=model_choice,
                messages=[
                    {"role": "system", "content": "You are a biomedical expert analyzing knowledge graph data. Provide detailed, accurate, and well-structured answers in Persian with proper formatting and emojis."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7,
                presence_penalty=0.1,  # ØªØ´ÙˆÛŒÙ‚ Ø¨Ù‡ ØªÙ†ÙˆØ¹
                frequency_penalty=0.1   # Ú©Ø§Ù‡Ø´ ØªÚ©Ø±Ø§Ø±
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± OpenAI ({model_choice}): {e}")
            return self._fallback_generation(retrieval_result, f"OpenAI ({model_choice})")
    
    def anthropic_claude_generation(self, retrieval_result: RetrievalResult, model: GenerationModel = None) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ Anthropic Claude (Ù†ÛŒØ§Ø² Ø¨Ù‡ API Key)"""
        try:
            import anthropic
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ API Key
            if not hasattr(self, 'anthropic_api_key') or not self.anthropic_api_key:
                return "ğŸ”‘ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ClaudeØŒ Ù„Ø·ÙØ§Ù‹ API Key Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.\n\n" + self._fallback_generation(retrieval_result, "Claude")
            
            # ØªØ¹ÛŒÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±
            model_mapping = {
                GenerationModel.ANTHROPIC_CLAUDE_3_5_SONNET: "claude-3-5-sonnet-20241022",
                GenerationModel.ANTHROPIC_CLAUDE_3_5_HAIKU: "claude-3-5-haiku-20241022",
                GenerationModel.ANTHROPIC_CLAUDE_3_OPUS: "claude-3-opus-20240229",
                GenerationModel.ANTHROPIC_CLAUDE_3_SONNET: "claude-3-sonnet-20240229",
                GenerationModel.ANTHROPIC_CLAUDE_3_HAIKU: "claude-3-haiku-20240307",
                GenerationModel.ANTHROPIC_CLAUDE: "claude-3-5-sonnet-20241022"  # Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ†
            }
            
            model_choice = model_mapping.get(model, "claude-3-5-sonnet-20241022")  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù…Ø¯Ù„
            max_tokens = 1500 if "3-5" in model_choice else 1000
            
            client = anthropic.Anthropic(api_key=self.anthropic_api_key)
            
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
            prompt = self._create_advanced_prompt(retrieval_result)
            
            # Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ Claude
            response = client.messages.create(
                model=model_choice,
                max_tokens=max_tokens,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            return response.content[0].text.strip()
            
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Claude ({model_choice}): {e}")
            return self._fallback_generation(retrieval_result, f"Claude ({model_choice})")
    
    def google_gemini_generation(self, retrieval_result: RetrievalResult, model: GenerationModel = None) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ Google Gemini (Ù†ÛŒØ§Ø² Ø¨Ù‡ API Key)"""
        try:
            import google.generativeai as genai
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ API Key
            if not hasattr(self, 'gemini_api_key') or not self.gemini_api_key:
                return "ğŸ”‘ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² GeminiØŒ Ù„Ø·ÙØ§Ù‹ API Key Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.\n\n" + self._fallback_generation(retrieval_result, "Gemini")
            
            # ØªØ¹ÛŒÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±
            model_mapping = {
                GenerationModel.GOOGLE_GEMINI_1_5_PRO: "gemini-1.5-pro",
                GenerationModel.GOOGLE_GEMINI_1_5_FLASH: "gemini-1.5-flash",
                GenerationModel.GOOGLE_GEMINI_1_0_PRO: "gemini-1.0-pro",
                GenerationModel.GOOGLE_GEMINI_1_0_FLASH: "gemini-1.0-flash",
                GenerationModel.GOOGLE_GEMINI: "gemini-1.5-pro"  # Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ†
            }
            
            model_choice = model_mapping.get(model, "gemini-1.5-pro")  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù…Ø¯Ù„
            
            genai.configure(api_key=self.gemini_api_key)
            model_instance = genai.GenerativeModel(model_choice)
            
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
            prompt = self._create_advanced_prompt(retrieval_result)
            
            # Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ Gemini
            response = model_instance.generate_content(prompt)
            
            return response.text.strip()
            
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Gemini ({model_choice}): {e}")
            return self._fallback_generation(retrieval_result, f"Gemini ({model_choice})")
    
    def _create_advanced_prompt(self, retrieval_result: RetrievalResult) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ³ØªÛŒ ØºÙ†ÛŒ Ø´Ø¯Ù‡"""
        query = retrieval_result.query
        context = retrieval_result.context_text
        method = retrieval_result.method
        
        # ØºÙ†ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ³ØªÛŒ
        enriched_data = self._enrich_retrieved_data(retrieval_result.nodes, retrieval_result.edges, query)
        
        # ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„
        question_type = self._analyze_question_type(query.lower())
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø§Ø² Ú¯Ø±Ø§Ù Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ ÛŒØ§ Ù†Ù‡
        if method == "Ø¨Ø¯ÙˆÙ† Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ (ÙÙ‚Ø· Ù…Ø¯Ù„)":
            # ÙÙ‚Ø· Ù…Ø¯Ù„ - Ø¨Ø¯ÙˆÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú¯Ø±Ø§Ù
            system_prompt = """You are an expert biomedical AI assistant with comprehensive knowledge of:
            - Molecular biology and genetics
            - Drug discovery and pharmacology
            - Disease mechanisms and pathology
            - Biological pathways and networks
            - Clinical medicine and therapeutics
            
            Your task is to provide detailed, accurate, and well-structured answers to biomedical questions
            based on your training knowledge. Focus on:
            - Scientific accuracy and current understanding
            - Comprehensive analysis and insights
            - Practical implications and applications
            - Research directions and future possibilities
            
            Always answer in Persian with proper formatting and structure your response with clear sections.
            Do not use emojis in your response."""
            
            user_prompt = f"""
            **Ø³ÙˆØ§Ù„ Ù¾Ø²Ø´Ú©ÛŒ-Ø²ÛŒØ³ØªÛŒ:**
            {query}
            
            **Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ:**
            Ù„Ø·ÙØ§Ù‹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ù†Ø´ ØªØ®ØµØµÛŒ Ø®ÙˆØ¯ Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡ Ø¹Ù„ÙˆÙ… Ø²ÛŒØ³ØªÛŒ Ùˆ Ù¾Ø²Ø´Ú©ÛŒØŒ Ù¾Ø§Ø³Ø® Ø¬Ø§Ù…Ø¹ Ùˆ Ø¯Ù‚ÛŒÙ‚ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ú©Ù‡ Ø´Ø§Ù…Ù„:
            
            1. **ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¶ÙˆØ¹:** Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚ Ø³ÙˆØ§Ù„ Ùˆ Ø¬Ù†Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¢Ù†
            2. **Ù…Ø¨Ø§Ù†ÛŒ Ø¹Ù„Ù…ÛŒ:** ØªÙˆØ¶ÛŒØ­ Ù…Ú©Ø§Ù†ÛŒØ²Ù…â€ŒÙ‡Ø§ Ùˆ ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ù…Ø±ØªØ¨Ø·
            3. **Ø¬Ù†Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†ÛŒ:** Ø¯Ø± ØµÙˆØ±Øª Ù…Ø±ØªØ¨Ø· Ø¨ÙˆØ¯Ù†ØŒ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†ÛŒ Ùˆ Ø¯Ø§Ø±ÙˆÛŒÛŒ
            4. **ØªØ­Ù‚ÛŒÙ‚Ø§Øª:** ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ ØªØ­Ù‚ÛŒÙ‚Ø§Øª Ùˆ Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø·
            5. **Ú†Ø´Ù…â€ŒØ§Ù†Ø¯Ø§Ø² Ø¢ÛŒÙ†Ø¯Ù‡:** Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ Ùˆ Ù¾ÛŒØ´Ø±ÙØªâ€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡
            6. **ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ:** Ù†Ú©Ø§Øª Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ Ù¾Ú˜ÙˆÙ‡Ø´Ú¯Ø±Ø§Ù† Ùˆ Ù¾Ø²Ø´Ú©Ø§Ù†
            
            Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ùˆ Ø¨Ø§ ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.
            """
            
        else:
            # Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú¯Ø±Ø§Ù Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØºÙ†ÛŒ Ø´Ø¯Ù‡
            system_prompt = """You are a biomedical knowledge graph expert analyzing data from Hetionet, a comprehensive
                biological knowledge graph containing information about:
                - Genes, proteins, and their functions
                - Diseases and their molecular mechanisms
                - Drugs, compounds, and their therapeutic effects
                - Biological processes and pathways
                - Anatomical structures and gene expression
                - Clinical relationships and treatment outcomes

                Your task is to provide precise, actionable analysis based on the retrieved graph data:
                - Evaluate biological relevance of genes to the specific query context
                - Assess clinical significance and potential therapeutic applications
                - Identify genes that are most likely to be clinically actionable
                - Provide specific insights rather than generic statements
                - Consider pathway involvement and disease associations
                - Focus on actionable insights and specific biological relevance

                IMPORTANT: 
                - Base your analysis primarily on the provided graph data
                - Supplement with your biomedical knowledge when needed
                - Provide specific, actionable insights rather than general statements
                - Focus on clinical relevance and therapeutic potential
                - Be precise about biological functions and mechanisms

                Always answer in Persian with proper formatting and structure your response with clear sections.
                Do not use emojis in your response."""
            
            user_prompt = f"""
            **Ø³ÙˆØ§Ù„:** {query}
            
            **Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯Ù‡:**
            {context}
            
            **Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„:** Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ØŒ Ù¾Ø§Ø³Ø® Ø¯Ù‚ÛŒÙ‚ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯. Ø¨Ø± Ø§Ù‡Ù…ÛŒØª Ø²ÛŒØ³ØªÛŒ Ùˆ Ø¨Ø§Ù„ÛŒÙ†ÛŒ ØªÙ…Ø±Ú©Ø² Ú©Ù†ÛŒØ¯.
            """
        
        return f"{system_prompt}\n\n{user_prompt}"
    
    def _fallback_generation(self, retrieval_result: RetrievalResult, model_name: str) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§"""
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø®Ù„ÛŒ Ø¨Ù‡ Ø¬Ø§ÛŒ Ù¾ÛŒØ§Ù… Ø³Ø§Ø¯Ù‡
        return f"""ğŸ¤– **ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ {model_name} (Ù¾Ø§Ø³Ø® Ù¾Ø´ØªÛŒØ¨Ø§Ù†):**

{self.gpt_simulation_generation(retrieval_result)}

---
ğŸ’¡ **Ù†Ú©ØªÙ‡:** Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡â€ŒØªØ±ØŒ Ù„Ø·ÙØ§Ù‹ API Key Ù…Ø±Ø¨ÙˆØ·Ù‡ Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.
"""
    
    def set_openai_api_key(self, api_key: str):
        """ØªÙ†Ø¸ÛŒÙ… API Key Ø¨Ø±Ø§ÛŒ OpenAI"""
        self.openai_api_key = api_key
        print("âœ… OpenAI API Key ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯")
    
    def set_anthropic_api_key(self, api_key: str):
        """ØªÙ†Ø¸ÛŒÙ… API Key Ø¨Ø±Ø§ÛŒ Anthropic"""
        self.anthropic_api_key = api_key
        print("âœ… Anthropic API Key ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯")
    
    def set_gemini_api_key(self, api_key: str):
        """ØªÙ†Ø¸ÛŒÙ… API Key Ø¨Ø±Ø§ÛŒ Google Gemini"""
        self.gemini_api_key = api_key
        print("âœ… Gemini API Key ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯")
    
    def _search_by_metaedges(self, matched_nodes: Dict[str, str], intent: Dict, target_metaedges: List[str], max_depth: int = 2) -> List[Tuple[str, int, float, str]]:
        """
        Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ metaedges Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡
        """
        results = []
        
        print(f"ğŸ” Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø§ metaedges: {target_metaedges}")
        
        for token, node_id in matched_nodes.items():
            node_name = self.G.nodes[node_id]['name']
            node_kind = self.G.nodes[node_id]['kind']
            print(f"  Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆØ¯: {node_name} ({node_kind})")
            
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ø± Ø§Ø³Ø§Ø³ metaedges
            for metaedge in target_metaedges:
                print(f"    Ø¨Ø±Ø±Ø³ÛŒ metaedge: {metaedge}")
                
                # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ø§ metaedge Ù…Ø´Ø®Øµ
                for neighbor in self.G.neighbors(node_id):
                    edge_data = self.G.get_edge_data(node_id, neighbor)
                    if edge_data and edge_data.get('metaedge') == metaedge:
                        neighbor_name = self.G.nodes[neighbor]['name']
                        neighbor_kind = self.G.nodes[neighbor]['kind']
                        
                        # Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ metaedge
                        score = self._calculate_metaedge_score(metaedge, 1)
                        explanation = f"{neighbor_name} ({neighbor_kind}) connected to {node_name} via {metaedge}"
                        
                        results.append((neighbor, 1, score, explanation))
                        print(f"      âœ… {neighbor_name} - {metaedge} (Ø§Ù…ØªÛŒØ§Ø²: {score})")
                
                # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ú©ÙˆØ³ (Ø§Ú¯Ø± metaedge Ù…Ø¹Ú©ÙˆØ³ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯)
                reverse_metaedges = self._get_reverse_metaedges(metaedge)
                for reverse_metaedge in reverse_metaedges:
                    print(f"    Ø¨Ø±Ø±Ø³ÛŒ metaedge Ù…Ø¹Ú©ÙˆØ³: {reverse_metaedge}")
                    for other_node, other_attrs in self.G.nodes(data=True):
                        if other_node != node_id:
                            for neighbor in self.G.neighbors(other_node):
                                if neighbor == node_id:
                                    edge_data = self.G.get_edge_data(other_node, neighbor)
                                    if edge_data and edge_data.get('metaedge') == reverse_metaedge:
                                        other_name = other_attrs['name']
                                        other_kind = other_attrs['kind']
                                        
                                        score = self._calculate_metaedge_score(reverse_metaedge, 1) * 0.8  # Ø§Ù…ØªÛŒØ§Ø² Ú©Ù…ØªØ± Ø¨Ø±Ø§ÛŒ Ù…Ø¹Ú©ÙˆØ³
                                        explanation = f"{other_name} ({other_kind}) connected to {node_name} via {reverse_metaedge}"
                                        
                                        results.append((other_node, 1, score, explanation))
                                        print(f"      âœ… {other_name} - {reverse_metaedge} Ù…Ø¹Ú©ÙˆØ³ (Ø§Ù…ØªÛŒØ§Ø²: {score})")
                
                # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ú©ÙˆØ³ (Ø§Ú¯Ø± metaedge Ù…Ø¹Ú©ÙˆØ³ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯)
                reverse_metaedges = self._get_reverse_metaedges(metaedge)
                for reverse_metaedge in reverse_metaedges:
                    print(f"    Ø¨Ø±Ø±Ø³ÛŒ metaedge Ù…Ø¹Ú©ÙˆØ³: {reverse_metaedge}")
                    for other_node, other_attrs in self.G.nodes(data=True):
                        if other_node != node_id:
                            for neighbor in self.G.neighbors(other_node):
                                if neighbor == node_id:
                                    edge_data = self.G.get_edge_data(other_node, neighbor)
                                    if edge_data and edge_data.get('metaedge') == reverse_metaedge:
                                        other_name = other_attrs['name']
                                        other_kind = other_attrs['kind']
                                        
                                        score = self._calculate_metaedge_score(reverse_metaedge, 1) * 0.8  # Ø§Ù…ØªÛŒØ§Ø² Ú©Ù…ØªØ± Ø¨Ø±Ø§ÛŒ Ù…Ø¹Ú©ÙˆØ³
                                        explanation = f"{other_name} ({other_kind}) connected to {node_name} via {reverse_metaedge}"
                                        
                                        results.append((other_node, 1, score, explanation))
                                        print(f"      âœ… {other_name} - {reverse_metaedge} Ù…Ø¹Ú©ÙˆØ³ (Ø§Ù…ØªÛŒØ§Ø²: {score})")
            
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¹Ù…ÛŒÙ‚ Ø¨Ø§ ÙÛŒÙ„ØªØ± metaedges
            if max_depth > 1:
                print(f"    Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¹Ù…ÛŒÙ‚ ØªØ§ Ø¹Ù…Ù‚ {max_depth}")
                for metaedge in target_metaedges:
                    dfs_results = self.dfs_search(node_id, max_depth, relation_filter=metaedge)
                    for found_node, depth in dfs_results:
                        if found_node != node_id:
                            found_name = self.G.nodes[found_node]['name']
                            found_kind = self.G.nodes[found_node]['kind']
                            
                            score = self._calculate_metaedge_score(metaedge, depth)
                            explanation = f"{found_name} ({found_kind}) related to {node_name} via {metaedge} (depth {depth})"
                            
                            results.append((found_node, depth, score, explanation))
                            print(f"      âœ… {found_name} - Ø¹Ù…Ù‚ {depth} Ø¨Ø§ {metaedge} (Ø§Ù…ØªÛŒØ§Ø²: {score:.2f})")
        
        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø± Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ
        unique_results = {}
        for node_id, depth, score, explanation in results:
            if node_id not in unique_results or score > unique_results[node_id][2]:
                unique_results[node_id] = (node_id, depth, score, explanation)
        
        final_results = sorted(unique_results.values(), key=lambda x: x[2], reverse=True)
        
        print(f"  ğŸ“Š Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ: {len(final_results)} Ù†ÙˆØ¯ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯")
        return final_results
    
    def _calculate_metaedge_score(self, metaedge: str, depth: int) -> float:
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ metaedge Ùˆ Ø¹Ù…Ù‚ - Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡
        """
        # Ø§Ù…ØªÛŒØ§Ø²Ø§Øª Ù¾Ø§ÛŒÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù‡Ù…ÛŒØª Ùˆ ÙØ±Ø§ÙˆØ§Ù†ÛŒ Ø¯Ø± Hetionet
        base_scores = {
            # Ø¨ÛŒØ§Ù† Ú˜Ù† Ø¯Ø± Ø¢Ù†Ø§ØªÙˆÙ…ÛŒ - Ø¨Ø³ÛŒØ§Ø± Ù…Ù‡Ù…
            'AeG': 6.0,  # Anatomy expresses Gene (526,407 edges)
            'GeA': 5.5,  # Gene expressed in Anatomy
            
            # ØªØ¹Ø§Ù…Ù„Ø§Øª Ú˜Ù†â€ŒÙ‡Ø§ - Ù…Ù‡Ù…
            'GiG': 5.0,  # Gene interacts with Gene (147,164 edges)
            'Gr>G': 4.5, # Gene regulates Gene (265,672 edges)
            'GcG': 4.0,  # Gene covaries with Gene (61,690 edges)
            
            # Ù…Ø´Ø§Ø±Ú©Øª Ø¯Ø± ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ - Ù…Ù‡Ù…
            'GpBP': 5.0, # Gene participates in Biological Process (559,504 edges)
            'GpPW': 4.5, # Gene participates in Pathway (84,372 edges)
            'GpMF': 4.0, # Gene participates in Molecular Function (97,222 edges)
            'GpCC': 4.0, # Gene participates in Cellular Component (73,566 edges)
            
            # ØªÙ†Ø¸ÛŒÙ… Ú˜Ù† ØªÙˆØ³Ø· Ø¢Ù†Ø§ØªÙˆÙ…ÛŒ
            'AuG': 4.5,  # Anatomy upregulates Gene (97,848 edges)
            'AdG': 4.5,  # Anatomy downregulates Gene (102,240 edges)
            'GuA': 4.0,  # Gene upregulates Anatomy
            'GdA': 4.0,  # Gene downregulates Anatomy
            
            # Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ú˜Ù†â€ŒÙ‡Ø§
            'DaG': 4.5,  # Disease associates with Gene (12,623 edges)
            'DuG': 4.0,  # Disease upregulates Gene (7,731 edges)
            'DdG': 4.0,  # Disease downregulates Gene (7,623 edges)
            'GaD': 4.0,  # Gene associates Disease
            'GuD': 3.5,  # Gene upregulates Disease
            'GdD': 3.5,  # Gene downregulates Disease
            
            # Ø¯Ø§Ø±ÙˆÙ‡Ø§ Ùˆ Ø¯Ø±Ù…Ø§Ù†
            'CtD': 4.5,  # Compound treats Disease (755 edges)
            'CpD': 4.0,  # Compound palliates Disease (390 edges)
            'DtC': 4.0,  # Disease treats Compound
            'DpC': 3.5,  # Disease palliates Compound
            
            # ØªÙ†Ø¸ÛŒÙ… Ú˜Ù† ØªÙˆØ³Ø· Ø¯Ø§Ø±Ùˆ
            'CuG': 4.0,  # Compound upregulates Gene (18,756 edges)
            'CdG': 4.0,  # Compound downregulates Gene (21,102 edges)
            'CbG': 4.5,  # Compound binds Gene (11,571 edges)
            'GuC': 3.5,  # Gene upregulates Compound
            'GdC': 3.5,  # Gene downregulates Compound
            'GbC': 4.0,  # Gene binds Compound
            
            # Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ø¢Ù†Ø§ØªÙˆÙ…ÛŒ
            'DlA': 4.0,  # Disease localizes to Anatomy (3,602 edges)
            'AlD': 3.5,  # Anatomy localizes Disease
            
            # Ø¹Ù„Ø§Ø¦Ù… Ùˆ Ø¹ÙˆØ§Ø±Ø¶
            'DpS': 4.0,  # Disease presents Symptom (3,357 edges)
            'SpD': 3.5,  # Symptom presents Disease
            'CcSE': 3.5, # Compound causes Side Effect (138,944 edges)
            'SEcC': 3.0, # Side Effect causes Compound
            
            # ØªØ´Ø§Ø¨Ù‡â€ŒÙ‡Ø§
            'DrD': 3.5,  # Disease resembles Disease (543 edges)
            'CrC': 3.5,  # Compound resembles Compound (6,486 edges)
            
            # Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø±ÙˆÛŒÛŒ
            'PCiC': 3.0, # Pharmacologic Class includes Compound (1,029 edges)
            'CiPC': 2.5  # Compound includes Pharmacologic Class
        }
        
        # Ú©Ø§Ù‡Ø´ ÙˆØ²Ù† Ø±ÙˆØ§Ø¨Ø· Ø´Ø¨Ø§Ù‡Øª Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù†ÙˆÛŒØ² Ø¯Ø± Ø³ÙˆØ§Ù„Ø§Øª Ù…Ú©Ø§Ù†ÛŒØ²Ù…ÛŒ
        base_score = base_scores.get(metaedge, 2.5)
        if metaedge in ['DrD', 'CrC']:
            base_score *= 0.6
        
        # Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¬Ø±ÛŒÙ…Ù‡ Ø¹Ù…Ù‚
        if depth == 1:
            depth_penalty = 1.0
        elif depth == 2:
            depth_penalty = 0.7
        elif depth == 3:
            depth_penalty = 0.5
        else:
            depth_penalty = 0.3
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨ÙˆÙ†ÙˆØ³ Ø¨Ø±Ø§ÛŒ metaedges Ù…Ù‡Ù…
        importance_bonus = 1.0
        if metaedge in ['AeG', 'GiG', 'GpBP', 'DaG', 'CtD']:
            importance_bonus = 1.2
        elif metaedge in ['Gr>G', 'GpPW', 'CbG']:
            importance_bonus = 1.1
        
        return base_score * depth_penalty * importance_bonus
    
    def _get_reverse_metaedges(self, metaedge: str) -> List[str]:
        """
        Ø¯Ø±ÛŒØ§ÙØª metaedges Ù…Ø¹Ú©ÙˆØ³
        """
        reverse_mapping = {
            'AeG': ['GeA'],  # Anatomy expresses Gene â†” Gene expressed in Anatomy
            'GeA': ['AeG'],
            'AuG': ['GuA'],  # Anatomy upregulates Gene â†” Gene upregulates Anatomy
            'GuA': ['AuG'],
            'AdG': ['GdA'],  # Anatomy downregulates Gene â†” Gene downregulates Anatomy
            'GdA': ['AdG'],
            'DaG': ['GaD'],  # Disease associates Gene â†” Gene associates Disease
            'GaD': ['DaG'],
            'DuG': ['GuD'],  # Disease upregulates Gene â†” Gene upregulates Disease
            'GuD': ['DuG'],
            'DdG': ['GdD'],  # Disease downregulates Gene â†” Gene downregulates Disease
            'GdD': ['DdG'],
            'CtD': ['DtC'],  # Compound treats Disease â†” Disease treats Compound
            'DtC': ['CtD'],
            'CuG': ['GuC'],  # Compound upregulates Gene â†” Gene upregulates Compound
            'GuC': ['CuG'],
            'CdG': ['GdC'],  # Compound downregulates Gene â†” Gene downregulates Compound
            'GdC': ['CdG'],
            'CbG': ['GbC'],  # Compound binds Gene â†” Gene binds Compound
            'GbC': ['CbG'],
            'DlA': ['AlD'],  # Disease localizes Anatomy â†” Anatomy localizes Disease
            'AlD': ['DlA'],
            'DpS': ['SpD'],  # Disease presents Symptom â†” Symptom presents Disease
            'SpD': ['DpS'],
            'CcSE': ['SEcC'], # Compound causes Side Effect â†” Side Effect causes Compound
            'SEcC': ['CcSE'],
            'GpBP': ['BPpG'], # Gene participates Biological Process â†” Biological Process participates Gene
            'BPpG': ['GpBP'],
            'GpMF': ['MFpG'], # Gene participates Molecular Function â†” Molecular Function participates Gene
            'MFpG': ['GpMF'],
            'GpCC': ['CCpG'], # Gene participates Cellular Component â†” Cellular Component participates Gene
            'CCpG': ['GpCC'],
            'GpPW': ['PWpG'], # Gene participates Pathway â†” Pathway participates Gene
            'PWpG': ['GpPW'],
            'PCiC': ['CiPC'], # Pharmacologic Class includes Compound â†” Compound includes Pharmacologic Class
            'CiPC': ['PCiC']
        }
        
        return reverse_mapping.get(metaedge, [])
    
    # ==================== KGSearch (Intent-Aware + Schema-Aware for Hetionet) ====================
    def kgsearch_traceable(self, query: str, top_k: int = 10) -> Tuple[List[Dict[str, Any]], str]:
        """
        Ø§Ø¬Ø±Ø§ÛŒ kgsearch Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Hetionet Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Intent/Schema.
        Ø®Ø±ÙˆØ¬ÛŒ: (hits, summary)

        Ù‡Ø± hit Ø´Ø§Ù…Ù„ ÛŒÚ© Ù…Ø³ÛŒØ± traceable Ø¨Ø§ Ù†ÙˆØ¯/ÛŒØ§Ù„â€ŒÙ‡Ø§ Ùˆ Ù…ØªØ§Ø¯ÛŒØªØ§ Ø§Ø³Øª.
        """
        if not self.G:
            return [], "Ú¯Ø±Ø§Ù Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª"

        intent_cfg = self._detect_intent_schema_map(query)
        allow = intent_cfg["allow"]
        deny = intent_cfg["deny"]
        end_type = intent_cfg["end_type"]
        hop_limit = intent_cfg["hop_limit"]
        constraints = intent_cfg.get("constraints", {})

        # 1) Canonicalization & Core Lock
        intent = self.analyze_question_intent(query)
        tokens = intent.get("keywords", [])
        matched = self.match_tokens_to_nodes(tokens)
        core_nodes = self._extract_core_nodes(query, matched, intent)
        if not core_nodes and matched:
            core_nodes = list(dict.fromkeys(matched.values()))[:3]

        # 2) Retrieval constrained by schema (allowlist/denylist + end-type)
        paths_with_meta = self._find_paths_allowlist(
            core_nodes=core_nodes,
            allow_metaedges=allow,
            deny_metaedges=deny,
            end_kind=end_type,
            hop_limit=hop_limit,
            max_results_per_hop=100,
            require_unique_nodes=True,
            extra_constraints=constraints,
            query=query,
        )

        # 3) Ranking
        # Ø§Ú¯Ø± intent Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù‡Ù…â€ŒÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ú˜Ù†â€ŒÙ‡Ø§Ø³ØªØŒ Ø®Ø±ÙˆØ¬ÛŒ Ø±Ø§ Ù…ÛŒÙ†ÛŒÙ…Ø§Ù„ Ùˆ Û±-Ù‡Ø§Ù¾ Ø±ÙˆÛŒ GcG Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø±
        if intent_cfg.get('intent') == 'G-G_covary':
            paths_with_meta = [p for p in paths_with_meta if len(p.get('path_nodes', [])) == 2 and all(m == 'GcG' for m in p.get('metaedges', []) if m)]
        ranked = self._rank_paths(paths_with_meta, query, intent_cfg)
        hits = []
        for rank, item in enumerate(ranked[:top_k], start=1):
            path_nodes = item["path_nodes"]
            path_edges = item["path_edges"]
            score = item["score"]
            hop_count = max(0, len(path_nodes) - 1)

            # Ø³Ø§Ø®Øª JSON Ù…Ø³ÛŒØ± Ù…Ø·Ø§Ø¨Ù‚ ÙØ±Ù…Øª Ø®ÙˆØ§Ø³ØªÙ‡â€ŒØ´Ø¯Ù‡
            json_path: List[Dict[str, Any]] = []
            for i, nid in enumerate(path_nodes):
                json_path.append({
                    "id": nid,
                    "label": self.G.nodes[nid].get("name", nid),
                    "type": self.G.nodes[nid].get("kind", "Unknown")
                })
                if i < len(path_nodes) - 1:
                    src, dst = nid, path_nodes[i+1]
                    ed = self.G.get_edge_data(src, dst) or {}
                    metaedge = ed.get("metaedge") or ed.get("relation") or "related"
                    # Ø³Ø§Ø®Øª Ø´Ù†Ø§Ø³Ù‡ ÛŒØ§Ù„ Ù¾Ø§ÛŒØ¯Ø§Ø±
                    edge_id = f"Edge::{metaedge}::{src}__{dst}"
                    evidence_count = ed.get("evidence_count") or ed.get("evidence") or None
                    source_count = ed.get("source_count") or (len(ed.get("sources", [])) if isinstance(ed.get("sources"), list) else None)
                    unbiased = ed.get("unbiased") if "unbiased" in ed else None
                    extra = {}
                    for k in ("cov_metric", "weight", "score"):
                        if k in ed:
                            extra[k] = ed[k]
                    json_path.append({
                        "edge_id": edge_id,
                        "edge_type": metaedge,
                        "unbiased": unbiased,
                        "evidence_count": evidence_count,
                        "source_count": source_count,
                        **extra
                    })

            notes = item.get("notes", "")
            hits.append({
                "rank": rank,
                "path": json_path,
                "end_type": end_type,
                "hop_count": hop_count,
                "score": round(score, 4),
                "notes": notes
            })

        # 4) Fallback Ø§Ú¯Ø± Ù†ØªÛŒØ¬Ù‡ ØªÙ‡ÛŒ Ø´Ø¯
        used_fallback = False
        if not hits:
            fb = self._fallback_from_intent(intent_cfg.get("intent"))
            if fb:
                used_fallback = True
                allow_fb = fb["allow"]
                end_type_fb = fb["end_type"] or end_type
                hop_limit_fb = fb["hop_limit"] or hop_limit
                paths_with_meta = self._find_paths_allowlist(
                    core_nodes=core_nodes,
                    allow_metaedges=allow_fb,
                    deny_metaedges=deny,
                    end_kind=end_type_fb,
                    hop_limit=hop_limit_fb,
                    max_results_per_hop=100,
                    require_unique_nodes=True,
                    extra_constraints=fb.get("constraints", {}),
                    query=query,
                )
                ranked = self._rank_paths(paths_with_meta, query, fb)
                for rank, item in enumerate(ranked[:top_k], start=1):
                    path_nodes = item["path_nodes"]
                    hop_count = max(0, len(path_nodes) - 1)
                    json_path: List[Dict[str, Any]] = []
                    for i, nid in enumerate(path_nodes):
                        json_path.append({
                            "id": nid,
                            "label": self.G.nodes[nid].get("name", nid),
                            "type": self.G.nodes[nid].get("kind", "Unknown")
                        })
                        if i < len(path_nodes) - 1:
                            src, dst = nid, path_nodes[i+1]
                            ed = self.G.get_edge_data(src, dst) or {}
                            metaedge = ed.get("metaedge") or ed.get("relation") or "related"
                            edge_id = f"Edge::{metaedge}::{src}__{dst}"
                            json_path.append({
                                "edge_id": edge_id,
                                "edge_type": metaedge,
                                "unbiased": ed.get("unbiased") if "unbiased" in ed else None,
                                "evidence_count": ed.get("evidence_count") or ed.get("evidence") or None,
                                "source_count": ed.get("source_count") or (len(ed.get("sources", [])) if isinstance(ed.get("sources"), list) else None),
                            })
                    hits.append({
                        "rank": rank,
                        "path": json_path,
                        "end_type": end_type_fb,
                        "hop_count": hop_count,
                        "score": round(item["score"], 4),
                        "notes": (item.get("notes", "") + " | fallback")[:200]
                    })

        # 5) Summary Ú©ÙˆØªØ§Ù‡ ÙØ§Ø±Ø³ÛŒ
        if hits:
            sum_lines = []
            sum_lines.append(f"Ù†ØªØ§ÛŒØ¬ Ø¨Ø± Ø§Ø³Ø§Ø³ Intent='{intent_cfg.get('intent')}', Ø¨Ø§ metaedgeÙ‡Ø§ÛŒ Ù…Ø¬Ø§Ø²: {', '.join(allow)}Ø› end-type='{end_type}' Ùˆ hopâ‰¤{hop_limit}.")
            if used_fallback:
                sum_lines.append("Ø§Ø² fallback Ø·Ø¨Ù‚ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ø› Ø§ÛŒÙ† Ø±ÙˆØ§Ø¨Ø· proxy Ù‡Ø³ØªÙ†Ø¯.")
            sum_lines.append(f"ØªØ¹Ø¯Ø§Ø¯ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø¨Ø±ØªØ±: {min(top_k, len(hits))}ØŒ Ø¨Ø§ ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡ Ùˆ Ø´ÙˆØ§Ù‡Ø¯ Ù‚ÙˆÛŒ.")
            summary = "\n".join(sum_lines)
        else:
            summary = "Ú†ÛŒØ²ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯: Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† IntentØŒ ÛŒØ§Ù„ Ù…Ø±ØªØ¨Ø· Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨ÙˆØ¯. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: fallback ÛŒØ§ Ø§ÙØ²Ø§ÛŒØ´ hop-limit Ø±Ø§ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒØ¯."

        return hits[:top_k], summary

    def _detect_intent_schema_map(self, query: str) -> Dict[str, Any]:
        q = (query or "").lower()
        # Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        cfg = {
            "intent": "general",
            "allow": [],
            "deny": ["DrD", "CrC"],
            "end_type": None,
            "hop_limit": 2,
            "constraints": {}
        }

        # ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¨Ø§Ù‡Øª ØªÙ†Ù‡Ø§ Ø¯Ø± ØµÙˆØ±Øª Ø°Ú©Ø±
        resembles = any(k in q for k in ["resembles", "similar", "similarity", "alike"])

        # I. Geneâ†’Gene
        if any(k in q for k in ["co-expression", "coexpression", "covary", "covaries", "Ù‡Ù…â€ŒÙˆØ§Ø±ÛŒØ§Ù†Ø³", "Ù‡Ù…â€ŒØ¨Ø±ÙˆØ²", "Ù‡Ù…â€ŒØªØºÛŒÛŒØ±"]):
            cfg.update({"intent": "G-G_covary", "allow": ["GcG"], "end_type": "Gene", "hop_limit": 1})
        elif any(k in q for k in ["interaction", "interacts", "ppi", "ØªØ¹Ø§Ù…Ù„"]):
            cfg.update({"intent": "G-G_interact", "allow": ["GiG"], "end_type": "Gene", "hop_limit": 1})
        elif any(k in q for k in ["regulates", "regulation", "ØªÙ†Ø¸ÛŒÙ…"]):
            cfg.update({"intent": "G-G_regulates", "allow": ["Gr>G"], "end_type": "Gene", "hop_limit": 1})

        # II. Diseaseâ†’Drug/Class
        elif any(k in q for k in ["treats", "treatment", "therapy", "therapeutic", "Ø¯Ø±Ù…Ø§Ù†", "Ù¾Ø§Ù„ÛŒØªÛŒÙˆ"]):
            allow = ["CtD", "CpD", "PCiC", "CbG"]
            if resembles:
                pass
            cfg.update({
                "intent": "Dâ†’(C|PC)",
                "allow": allow,
                "end_type": ("Compound|Pharmacologic Class"),
                "hop_limit": 3,
                "constraints": {"require_any_edge": ["CtD", "CpD"], "require_edge_to": "Disease"}
            })

        # III. Geneâ†’Drug/Class
        elif any(k in q for k in ["drug", "compound", "pharmacologic class", "mechanism", "target"]):
            cfg.update({
                "intent": "Gâ†’(C|PC)",
                "allow": ["GiG", "Gr>G", "CbG", "PCiC"],
                "end_type": ("Compound|Pharmacologic Class"),
                "hop_limit": 4
            })

        # IV. Geneâ†’Disease
        elif any(k in q for k in ["disease", "associated", "association", "Ø¨ÛŒÙ…Ø§Ø±ÛŒ"]):
            cfg.update({"intent": "Gâ†’D", "allow": ["DaG"], "end_type": "Disease", "hop_limit": 2})

        # V. Diseaseâ†’Symptom / Anatomy
        if any(k in q for k in ["symptom", "Ø¹Ù„Ø§Ø¦Ù…", "signs"]):
            cfg.update({"intent": "Dâ†’S", "allow": ["DpS"], "end_type": "Symptom", "hop_limit": 1})
        if any(k in q for k in ["anatomy", "tissue", "Ø¨Ø§ÙØª", "anatomical", "localized"]):
            cfg.update({"intent": "Dâ†’A", "allow": ["DlA"], "end_type": "Anatomy", "hop_limit": 1})

        # VI. Drugâ†’Target/Mechanism/Side-effect
        if any(k in q for k in ["side effect", "adverse", "Ø¹ÙˆØ§Ø±Ø¶"]):
            cfg.update({"intent": "Câ†’SE", "allow": ["CcSE"], "end_type": "Side Effect", "hop_limit": 1})
        elif any(k in q for k in ["mechanism", "target", "binds", "regulates"]):
            cfg.update({"intent": "Câ†’(G|BP|PW)", "allow": ["CbG", "PCiC", "GiG", "Gr>G", "GpPW", "GpBP"], "end_type": ("Gene|BP|PW"), "hop_limit": 2})

        # VII. Anatomyâ†’Gene
        if any(k in q for k in ["expressed in", "expression", "Ø¨ÛŒØ§Ù†"]):
            cfg.update({"intent": "Aâ†’G_expression", "allow": ["AeG"], "end_type": "Gene", "hop_limit": 1})
        if any(k in q for k in ["upregulates", "downregulates", "regulates"]):
            # Anatomy regulation of Gene
            cfg.update({"intent": "Aâ†’G_regulation", "allow": ["AuG", "AdG"], "end_type": "Gene", "hop_limit": 1})

        # VIII. Pathway/BP/MF membership
        if any(k in q for k in ["pathway", "biological process", "molecular function", "go:"]):
            cfg.update({"intent": "Gâ†”(PW|BP|MF)", "allow": ["GpPW", "GpBP", "GpMF"], "end_type": ("Gene|PW|BP|MF"), "hop_limit": 1})

        # Denylist for similarity unless explicitly requested
        if resembles:
            cfg["deny"] = [m for m in cfg["deny"] if m not in ("DrD", "CrC")]
        return cfg

    def _fallback_from_intent(self, intent: Optional[str]) -> Optional[Dict[str, Any]]:
        if not intent:
            return None
        # Ù‚ÙˆØ§Ø¹Ø¯ fallback
        if intent == "G-G_covary":
            return {"intent": "G-G_interact", "allow": ["GiG"], "end_type": "Gene", "hop_limit": 1}
        if intent == "Dâ†’(C|PC)":
            return {"intent": "Dâ†’(C|PC)_palliative", "allow": ["CpD", "PCiC"], "end_type": ("Compound|Pharmacologic Class"), "hop_limit": 3,
                    "constraints": {"require_any_edge": ["CtD", "CpD"], "require_edge_to": "Disease"}}
        if intent == "Câ†’(G|BP|PW)":
            return {"intent": "Câ†’PCâ†’C", "allow": ["PCiC"], "end_type": ("Gene|BP|PW|Compound|Pharmacologic Class"), "hop_limit": 3}
        if intent == "Gâ†’(C|PC)":
            return {"intent": "Gâ†’Gâ†’(C|PC)", "allow": ["GiG", "Gr>G", "CbG", "PCiC"], "end_type": ("Compound|Pharmacologic Class"), "hop_limit": 4}
        return None

    def _find_paths_allowlist(
        self,
        core_nodes: List[str],
        allow_metaedges: List[str],
        deny_metaedges: List[str],
        end_kind: Optional[str],
        hop_limit: int,
        max_results_per_hop: int,
        require_unique_nodes: bool,
        extra_constraints: Dict[str, Any],
        query: str,
    ) -> List[Dict[str, Any]]:
        """
        Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø³ÛŒØ±Ù‡Ø§ ÙÙ‚Ø· Ø¨Ø§ metaedgeÙ‡Ø§ÛŒ Ù…Ø¬Ø§Ø²ØŒ Ø¨Ø§ Ø§Ø¹Ù…Ø§Ù„ end-type Ùˆ Ù‚ÛŒÙˆØ¯.
        Ø®Ø±ÙˆØ¬ÛŒ: Ù„ÛŒØ³Øª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø´Ø§Ù…Ù„ path_nodes, path_edges Ùˆ Ù…ØªØ§Ø¯ÛŒØªØ§ Ø¨Ø±Ø§ÛŒ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ.
        """
        if not core_nodes:
            return []
        allow_set = set(allow_metaedges or [])
        deny_set = set(deny_metaedges or [])

        def valid_edge(u, v) -> Optional[str]:
            ed = self.G.get_edge_data(u, v) or {}
            meta = ed.get("metaedge") or ed.get("relation")
            if not meta:
                return None
            if meta in deny_set:
                return None
            if allow_set and meta not in allow_set:
                return None
            return meta

        results: List[Dict[str, Any]] = []
        seen_paths: set = set()

        for start in core_nodes:
            if not self.G.has_node(start):
                continue
            # DFS Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ hop_limit Ùˆ allowlist
            stack: List[Tuple[str, List[str]]] = [(start, [start])]
            per_hop_counts = [0] * (hop_limit + 1)
            while stack:
                node, path = stack.pop()
                depth = len(path) - 1
                if depth > hop_limit:
                    continue
                # Ø§Ù†ØªÙ‡Ø§ÛŒÛŒ Ù…Ø¹ØªØ¨Ø±ØŸ
                if depth >= 1:
                    if end_kind:
                        k = self.G.nodes[path[-1]].get("kind")
                        if k == end_kind or (isinstance(end_kind, str) and any(et.strip() == k for et in end_kind.split("|"))):
                            # Ù‚ÛŒÙˆØ¯ Ø®Ø§Øµ Intent (Ù…Ø«Ù„ ÙˆØ¬ÙˆØ¯ CtD/CpD Ø±ÙˆÛŒ Disease)
                            if self._path_satisfies_constraints(path, extra_constraints):
                                key = tuple(path)
                                if key not in seen_paths:
                                    seen_paths.add(key)
                                    results.append({
                                        "path_nodes": path.copy(),
                                        "path_edges": self._edges_for_path(path),
                                        "metaedges": [valid_edge(path[i], path[i+1]) for i in range(len(path)-1)]
                                    })
                if depth == hop_limit:
                    continue
                # Ú©Ù†ØªØ±Ù„ max_results_per_hop
                if per_hop_counts[depth] >= max_results_per_hop:
                    continue
                per_hop_counts[depth] += 1

                for nbr in self.G.neighbors(node):
                    if require_unique_nodes and nbr in path:
                        continue
                    meta = valid_edge(node, nbr)
                    if not meta:
                        continue
                    # enforce end-kind at final hop only
                    next_depth = depth + 1
                    if next_depth == hop_limit and end_kind:
                        k = self.G.nodes[nbr].get("kind")
                        if isinstance(end_kind, str):
                            end_ok = any(et.strip() == k for et in end_kind.split("|")) or (k == end_kind)
                        else:
                            end_ok = (k == end_kind)
                        if not end_ok:
                            continue
                    stack.append((nbr, path + [nbr]))

        return results

    def _edges_for_path(self, path: List[str]) -> List[Tuple[str, str, str]]:
        edges = []
        for i in range(len(path) - 1):
            u, v = path[i], path[i+1]
            ed = self.G.get_edge_data(u, v) or {}
            meta = ed.get("metaedge") or ed.get("relation") or "related"
            edges.append((u, v, meta))
        return edges

    def _path_satisfies_constraints(self, path: List[str], constraints: Dict[str, Any]) -> bool:
        if not constraints:
            return True
        # Ù…Ø«Ø§Ù„: require_any_edge=[CtD,CpD] Ú©Ù‡ Ø¨Ù‡ Disease Ù…ØªØµÙ„ Ø¨Ø§Ø´Ø¯
        req_any = constraints.get("require_any_edge") or []
        req_to = constraints.get("require_edge_to")  # Ù†ÙˆØ¹ Ù†ÙˆØ¯ÛŒ Ú©Ù‡ ÛŒØ§Ù„ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ Ø¢Ù† ÙˆØµÙ„ Ø´ÙˆØ¯
        if req_any:
            ok = False
            for i in range(len(path) - 1):
                u, v = path[i], path[i+1]
                ed = self.G.get_edge_data(u, v) or {}
                meta = ed.get("metaedge") or ed.get("relation")
                if meta in req_any:
                    if not req_to:
                        ok = True
                        break
                    # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆØ¹ Ù…Ù‚ØµØ¯/Ù…Ø¨Ø¯Ø£
                    if self.G.nodes[v].get("kind") == req_to or self.G.nodes[u].get("kind") == req_to:
                        ok = True
                        break
            if not ok:
                return False
        return True

    def _rank_paths(self, paths: List[Dict[str, Any]], query: str, intent_cfg: Dict[str, Any]) -> List[Dict[str, Any]]:
        # ÙˆØ²Ù†â€ŒÙ‡Ø§
        w_match = 0.35
        w_edge = 0.25
        w_schema = 0.20
        w_hop = 0.10
        w_hub = 0.05
        w_div = 0.05

        ql = (query or "").lower()
        allow = set(intent_cfg.get("allow", []))
        end_type = intent_cfg.get("end_type")

        def match_score(metaedges: List[Optional[str]]) -> float:
            # ØªØ·Ø¨ÛŒÙ‚ Ø³Ø§Ø¯Ù‡ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ Ø¨Ø§ Ø§Ù†ÙˆØ§Ø¹ ÛŒØ§Ù„
            s = 0.0
            if any(m == "GcG" for m in metaedges) and any(k in ql for k in ["covary", "co-expression", "coexpression", "Ù‡Ù…â€ŒÙˆØ§Ø±ÛŒØ§Ù†Ø³", "Ù‡Ù…â€ŒØ¨Ø±ÙˆØ²"]):
                s += 1.0
            if any(m == "GiG" for m in metaedges) and any(k in ql for k in ["interaction", "interacts", "ppi", "ØªØ¹Ø§Ù…Ù„"]):
                s += 1.0
            if any(m == "Gr>G" for m in metaedges) and any(k in ql for k in ["regulates", "regulation", "ØªÙ†Ø¸ÛŒÙ…"]):
                s += 1.0
            if any(m == "CtD" for m in metaedges) and any(k in ql for k in ["treats", "Ø¯Ø±Ù…Ø§Ù†"]):
                s += 1.0
            if any(m == "CbG" for m in metaedges) and any(k in ql for k in ["binds", "target", "mechanism"]):
                s += 1.0
            return min(s, 1.0)

        def edge_strength_score(path_edges: List[Tuple[str, str, str]]) -> float:
            # Ø´ÙˆØ§Ù‡Ø¯/Ø¨ÛŒâ€ŒØ·Ø±ÙÛŒ Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯ØŒ Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±Øª Ø§Ø² Ù†ÙˆØ¹ ÛŒØ§Ù„ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ú¯ÛŒØ±
            total = 0.0
            for u, v, meta in path_edges:
                ed = self.G.get_edge_data(u, v) or {}
                evc = ed.get("evidence_count") or ed.get("evidence") or 0
                unbiased = 1.0 if ed.get("unbiased") else 0.0
                base = 1.0
                if meta == "CtD":
                    base = 1.2
                elif meta == "CpD":
                    base = 1.0
                elif meta == "GcG":
                    # Ø§Ú¯Ø± Ù…ØªØ±ÛŒÚ© Ú©ÙˆÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÙˆØ¯ (Ù…Ø«Ù„ cov_metric/weight)ØŒ Ø¯Ø± Ø§Ù…ØªÛŒØ§Ø² Ø§Ø«Ø± Ø¨Ø¯Ù‡
                    cov = ed.get("cov_metric") or ed.get("weight") or 0
                    try:
                        cov = float(cov)
                    except Exception:
                        cov = 0
                    base = 1.0 + 0.5 * max(0.0, min(1.0, cov))
                total += base + 0.05 * float(evc) + 0.1 * unbiased
            return total / max(1, len(path_edges))

        def schema_fit_score(metaedges: List[Optional[str]]) -> float:
            if not metaedges:
                return 0.0
            ok = sum(1 for m in metaedges if m in allow)
            return ok / len(metaedges)

        def hop_penalty(num_hops: int) -> float:
            # Ø¨ÛŒØ´ÛŒÙ†Ù‡ 1.0 Ø¨Ø±Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ±ÛŒÙ†â€ŒÙ‡Ø§
            if num_hops <= 1:
                return 1.0
            if num_hops == 2:
                return 0.8
            if num_hops == 3:
                return 0.6
            return 0.4

        def hub_penalty(path_nodes: List[str]) -> float:
            # Ø¬Ø±ÛŒÙ…Ù‡ Ø¨Ø±Ø§ÛŒ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø¯Ø±Ø¬Ù‡ Ø¨Ø§Ù„Ø§
            import math
            gene_nodes = [n for n in path_nodes if self.G.nodes[n].get("kind") == "Gene"]
            if not gene_nodes:
                return 1.0
            vals = []
            for n in gene_nodes:
                d = self.G.degree(n)
                vals.append(1.0 / (1.0 + math.log(1 + d)))
            return sum(vals) / len(vals)

        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ØªÙ†ÙˆØ¹ Ø±ÙˆÛŒ end-type
        seen_ends: set = set()
        ranked = []
        for item in paths:
            nodes = item["path_nodes"]
            edges = item["path_edges"]
            metas = item.get("metaedges", [])
            num_hops = max(0, len(nodes) - 1)
            ms = match_score(metas)
            es = edge_strength_score(edges)
            ss = schema_fit_score(metas)
            hp = hop_penalty(num_hops)
            hb = hub_penalty(nodes)
            base = w_match * ms + w_edge * es + w_schema * ss + w_hop * hp + w_hub * hb

            end_id = nodes[-1] if nodes else None
            end_kind_ok = (self.G.nodes[end_id].get("kind") if end_id and self.G.has_node(end_id) else None)
            div_bonus = 0.0
            if end_id:
                key = (end_kind_ok, end_id)
                if key not in seen_ends:
                    div_bonus = w_div * 1.0
                    seen_ends.add(key)
            score = base + div_bonus

            ranked.append({**item, "score": float(score), "notes": f"{num_hops} hops; schema-fit={ss:.2f}"})

        ranked.sort(key=lambda x: x["score"], reverse=True)
        return ranked
    
    def multi_hop_search(self, query: str, max_depth: int = 3) -> List[Tuple[str, int, float, str, List[str]]]:
        """
        Ø¬Ø³ØªØ¬ÙˆÛŒ Ú†Ù†Ø¯Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡
        Returns: (node_id, depth, score, explanation, path)
        """
        print(f"ğŸ”„ Ø¬Ø³ØªØ¬ÙˆÛŒ Ú†Ù†Ø¯Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ: {query}")
        
        # ØªØ­Ù„ÛŒÙ„ Ø³ÙˆØ§Ù„
        intent = self.analyze_question_intent(query)
        print(f"  ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹: {intent['question_type']}")
        print(f"  Metaedges: {intent['metaedges']}")
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
        keywords = intent['keywords']
        matched_nodes = self.match_tokens_to_nodes(keywords)
        
        if not matched_nodes:
            print("  âŒ Ù‡ÛŒÚ† Ù†ÙˆØ¯ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ù†Ú©Ø±Ø¯")
            return []
        
        results = []
        
        # Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„ØŒ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ú†Ù†Ø¯Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ Ø±Ø§ ØªØ¹Ø±ÛŒÙ Ú©Ù†
        multi_hop_patterns = {
            'anatomy_expression': [
                # Anatomy â†’ AeG â†’ Gene
                ['AeG'],
                # Anatomy â†’ AuG â†’ Gene  
                ['AuG'],
                # Anatomy â†’ AdG â†’ Gene
                ['AdG']
            ],
            'compound_gene_regulation': [
                # Compound â†’ CuG â†’ Gene
                ['CuG'],
                # Compound â†’ CdG â†’ Gene
                ['CdG'],
                # Compound â†’ CbG â†’ Gene
                ['CbG']
            ],
            'disease_gene_regulation': [
                # Disease â†’ DuG â†’ Gene
                ['DuG'],
                # Disease â†’ DdG â†’ Gene
                ['DdG'],
                # Disease â†’ DaG â†’ Gene
                ['DaG']
            ],
            'complex_expression': [
                # Anatomy â†’ AeG â†’ Gene â†’ CuG â†’ Compound
                ['AeG', 'CuG'],
                # Anatomy â†’ AeG â†’ Gene â†’ CdG â†’ Compound
                ['AeG', 'CdG'],
                # Gene â†’ GeA â†’ Anatomy â†’ Compound (Ù…Ø¹Ú©ÙˆØ³)
                ['GeA', 'GuC'],
                # Gene â†’ GeA â†’ Anatomy â†’ Compound (Ù…Ø¹Ú©ÙˆØ³)
                ['GeA', 'GdC'],
                # Compound â†’ CdG â†’ Gene â†’ GeA â†’ Anatomy (Ù…Ø¹Ú©ÙˆØ³)
                ['CdG', 'GeA'],
                # Compound â†’ CuG â†’ Gene â†’ GeA â†’ Anatomy (Ù…Ø¹Ú©ÙˆØ³)
                ['CuG', 'GeA']
            ],
            'complex_disease': [
                # Disease â†’ DaG â†’ Gene â†’ GiG â†’ Gene
                ['DaG', 'GiG'],
                # Disease â†’ DuG â†’ Gene â†’ GpBP â†’ Biological Process
                ['DuG', 'GpBP'],
                # Disease â†’ DlA â†’ Anatomy â†’ AeG â†’ Gene
                ['DlA', 'AeG'],
                # Gene â†’ GaD â†’ Disease â†’ GpBP â†’ Biological Process
                ['GaD', 'GpBP']
            ],
            'complex_treatment': [
                # Compound â†’ CtD â†’ Disease â†’ DaG â†’ Gene
                ['CtD', 'DaG'],
                # Compound â†’ CuG â†’ Gene â†’ GaD â†’ Disease
                ['CuG', 'GaD'],
                # Compound â†’ CdG â†’ Gene â†’ GaD â†’ Disease
                ['CdG', 'GaD'],
                # Disease â†’ DtC â†’ Compound â†’ CuG â†’ Gene
                ['DtC', 'CuG'],
                # Gene â†’ GuC â†’ Compound â†’ CtD â†’ Disease
                ['GuC', 'CtD']
            ],
            'complex_function': [
                # Gene â†’ GpBP â†’ Biological Process â†’ BPpG â†’ Gene
                ['GpBP', 'BPpG'],
                # Gene â†’ GpPW â†’ Pathway â†’ PWpG â†’ Gene
                ['GpPW', 'PWpG'],
                # Gene â†’ GiG â†’ Gene â†’ GpBP â†’ Biological Process
                ['GiG', 'GpBP'],
                # Gene â†’ Gr>G â†’ Gene â†’ GpMF â†’ Molecular Function
                ['Gr>G', 'GpMF']
            ]
        }
        
        # ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡
        complex_type = self._detect_complex_question_type(intent)
        print(f"  Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡: {complex_type}")
        
        if complex_type in multi_hop_patterns:
            patterns = multi_hop_patterns[complex_type]
            
            for pattern in patterns:
                print(f"  Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù„Ú¯Ùˆ: {' â†’ '.join(pattern)}")
                pattern_results = self._search_multi_hop_pattern(matched_nodes, pattern, max_depth)
                results.extend(pattern_results)
        
        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø± Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ
        unique_results = {}
        for node_id, depth, score, explanation, path in results:
            if node_id not in unique_results or score > unique_results[node_id][2]:
                unique_results[node_id] = (node_id, depth, score, explanation, path)
        
        final_results = sorted(unique_results.values(), key=lambda x: x[2], reverse=True)
        
        print(f"  âœ… {len(final_results)} Ù†ØªÛŒØ¬Ù‡ Ú†Ù†Ø¯Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ø´Ø¯")
        return final_results
    
    def _detect_complex_question_type(self, intent: Dict) -> str:
        """ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡"""
        query_lower = intent['query_lower']
        
        # Ø³ÙˆØ§Ù„Ø§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú†Ù†Ø¯ Ù…Ø±Ø­Ù„Ù‡ Ø¯Ø§Ø±Ù†Ø¯
        if any(word in query_lower for word in ['upregulate', 'downregulate', 'regulate']) and \
           any(word in query_lower for word in ['expressed', 'expression']):
            return 'complex_expression'
        
        if any(word in query_lower for word in ['interact', 'interaction']) and \
           any(word in query_lower for word in ['disease', 'associated']):
            return 'complex_disease'
        
        if any(word in query_lower for word in ['treat', 'treatment', 'therapy']) and \
           any(word in query_lower for word in ['compound', 'drug', 'medicine']):
            return 'complex_treatment'
        
        if any(word in query_lower for word in ['function', 'process', 'pathway']) and \
           any(word in query_lower for word in ['gene', 'protein']):
            return 'complex_function'
        
        # ØªØ´Ø®ÛŒØµ Ø¨Ø± Ø§Ø³Ø§Ø³ metaedges Ù…ÙˆØ¬ÙˆØ¯
        metaedges = intent.get('metaedges', [])
        if 'AeG' in metaedges and ('CuG' in metaedges or 'CdG' in metaedges):
            return 'complex_expression'
        if 'DaG' in metaedges and ('GiG' in metaedges or 'GpBP' in metaedges):
            return 'complex_disease'
        if 'CtD' in metaedges and ('DaG' in metaedges or 'CuG' in metaedges):
            return 'complex_treatment'
        if 'GpBP' in metaedges or 'GpPW' in metaedges:
            return 'complex_function'
        
        # Ø³ÙˆØ§Ù„Ø§Øª Ø³Ø§Ø¯Ù‡â€ŒØªØ±
        if intent['question_type'] == 'anatomy_expression':
            return 'anatomy_expression'
        elif intent['question_type'] == 'compound_gene_regulation':
            return 'compound_gene_regulation'
        elif intent['question_type'] == 'disease_gene_regulation':
            return 'disease_gene_regulation'
        
        return 'general'
    
    def _search_multi_hop_pattern(self, matched_nodes: Dict[str, str], pattern: List[str], max_depth: int) -> List[Tuple[str, int, float, str, List[str]]]:
        """Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù„Ú¯ÙˆÛŒ Ú†Ù†Ø¯Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ"""
        results = []
        
        for token, start_node in matched_nodes.items():
            print(f"    Ø´Ø±ÙˆØ¹ Ø§Ø² Ù†ÙˆØ¯: {self.G.nodes[start_node]['name']}")
            
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ú†Ù†Ø¯Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ
            paths = self._find_paths_with_pattern(start_node, pattern, max_depth)
            
            for path, path_metaedges in paths:
                if len(path) > 1:  # Ø­Ø¯Ø§Ù‚Ù„ 2 Ù†ÙˆØ¯
                    target_node = path[-1]
                    depth = len(path) - 1
                    
                    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù„Ú¯Ùˆ
                    score = self._calculate_pattern_score(pattern, path_metaedges, depth)
                    
                    # Ø§ÛŒØ¬Ø§Ø¯ ØªÙˆØ¶ÛŒØ­
                    path_names = [self.G.nodes[node]['name'] for node in path]
                    explanation = f"Ù…Ø³ÛŒØ±: {' â†’ '.join(path_names)} (Ø§Ù„Ú¯Ùˆ: {' â†’ '.join(pattern)})"
                    
                    results.append((target_node, depth, score, explanation, path))
        
        return results
    
    def _find_paths_with_pattern(self, start_node: str, pattern: List[str], max_depth: int) -> List[Tuple[List[str], List[str]]]:
        """ÛŒØ§ÙØªÙ† Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ Ø§Ù„Ú¯ÙˆÛŒ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ Ù…Ø·Ø§Ø¨Ù‚Øª Ø¯Ø§Ø±Ù†Ø¯"""
        paths = []
        
        def dfs_with_pattern(node: str, current_path: List[str], current_metaedges: List[str], depth: int):
            if depth >= max_depth:
                return
            
            current_path.append(node)
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù…Ø³ÛŒØ± ÙØ¹Ù„ÛŒ Ø¨Ø§ Ø§Ù„Ú¯Ùˆ Ù…Ø·Ø§Ø¨Ù‚Øª Ø¯Ø§Ø±Ø¯
            if len(current_metaedges) == len(pattern):
                paths.append((current_path.copy(), current_metaedges.copy()))
            
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§
            for neighbor in self.G.neighbors(node):
                if neighbor not in current_path:  # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø­Ù„Ù‚Ù‡
                    edge_data = self.G.get_edge_data(node, neighbor)
                    if edge_data and edge_data.get('relation'):
                        metaedge = edge_data.get('relation')
                        
                        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø§ÛŒÙ† metaedge Ø¯Ø± Ø§Ù„Ú¯Ùˆ Ø§Ø³Øª
                        if len(current_metaedges) < len(pattern) and metaedge == pattern[len(current_metaedges)]:
                            new_metaedges = current_metaedges + [metaedge]
                            dfs_with_pattern(neighbor, current_path, new_metaedges, depth + 1)
                        elif metaedge in pattern:  # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¢Ø²Ø§Ø¯ØªØ±
                            new_metaedges = current_metaedges + [metaedge]
                            dfs_with_pattern(neighbor, current_path, new_metaedges, depth + 1)
            
            current_path.pop()
        
        # Ø´Ø±ÙˆØ¹ Ø§Ø² Ù†ÙˆØ¯ Ø§ÙˆÙ„
        dfs_with_pattern(start_node, [], [], 0)
        
        # Ø§Ú¯Ø± Ù…Ø³ÛŒØ±ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ø³Ø¹ÛŒ Ú©Ù† Ø§Ø² Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒ
        if not paths:
            print(f"    âš ï¸ Ù‡ÛŒÚ† Ù…Ø³ÛŒØ±ÛŒ Ø§Ø² {start_node} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ ØªÙ„Ø§Ø´ Ø§Ø² Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±...")
            
            # Ø¨Ø±Ø§ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú†Ù†Ø¯Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒØŒ Ø³Ø¹ÛŒ Ú©Ù† Ø§Ø² Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ù…ÛŒØ§Ù†ÛŒ Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒ
            if len(pattern) > 1:
                # Ø¨Ø±Ø§ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ AeG â†’ CuG/CdGØŒ Ø§Ø² Ù†ÙˆØ¯Ù‡Ø§ÛŒ Compound Ø´Ø±ÙˆØ¹ Ú©Ù†
                if 'CuG' in pattern or 'CdG' in pattern:
                    compound_nodes = [nid for nid, attrs in self.G.nodes(data=True) 
                                    if attrs.get('kind') == 'Compound' or attrs.get('metanode') == 'Compound']
                    
                    for compound_node in compound_nodes[:3]:  # 3 Ù†ÙˆØ¯ Ø§ÙˆÙ„
                        if compound_node != start_node:
                            print(f"    ØªÙ„Ø§Ø´ Ø§Ø² Ù†ÙˆØ¯: {self.G.nodes[compound_node]['name']}")
                            dfs_with_pattern(compound_node, [], [], 0)
                
                # Ø§Ø² Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ú˜Ù† Ø´Ø±ÙˆØ¹ Ú©Ù† (Ø¨Ø±Ø§ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±)
                else:
                    gene_nodes = [nid for nid, attrs in self.G.nodes(data=True) 
                                 if attrs.get('kind') == 'Gene' or attrs.get('metanode') == 'Gene']
                    
                    for gene_node in gene_nodes[:5]:  # 5 Ù†ÙˆØ¯ Ø§ÙˆÙ„
                        if gene_node != start_node:
                            print(f"    ØªÙ„Ø§Ø´ Ø§Ø² Ù†ÙˆØ¯: {self.G.nodes[gene_node]['name']}")
                            dfs_with_pattern(gene_node, [], [], 0)
        
        return paths
    
    def _calculate_pattern_score(self, pattern: List[str], path_metaedges: List[str], depth: int) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ú¯Ùˆ"""
        base_score = 5.0
        
        # Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ ØªØ·Ø§Ø¨Ù‚ Ú©Ø§Ù…Ù„ Ø§Ù„Ú¯Ùˆ
        if path_metaedges == pattern:
            base_score += 2.0
        elif all(me in path_metaedges for me in pattern):
            base_score += 1.0
        
        # Ú©Ø§Ù‡Ø´ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¹Ù…Ù‚
        depth_penalty = 1.0 / (depth + 1)
        
        # Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ Ø·ÙˆÙ„ Ù…Ø³ÛŒØ±
        length_bonus = len(path_metaedges) * 0.5
        
        return (base_score + length_bonus) * depth_penalty

    # ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø³Ø§Ø¯Ù‡ Ùˆ Ø¹Ù…ÙˆÙ…ÛŒ
    def _generate_general_knowledge_answer(self, query: str) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¹Ù…ÙˆÙ…ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ù†Ø´ Ù…Ø¯Ù„"""
        query_lower = query.lower()
        
        if "cancer" in query_lower and "tissue" in query_lower:
            return """Ø³Ø±Ø·Ø§Ù† Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ø± Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø¯Ù† ØªØ£Ø«ÛŒØ± Ø¨Ú¯Ø°Ø§Ø±Ø¯:

**Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ:**
â€¢ **ØªÙ‡Ø§Ø¬Ù… Ù…Ø³ØªÙ‚ÛŒÙ…:** Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ø³Ø±Ø·Ø§Ù†ÛŒ Ø¨Ù‡ Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø§ÙˆØ± Ù†ÙÙˆØ° Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
â€¢ **Ù…ØªØ§Ø³ØªØ§Ø²:** Ú¯Ø³ØªØ±Ø´ Ø³Ø±Ø·Ø§Ù† Ø¨Ù‡ Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ÛŒ Ø¯ÙˆØ±ØªØ± Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø®ÙˆÙ† ÛŒØ§ Ù„Ù†Ù
â€¢ **ØªØºÛŒÛŒØ±Ø§Øª Ù…ØªØ§Ø¨ÙˆÙ„ÛŒÚ©:** Ø§ÙØ²Ø§ÛŒØ´ Ù…ØµØ±Ù Ø§Ù†Ø±Ú˜ÛŒ Ùˆ ØªØºÛŒÛŒØ± Ø¯Ø± Ù…ØªØ§Ø¨ÙˆÙ„ÛŒØ³Ù… Ø¨Ø§ÙØª
â€¢ **Ø§Ù„ØªÙ‡Ø§Ø¨:** Ù¾Ø§Ø³Ø® Ø§ÛŒÙ…Ù†ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ Ø¨Ø§ÙØª Ø¢Ø³ÛŒØ¨ Ø¨Ø±Ø³Ø§Ù†Ø¯
â€¢ **ÙØ´Ø§Ø± Ù…Ú©Ø§Ù†ÛŒÚ©ÛŒ:** ØªÙˆÙ…ÙˆØ±Ù‡Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¨Ø± Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø§ÙˆØ± ÙØ´Ø§Ø± ÙˆØ§Ø±Ø¯ Ú©Ù†Ù†Ø¯

**Ø§Ø«Ø±Ø§Øª Ø¨Ø± Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù:**
â€¢ **Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù…:** ØªØºÛŒÛŒØ± Ø¯Ø± Ø³Ø§Ø®ØªØ§Ø± Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯
â€¢ **Ø§Ø³ØªØ®ÙˆØ§Ù†:** Ø¶Ø¹ÛŒÙ Ø´Ø¯Ù† Ùˆ Ø´Ú©Ø³ØªÚ¯ÛŒ
â€¢ **Ø¹Ø±ÙˆÙ‚ Ø®ÙˆÙ†ÛŒ:** Ø±Ø´Ø¯ Ø¹Ø±ÙˆÙ‚ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ ØªØºØ°ÛŒÙ‡ ØªÙˆÙ…ÙˆØ±
â€¢ **Ø³ÛŒØ³ØªÙ… Ø§ÛŒÙ…Ù†ÛŒ:** ØªØºÛŒÛŒØ± Ø¯Ø± Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ…Ù†ÛŒ

**Ø¹Ù„Ø§Ø¦Ù… Ø¨Ø§Ù„ÛŒÙ†ÛŒ:**
â€¢ Ø¯Ø±Ø¯ØŒ ØªÙˆØ±Ù…ØŒ ØªØºÛŒÛŒØ± Ø¯Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¹Ø¶Ùˆ
â€¢ Ú©Ø§Ù‡Ø´ ÙˆØ²Ù†ØŒ Ø®Ø³ØªÚ¯ÛŒØŒ Ø¶Ø¹Ù Ø¹Ù…ÙˆÙ…ÛŒ"""

        elif "gene" in query_lower:
            return """Ú˜Ù†â€ŒÙ‡Ø§ ÙˆØ§Ø­Ø¯Ù‡Ø§ÛŒ ÙˆØ±Ø§Ø«ØªÛŒ Ù‡Ø³ØªÙ†Ø¯ Ú©Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú˜Ù†ØªÛŒÚ©ÛŒ Ø±Ø§ Ø­Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯:

**Ù†Ù‚Ø´â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ:**
â€¢ **Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ Ù¾Ø±ÙˆØªØ¦ÛŒÙ†:** ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±ÙˆØªØ¦ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø³Ù„ÙˆÙ„
â€¢ **ØªÙ†Ø¸ÛŒÙ… ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§:** Ú©Ù†ØªØ±Ù„ Ù…ØªØ§Ø¨ÙˆÙ„ÛŒØ³Ù… Ùˆ Ø±Ø´Ø¯ Ø³Ù„ÙˆÙ„ÛŒ
â€¢ **Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ù…Ø­ÛŒØ·:** ØªÙ†Ø¸ÛŒÙ… Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø³Ù„ÙˆÙ„ÛŒ Ø¨Ù‡ ØªØºÛŒÛŒØ±Ø§Øª Ù…Ø­ÛŒØ·ÛŒ

**Ø§Ù†ÙˆØ§Ø¹ Ú˜Ù†â€ŒÙ‡Ø§:**
â€¢ **Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒ:** ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±ÙˆØªØ¦ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒ
â€¢ **Ú˜Ù†â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…ÛŒ:** Ú©Ù†ØªØ±Ù„ Ø¨ÛŒØ§Ù† Ø³Ø§ÛŒØ± Ú˜Ù†â€ŒÙ‡Ø§
â€¢ **Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ø¢Ù†Ø²ÛŒÙ…ÛŒ:** ØªÙˆÙ„ÛŒØ¯ Ø¢Ù†Ø²ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù…ØªØ§Ø¨ÙˆÙ„ÛŒÚ©"""

        else:
            return """Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³ÙˆØ§Ù„ Ø´Ù…Ø§ØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø²ÛŒØ³Øªâ€ŒÙ¾Ø²Ø´Ú©ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯. Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø® Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ØŒ Ù„Ø·ÙØ§Ù‹ Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ Ø´Ú©Ù„ Ù…Ø´Ø®Øµâ€ŒØªØ±ÛŒ Ù…Ø·Ø±Ø­ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."""

    def _generate_cancer_related_answer(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø³Ø±Ø·Ø§Ù†"""
        query = retrieval_result.query
        context = retrieval_result.context_text
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø· Ø§Ø² context
        cancer_info = self._extract_cancer_info_from_context(context)
        
        return f"""ğŸ¥ **ØªØ­Ù„ÛŒÙ„ Ø³Ø±Ø·Ø§Ù† Ùˆ Ø§Ø«Ø±Ø§Øª Ø¢Ù†**

**Ø³ÙˆØ§Ù„:** {query}

**Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÛŒØ§ÙØª Ø´Ø¯Ù‡:**
{cancer_info}

**ØªØ­Ù„ÛŒÙ„ Ú©Ù„ÛŒ:**
Ø³Ø±Ø·Ø§Ù† Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ø± Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ ØªØ£Ø«ÛŒØ± Ø¨Ú¯Ø°Ø§Ø±Ø¯:

â€¢ **ØªØºÛŒÛŒØ±Ø§Øª Ú˜Ù†ØªÛŒÚ©ÛŒ:** Ø¬Ù‡Ø´â€ŒÙ‡Ø§ÛŒ Ú˜Ù†ØªÛŒÚ©ÛŒ Ú©Ù‡ Ù…Ù†Ø¬Ø± Ø¨Ù‡ Ø±Ø´Ø¯ ØºÛŒØ±Ø·Ø¨ÛŒØ¹ÛŒ Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯
â€¢ **ØªØºÛŒÛŒØ±Ø§Øª Ù…ØªØ§Ø¨ÙˆÙ„ÛŒÚ©:** Ø§ÙØ²Ø§ÛŒØ´ Ù…ØµØ±Ù Ø§Ù†Ø±Ú˜ÛŒ Ùˆ ØªØºÛŒÛŒØ± Ø¯Ø± Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…ØªØ§Ø¨ÙˆÙ„ÛŒÚ©
â€¢ **Ø§Ø«Ø±Ø§Øª Ø¨Ø± Ø¨Ø§ÙØª:** ØªØºÛŒÛŒØ± Ø¯Ø± Ø³Ø§Ø®ØªØ§Ø± Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ú¯ÛŒØ±
â€¢ **Ù¾Ø§Ø³Ø® Ø§ÛŒÙ…Ù†ÛŒ:** ØªØºÛŒÛŒØ± Ø¯Ø± Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ… Ø§ÛŒÙ…Ù†ÛŒ

ğŸ’¡ **Ù†Ú©ØªÙ‡:** Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø³Øª."""

    def _generate_gene_related_answer(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ú˜Ù†â€ŒÙ‡Ø§"""
        query = retrieval_result.query
        context = retrieval_result.context_text
        
        gene_info = self._extract_gene_info_from_context(context)
        
        return f"""ğŸ§¬ **ØªØ­Ù„ÛŒÙ„ Ú˜Ù†â€ŒÙ‡Ø§ Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¢Ù†Ù‡Ø§**

**Ø³ÙˆØ§Ù„:** {query}

**Ú˜Ù†â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡:**
{gene_info}

**Ù†Ù‚Ø´â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒÙˆÙ„ÙˆÚ˜ÛŒÚ©ÛŒ:**
â€¢ **ØªÙ†Ø¸ÛŒÙ… Ø¨ÛŒØ§Ù† Ú˜Ù†:** Ú©Ù†ØªØ±Ù„ ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø³Ù„ÙˆÙ„ÛŒ
â€¢ **Ù…ØªØ§Ø¨ÙˆÙ„ÛŒØ³Ù…:** Ø´Ø±Ú©Øª Ø¯Ø± Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…ØªØ§Ø¨ÙˆÙ„ÛŒÚ©
â€¢ **Ø³ÛŒÚ¯Ù†Ø§Ù„ÛŒÙ†Ú¯:** Ø§Ù†ØªÙ‚Ø§Ù„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø³Ù„ÙˆÙ„ÛŒ
â€¢ **Ø³Ø§Ø®ØªØ§Ø± Ø³Ù„ÙˆÙ„ÛŒ:** Ø­ÙØ¸ Ø³Ø§Ø®ØªØ§Ø± Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³Ù„ÙˆÙ„

ğŸ’¡ **Ù†Ú©ØªÙ‡:** Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ§Ø¨Ø· Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø³Øª."""

    def _generate_drug_related_answer(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¯Ø§Ø±ÙˆÙ‡Ø§"""
        query = retrieval_result.query
        context = retrieval_result.context_text
        
        drug_info = self._extract_drug_info_from_context(context)
        
        return f"""ğŸ’Š **ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø±ÙˆÙ‡Ø§ Ùˆ Ø¯Ø±Ù…Ø§Ù†â€ŒÙ‡Ø§**

**Ø³ÙˆØ§Ù„:** {query}

**Ø¯Ø§Ø±ÙˆÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡:**
{drug_info}

**Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†ÛŒ:**
â€¢ **Ù…Ù‡Ø§Ø± Ø±Ø´Ø¯ Ø³Ù„ÙˆÙ„ÛŒ:** Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÚ©Ø«ÛŒØ± Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ø³Ø±Ø·Ø§Ù†ÛŒ
â€¢ **ØªØ­Ø±ÛŒÚ© Ø³ÛŒØ³ØªÙ… Ø§ÛŒÙ…Ù†ÛŒ:** ØªÙ‚ÙˆÛŒØª Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ…Ù†ÛŒ
â€¢ **Ù…Ù‡Ø§Ø± Ø¢Ù†Ú˜ÛŒÙˆÚ˜Ù†Ø²:** Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø±Ø´Ø¯ Ø¹Ø±ÙˆÙ‚ Ø®ÙˆÙ†ÛŒ ØªÙˆÙ…ÙˆØ±
â€¢ **Ø§Ù„Ù‚Ø§ÛŒ Ø¢Ù¾ÙˆÙ¾ØªÙˆØ²:** Ù…Ø±Ú¯ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ø´Ø¯Ù‡ Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ø³Ø±Ø·Ø§Ù†ÛŒ

ğŸ’¡ **Ù†Ú©ØªÙ‡:** Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ§Ø¨Ø· Ø¯Ø§Ø±Ùˆ-Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¯Ø± Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø³Øª."""

    def _generate_disease_related_answer(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§"""
        query = retrieval_result.query
        context = retrieval_result.context_text
        
        disease_info = self._extract_disease_info_from_context(context)
        
        return f"""ğŸ¥ **ØªØ­Ù„ÛŒÙ„ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ø¹Ù„Ù„ Ø¢Ù†Ù‡Ø§**

**Ø³ÙˆØ§Ù„:** {query}

**Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡:**
{disease_info}

**Ù…Ú©Ø§Ù†ÛŒØ³Ù…â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒØ²Ø§ÛŒÛŒ:**
â€¢ **ØªØºÛŒÛŒØ±Ø§Øª Ú˜Ù†ØªÛŒÚ©ÛŒ:** Ø¬Ù‡Ø´â€ŒÙ‡Ø§ÛŒ Ú˜Ù†ØªÛŒÚ©ÛŒ Ù…Ø¤Ø«Ø± Ø¯Ø± Ø¨ÛŒÙ…Ø§Ø±ÛŒ
â€¢ **Ø§Ø®ØªÙ„Ø§Ù„Ø§Øª Ù…ØªØ§Ø¨ÙˆÙ„ÛŒÚ©:** ØªØºÛŒÛŒØ± Ø¯Ø± Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…ØªØ§Ø¨ÙˆÙ„ÛŒÚ©
â€¢ **Ø§Ù„ØªÙ‡Ø§Ø¨:** Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø§Ù„ØªÙ‡Ø§Ø¨ÛŒ ØºÛŒØ±Ø·Ø¨ÛŒØ¹ÛŒ
â€¢ **Ø§Ø®ØªÙ„Ø§Ù„Ø§Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒ:** ØªØºÛŒÛŒØ± Ø¯Ø± Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§ÙØªâ€ŒÙ‡Ø§

ğŸ’¡ **Ù†Ú©ØªÙ‡:** Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒÙ…Ø§Ø±ÛŒ-Ú˜Ù† Ø¯Ø± Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø³Øª."""

    def _generate_tissue_related_answer(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¨Ø§ÙØªâ€ŒÙ‡Ø§"""
        query = retrieval_result.query
        context = retrieval_result.context_text
        
        tissue_info = self._extract_tissue_info_from_context(context)
        
        return f"""ğŸ”¬ **ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¢Ù†Ù‡Ø§**

**Ø³ÙˆØ§Ù„:** {query}

**Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡:**
{tissue_info}

**Ù†Ù‚Ø´â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒÙˆÙ„ÙˆÚ˜ÛŒÚ©ÛŒ:**
â€¢ **Ø³Ø§Ø®ØªØ§Ø± Ùˆ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ:** Ø­ÙØ¸ Ø´Ú©Ù„ Ùˆ Ø³Ø§Ø®ØªØ§Ø± Ø§Ù†Ø¯Ø§Ù…â€ŒÙ‡Ø§
â€¢ **Ù…ØªØ§Ø¨ÙˆÙ„ÛŒØ³Ù…:** Ø´Ø±Ú©Øª Ø¯Ø± ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ù…ØªØ§Ø¨ÙˆÙ„ÛŒÚ©
â€¢ **Ø³ÛŒÚ¯Ù†Ø§Ù„ÛŒÙ†Ú¯:** Ø§Ù†ØªÙ‚Ø§Ù„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø³Ù„ÙˆÙ„ÛŒ
â€¢ **Ù…Ø­Ø§ÙØ¸Øª:** Ù…Ø­Ø§ÙØ¸Øª Ø§Ø² Ø§Ù†Ø¯Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ

ğŸ’¡ **Ù†Ú©ØªÙ‡:** Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ§Ø¨Ø· Ø¨Ø§ÙØª-Ú˜Ù† Ø¯Ø± Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø³Øª."""

    def _generate_general_structured_answer(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ø¹Ù…ÙˆÙ…ÛŒ"""
        query = retrieval_result.query
        context = retrieval_result.context_text
        
        # Ø®Ù„Ø§ØµÙ‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÛŒØ§ÙØª Ø´Ø¯Ù‡
        summary = self._create_context_summary(context)
        
        return f"""ğŸ“Š **ØªØ­Ù„ÛŒÙ„ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÛŒØ§ÙØª Ø´Ø¯Ù‡**

**Ø³ÙˆØ§Ù„:** {query}

**Ø®Ù„Ø§ØµÙ‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª:**
{summary}

**ØªØ­Ù„ÛŒÙ„ Ú©Ù„ÛŒ:**
Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø³ÙˆØ§Ù„ Ø´Ù…Ø§ ÛŒØ§ÙØª Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø´Ø§Ù…Ù„ Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒÙ† Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ù…Ø®ØªÙ„Ù Ø§Ø³Øª Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ Ø¯Ø±Ú© Ø¨Ù‡ØªØ± Ù…ÙˆØ¶ÙˆØ¹ Ú©Ù…Ú© Ú©Ù†Ø¯.

ğŸ’¡ **Ù†Ú©ØªÙ‡:** Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."""

    def _extract_cancer_info_from_context(self, context: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø±Ø·Ø§Ù† Ø§Ø² context"""
        if not context:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú˜Ù†â€ŒÙ‡Ø§ Ùˆ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
        lines = context.split('\n')
        cancer_related = []
        
        for line in lines:
            if any(word in line.lower() for word in ['cancer', 'tumor', 'malignant']):
                cancer_related.append(line.strip())
        
        if cancer_related:
            return "\n".join(cancer_related[:10])  # Ø­Ø¯Ø§Ú©Ø«Ø± 10 Ø®Ø·
        else:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø³Ø±Ø·Ø§Ù† Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ø§Ø³Øª."

    def _extract_gene_info_from_context(self, context: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú˜Ù† Ø§Ø² context"""
        if not context:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        
        lines = context.split('\n')
        gene_related = []
        
        for line in lines:
            if 'gene' in line.lower() or any(word in line.lower() for word in ['express', 'regulate', 'function']):
                gene_related.append(line.strip())
        
        if gene_related:
            return "\n".join(gene_related[:10])
        else:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ú˜Ù†â€ŒÙ‡Ø§ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ø§Ø³Øª."

    def _extract_drug_info_from_context(self, context: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ø±Ùˆ Ø§Ø² context"""
        if not context:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        
        lines = context.split('\n')
        drug_related = []
        
        for line in lines:
            if any(word in line.lower() for word in ['drug', 'compound', 'medicine', 'treat']):
                drug_related.append(line.strip())
        
        if drug_related:
            return "\n".join(drug_related[:10])
        else:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¯Ø§Ø±ÙˆÙ‡Ø§ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ø§Ø³Øª."

    def _extract_disease_info_from_context(self, context: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø§Ø² context"""
        if not context:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        
        lines = context.split('\n')
        disease_related = []
        
        for line in lines:
            if any(word in line.lower() for word in ['disease', 'disorder', 'condition', 'symptom']):
                disease_related.append(line.strip())
        
        if disease_related:
            return "\n".join(disease_related[:10])
        else:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ø§Ø³Øª."

    def _extract_tissue_info_from_context(self, context: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø§ÙØª Ø§Ø² context"""
        if not context:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        
        lines = context.split('\n')
        tissue_related = []
        
        for line in lines:
            if any(word in line.lower() for word in ['tissue', 'organ', 'anatomy', 'heart', 'brain', 'liver']):
                tissue_related.append(line.strip())
        
        if tissue_related:
            return "\n".join(tissue_related[:10])
        else:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¨Ø§ÙØªâ€ŒÙ‡Ø§ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ø§Ø³Øª."

    def _create_context_summary(self, context: str) -> str:
        """Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ context"""
        if not context:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        
        lines = context.split('\n')
        summary_lines = []
        
        # Ø´Ù…Ø§Ø±Ø´ Ø§Ù†ÙˆØ§Ø¹ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
        gene_count = sum(1 for line in lines if 'gene' in line.lower())
        disease_count = sum(1 for line in lines if 'disease' in line.lower())
        drug_count = sum(1 for line in lines if 'drug' in line.lower() or 'compound' in line.lower())
        
        if gene_count > 0:
            summary_lines.append(f"â€¢ Ú˜Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·: {gene_count} Ù…ÙˆØ±Ø¯")
        if disease_count > 0:
            summary_lines.append(f"â€¢ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·: {disease_count} Ù…ÙˆØ±Ø¯")
        if drug_count > 0:
            summary_lines.append(f"â€¢ Ø¯Ø§Ø±ÙˆÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·: {drug_count} Ù…ÙˆØ±Ø¯")
        
        if summary_lines:
            return "\n".join(summary_lines)
        else:
            return "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³Øª."

    # ========================================
    # Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ù‡ÙˆØ´Ù…Ù†Ø¯
    # ========================================
    
    def meta_llama_generation(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ Meta Llama 3.1 (Ù…Ø­Ù„ÛŒ)"""
        try:
            # Ø§ÛŒÙ† Ù…ØªØ¯ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù†ØµØ¨ Llama 3.1 Ø¯Ø§Ø±Ø¯
            # Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ API Key ÛŒØ§ Ù†ØµØ¨ Ù…Ø­Ù„ÛŒ Ø§Ø³Øª
            return "ğŸ”§ Meta Llama 3.1 Ø¯Ø± Ø­Ø§Ù„ ØªÙˆØ³Ø¹Ù‡ Ø§Ø³Øª.\n\n" + self._fallback_generation(retrieval_result, "Meta Llama 3.1")
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Meta Llama 3.1: {e}")
            return self._fallback_generation(retrieval_result, "Meta Llama 3.1")
    
    def mistral_ai_generation(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ Mistral AI (Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§)"""
        try:
            # Ø§ÛŒÙ† Ù…ØªØ¯ Ù†ÛŒØ§Ø² Ø¨Ù‡ API Key Ø§Ø² Mistral AI Ø¯Ø§Ø±Ø¯
            return "ğŸ”§ Mistral AI Ø¯Ø± Ø­Ø§Ù„ ØªÙˆØ³Ø¹Ù‡ Ø§Ø³Øª.\n\n" + self._fallback_generation(retrieval_result, "Mistral AI")
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Mistral AI: {e}")
            return self._fallback_generation(retrieval_result, "Mistral AI")
    
    def cohere_command_generation(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ Cohere Command (ØªØ®ØµØµÛŒ)"""
        try:
            # Ø§ÛŒÙ† Ù…ØªØ¯ Ù†ÛŒØ§Ø² Ø¨Ù‡ API Key Ø§Ø² Cohere Ø¯Ø§Ø±Ø¯
            return "ğŸ”§ Cohere Command Ø¯Ø± Ø­Ø§Ù„ ØªÙˆØ³Ø¹Ù‡ Ø§Ø³Øª.\n\n" + self._fallback_generation(retrieval_result, "Cohere Command")
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Cohere Command: {e}")
            return self._fallback_generation(retrieval_result, "Cohere Command")
    
    def perplexity_sonar_generation(self, retrieval_result: RetrievalResult) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ Perplexity Sonar (Ø¬Ø³ØªØ¬ÙˆÚ¯Ø±)"""
        try:
            # Ø§ÛŒÙ† Ù…ØªØ¯ Ù†ÛŒØ§Ø² Ø¨Ù‡ API Key Ø§Ø² Perplexity Ø¯Ø§Ø±Ø¯
            return "ğŸ”§ Perplexity Sonar Ø¯Ø± Ø­Ø§Ù„ ØªÙˆØ³Ø¹Ù‡ Ø§Ø³Øª.\n\n" + self._fallback_generation(retrieval_result, "Perplexity Sonar")
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Perplexity Sonar: {e}")
            return self._fallback_generation(retrieval_result, "Perplexity Sonar")

# Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡
if __name__ == "__main__":
    service = GraphRAGService()
    
    # ØªØ³Øª Ø³Ø±ÙˆÛŒØ³
    result = service.process_query(
        query="What is the relationship between HMGB3 and diabetes?",
        retrieval_method=RetrievalMethod.BFS,
        generation_model=GenerationModel.GPT_SIMULATION,
        text_generation_type='INTELLIGENT'
    )
    
    print(json.dumps(result, indent=2, ensure_ascii=False)) 
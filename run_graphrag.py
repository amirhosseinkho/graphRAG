# -*- coding: utf-8 -*-
"""
GraphRAG - Simple Demo Script
Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ÛŒÚ© Ù†Ø³Ø®Ù‡ Ø³Ø§Ø¯Ù‡ Ø§Ø² Ù¾Ø±ÙˆÚ˜Ù‡ GraphRAG Ø±Ø§ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
"""

import pandas as pd
import networkx as nx
import spacy
from spacy.lang.en.stop_words import STOP_WORDS
from collections import deque
import pickle
import os

def download_data():
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Hetionet"""
    import urllib.request
    import gzip
    import subprocess
    import sys
    
    print("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Hetionet...")
    
    # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†ÙˆØ¯Ù‡Ø§
    if not os.path.exists('hetionet-v1.0-nodes.tsv'):
        print("Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ù†ÙˆØ¯Ù‡Ø§...")
        urllib.request.urlretrieve(
            'https://raw.githubusercontent.com/hetio/hetionet/master/hetnet/tsv/hetionet-v1.0-nodes.tsv',
            'hetionet-v1.0-nodes.tsv'
        )
    
    # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÛŒØ§Ù„â€ŒÙ‡Ø§ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² wget ÛŒØ§ curl
    if not os.path.exists('hetionet-v1.0-edges.sif') or os.path.getsize('hetionet-v1.0-edges.sif') == 0:
        print("Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ÛŒØ§Ù„â€ŒÙ‡Ø§...")
        
        # Ø­Ø°Ù ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ
        if os.path.exists('hetionet-v1.0-edges.sif.gz'):
            os.remove('hetionet-v1.0-edges.sif.gz')
        if os.path.exists('hetionet-v1.0-edges.sif'):
            os.remove('hetionet-v1.0-edges.sif')
        
        try:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² PowerShell Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯
            cmd = [
                'powershell', '-Command',
                'Invoke-WebRequest -Uri "https://raw.githubusercontent.com/hetio/hetionet/master/hetnet/tsv/hetionet-v1.0-edges.sif.gz" -OutFile "hetionet-v1.0-edges.sif.gz"'
            ]
            subprocess.run(cmd, check=True)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ§ÛŒÙ„ ÙØ´Ø±Ø¯Ù‡
            with gzip.open('hetionet-v1.0-edges.sif.gz', 'rb') as f_in:
                with open('hetionet-v1.0-edges.sif', 'wb') as f_out:
                    f_out.write(f_in.read())
            
            # Ø­Ø°Ù ÙØ§ÛŒÙ„ ÙØ´Ø±Ø¯Ù‡
            os.remove('hetionet-v1.0-edges.sif.gz')
            print("ÙØ§ÛŒÙ„ ÛŒØ§Ù„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
            
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯: {e}")
            print("ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø³ØªÙ‚ÛŒÙ…...")
            try:
                cmd = [
                    'powershell', '-Command',
                    'Invoke-WebRequest -Uri "https://raw.githubusercontent.com/hetio/hetionet/master/hetnet/tsv/hetionet-v1.0-edges.sif" -OutFile "hetionet-v1.0-edges.sif"'
                ]
                subprocess.run(cmd, check=True)
                print("ÙØ§ÛŒÙ„ ÛŒØ§Ù„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯.")
            except Exception as e2:
                print(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø³ØªÙ‚ÛŒÙ…: {e2}")
                print("Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø³ØªÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.")
                return False
    
    return True

def load_graph():
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú¯Ø±Ø§Ù"""
    print("ğŸ“Š Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú¯Ø±Ø§Ù...")
    
    # Ø®ÙˆØ§Ù†Ø¯Ù† Ù†ÙˆØ¯Ù‡Ø§
    nodes = pd.read_csv('hetionet-v1.0-nodes.tsv', sep='\t', encoding='utf-8-sig')
    print(f"ØªØ¹Ø¯Ø§Ø¯ Ù†ÙˆØ¯Ù‡Ø§: {len(nodes)}")
    
    # Ø®ÙˆØ§Ù†Ø¯Ù† ÛŒØ§Ù„â€ŒÙ‡Ø§
    edges = pd.read_csv('hetionet-v1.0-edges.sif', sep='\t')
    print(f"ØªØ¹Ø¯Ø§Ø¯ ÛŒØ§Ù„â€ŒÙ‡Ø§: {len(edges)}")
    
    # Ø³Ø§Ø®Øª Ú¯Ø±Ø§Ù
    G = nx.Graph()
    
    # Ø§ÙØ²ÙˆØ¯Ù† Ù†ÙˆØ¯Ù‡Ø§
    for _, row in nodes.iterrows():
        G.add_node(row['id'], name=row['name'], kind=row['kind'])
    
    # Ø§ÙØ²ÙˆØ¯Ù† ÛŒØ§Ù„â€ŒÙ‡Ø§
    for _, row in edges.iterrows():
        G.add_edge(row['source'], row['target'], metaedge=row['metaedge'])
    
    print(f"Ú¯Ø±Ø§Ù Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯: {G.number_of_nodes()} Ù†ÙˆØ¯ØŒ {G.number_of_edges()} ÛŒØ§Ù„")
    return G

def extract_keywords(text):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø§Ø² Ù…ØªÙ†"""
    nlp = spacy.load("en_core_web_sm")
    doc = nlp(text)
    keywords = set()
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…â€ŒØ¯Ø§Ø±
    for ent in doc.ents:
        if ent.label_ not in {"DATE", "TIME", "PERCENT", "MONEY", "QUANTITY", "ORDINAL", "CARDINAL"}:
            keywords.add(ent.text.lower())
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù…â€ŒÙ‡Ø§ Ùˆ Ø§Ø³Ù… Ø®Ø§Øµâ€ŒÙ‡Ø§
    for token in doc:
        if (token.pos_ in {"NOUN", "PROPN"} and 
            token.text.lower() not in STOP_WORDS and 
            token.is_alpha and len(token.text) > 2):
            keywords.add(token.text.lower())
    
    return sorted(keywords)

def match_tokens_to_nodes(graph, tokens):
    """ØªØ·Ø¨ÛŒÙ‚ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¨Ø§ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ú¯Ø±Ø§Ù"""
    matched = {}
    for token in tokens:
        token_lower = token.lower()
        for node_id, attrs in graph.nodes(data=True):
            if token_lower in attrs['name'].lower():
                matched[token] = node_id
                break
    return matched

def get_shortest_path(graph, source, target):
    """ÛŒØ§ÙØªÙ† Ú©ÙˆØªØ§Ù‡â€ŒØªØ±ÛŒÙ† Ù…Ø³ÛŒØ± Ø¨ÛŒÙ† Ø¯Ùˆ Ù†ÙˆØ¯"""
    try:
        path = nx.shortest_path(graph, source=source, target=target)
        return path
    except nx.NetworkXNoPath:
        return None

def demo():
    """Ù†Ù…Ø§ÛŒØ´ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³ÛŒØ³ØªÙ…"""
    print("ğŸš€ Ø´Ø±ÙˆØ¹ Ù†Ù…Ø§ÛŒØ´ GraphRAG...")
    
    # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    if not download_data():
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        return
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú¯Ø±Ø§Ù
    G = load_graph()
    
    # Ù…Ø«Ø§Ù„ Ø³ÙˆØ§Ù„
    question = "What is the relationship between HMGB3 and pulmonary valve formation?"
    print(f"\nâ“ Ø³ÙˆØ§Ù„: {question}")
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
    tokens = extract_keywords(question)
    print(f"ğŸ” Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡: {tokens}")
    
    # ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ú¯Ø±Ø§Ù
    matches = match_tokens_to_nodes(G, tokens)
    print(f"âœ… ØªØ·Ø¨ÛŒÙ‚â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡:")
    for token, node_id in matches.items():
        print(f"  {token} â†’ {G.nodes[node_id]['name']} ({G.nodes[node_id]['kind']})")
    
    # ÛŒØ§ÙØªÙ† Ù…Ø³ÛŒØ± Ø¨ÛŒÙ† Ø¯Ùˆ Ù†ÙˆØ¯
    if len(matches) >= 2:
        node_ids = list(matches.values())
        path = get_shortest_path(G, node_ids[0], node_ids[1])
        
        if path:
            print(f"\nğŸ›¤ï¸ Ù…Ø³ÛŒØ± ÛŒØ§ÙØª Ø´Ø¯Ù‡ Ø¨ÛŒÙ† '{G.nodes[node_ids[0]]['name']}' Ùˆ '{G.nodes[node_ids[1]]['name']}':")
            for i, node in enumerate(path):
                print(f"  {i+1}. {G.nodes[node]['name']} ({G.nodes[node]['kind']})")
                if i < len(path) - 1:
                    edge_data = G.get_edge_data(node, path[i+1])
                    print(f"     â†“ [{edge_data['metaedge']}]")
        else:
            print("âŒ Ù…Ø³ÛŒØ±ÛŒ Ø¨ÛŒÙ† Ù†ÙˆØ¯Ù‡Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ ÛŒØ§ÙØªÙ‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    else:
        print("âŒ Ú©Ù…ØªØ± Ø§Ø² 2 ØªÙˆÚ©Ù† Ø¯Ø± Ú¯Ø±Ø§Ù ØªØ·Ø¨ÛŒÙ‚ ÛŒØ§ÙØª.")

if __name__ == "__main__":
    demo() 
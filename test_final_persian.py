#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ Ø³ÙˆØ§Ù„Ø§Øª ÙØ§Ø±Ø³ÛŒ - Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ÛŒ Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯Ù‡
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from graphrag_service import GraphRAGService

def test_final_persian():
    """ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ Ú©Ù„Ù…Ø§Øª ÙØ§Ø±Ø³ÛŒ"""
    
    service = GraphRAGService()
    service.initialize()
    
    # ØªØ³Øª Ú©Ù„Ù…Ø§Øª ÙØ§Ø±Ø³ÛŒ Ù…Ø®ØªÙ„Ù
    test_words = [
        "Ø³Ø±Ø·Ø§Ù†",
        "Ú©Ø¨Ø¯", 
        "Ù…ØºØ²",
        "Ú˜Ù†",
        "Ø¯Ø§Ø±Ùˆ",
        "Ø¢Ø³Ù¾Ø±ÛŒÙ†",
        "Ø¨ÛŒÙ…Ø§Ø±ÛŒ",
        "Ø¨Ø§ÙØª",
        "ÙØ±Ø¢ÛŒÙ†Ø¯",
        "Ø¢Ù¾ÙˆÙ¾ØªÙˆØ²",
        "TP53",
        "BRCA1"
    ]
    
    print("ğŸ” ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ Ú©Ù„Ù…Ø§Øª ÙØ§Ø±Ø³ÛŒ")
    print("=" * 40)
    
    for word in test_words:
        print(f"\nğŸ“ Ú©Ù„Ù…Ù‡: {word}")
        print("-" * 25)
        
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
            keywords = service.extract_keywords(word)
            print(f"ğŸ”‘ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: {keywords}")
            
            # ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ú¯Ø±Ø§Ù
            matched_nodes = service.match_tokens_to_nodes(keywords)
            print(f"ğŸ¯ Ù†ÙˆØ¯Ù‡Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ ÛŒØ§ÙØªÙ‡: {len(matched_nodes)}")
            
            if matched_nodes:
                for token, node_id in matched_nodes.items():
                    node_name = service.G.nodes[node_id]['name']
                    node_kind = service.G.nodes[node_id].get('kind', 'Unknown')
                    print(f"   '{token}' -> {node_name} ({node_kind})")
            else:
                print("âŒ Ù‡ÛŒÚ† Ù†ÙˆØ¯ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ù†ÛŒØ§ÙØª!")
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§: {e}")
        
        print()

def test_persian_sentences():
    """ØªØ³Øª Ø¬Ù…Ù„Ø§Øª ÙØ§Ø±Ø³ÛŒ"""
    
    service = GraphRAGService()
    service.initialize()
    
    # Ø¬Ù…Ù„Ø§Øª ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ³Øª
    sentences = [
        "Ú˜Ù† TP53 Ú†Ù‡ Ú©Ø§Ø±ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ØŸ",
        "Ú©Ø¯Ø§Ù… Ú˜Ù†â€ŒÙ‡Ø§ Ø¯Ø± Ú©Ø¨Ø¯ Ø¨ÛŒØ§Ù† Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ØŸ",
        "Ø³Ø±Ø·Ø§Ù† Ø³ÛŒÙ†Ù‡ Ø¨Ø§ Ú©Ø¯Ø§Ù… Ú˜Ù†â€ŒÙ‡Ø§ Ù…Ø±ØªØ¨Ø· Ø§Ø³ØªØŸ",
        "Ø¢Ø³Ù¾Ø±ÛŒÙ† Ú†Ù‡ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ø±Ø§ Ø¯Ø±Ù…Ø§Ù† Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ"
    ]
    
    print("\nğŸ” ØªØ³Øª Ø¬Ù…Ù„Ø§Øª ÙØ§Ø±Ø³ÛŒ")
    print("=" * 40)
    
    for sentence in sentences:
        print(f"\nğŸ“ Ø¬Ù…Ù„Ù‡: {sentence}")
        print("-" * 30)
        
        try:
            keywords = service.extract_keywords(sentence)
            print(f"ğŸ”‘ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: {keywords}")
            
            matched_nodes = service.match_tokens_to_nodes(keywords)
            print(f"ğŸ¯ Ù†ÙˆØ¯Ù‡Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ ÛŒØ§ÙØªÙ‡: {len(matched_nodes)}")
            
            if matched_nodes:
                for token, node_id in matched_nodes.items():
                    node_name = service.G.nodes[node_id]['name']
                    node_kind = service.G.nodes[node_id].get('kind', 'Unknown')
                    print(f"   '{token}' -> {node_name} ({node_kind})")
            else:
                print("âŒ Ù‡ÛŒÚ† Ù†ÙˆØ¯ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ù†ÛŒØ§ÙØª!")
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§: {e}")
        
        print()

if __name__ == "__main__":
    print("ğŸš€ Ø´Ø±ÙˆØ¹ ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ ÙØ§Ø±Ø³ÛŒ")
    test_final_persian()
    test_persian_sentences()
    print("\nâœ… ØªØ³Øª Ú©Ø§Ù…Ù„ Ø´Ø¯!") 
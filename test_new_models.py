#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from graphrag_service import GraphRAGService, RetrievalMethod, GenerationModel

def test_new_models():
    """ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯"""
    
    print("ğŸ§ª Ø´Ø±ÙˆØ¹ ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯...")
    print("=" * 60)
    
    # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆÛŒØ³
    service = GraphRAGService()
    service.initialize()
    
    # Ø³ÙˆØ§Ù„ ØªØ³Øª
    test_query = "What genes are expressed in heart?"
    
    print(f"ğŸ“ Ø³ÙˆØ§Ù„ ØªØ³Øª: {test_query}")
    print()
    
    # ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
    models_to_test = [
        GenerationModel.OPENAI_GPT_4O,
        GenerationModel.OPENAI_GPT_4O_MINI,
        GenerationModel.ANTHROPIC_CLAUDE_3_5_SONNET,
        GenerationModel.GOOGLE_GEMINI_1_5_PRO,
        GenerationModel.META_LLAMA_3_1,
        GenerationModel.MISTRAL_AI
    ]
    
    for model in models_to_test:
        print(f"ğŸ”¹ ØªØ³Øª Ù…Ø¯Ù„: {model.value}")
        print("-" * 40)
        
        try:
            result = service.process_query(
                query=test_query,
                retrieval_method=RetrievalMethod.BFS,
                generation_model=model,
                text_generation_type='SIMPLE',
                max_depth=2
            )
            
            print("âœ… Ù†ØªÛŒØ¬Ù‡:")
            print(f"â€¢ Ù…Ø¯Ù„: {result['model']}")
            print(f"â€¢ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {result['confidence']}")
            print(f"â€¢ Ù¾Ø§Ø³Ø®: {result['answer'][:100]}...")
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§: {e}")
        
        print()
        print("=" * 60)
        print()
    
    print("ğŸ‰ ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ú©Ø§Ù…Ù„ Ø´Ø¯!")

if __name__ == "__main__":
    test_new_models() 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ØªØ³Øª OpenAI GPT Ø¨Ø§ API Key
"""

import json
from graphrag_service import GraphRAGService, RetrievalMethod, GenerationModel

def test_openai_gpt():
    """ØªØ³Øª OpenAI GPT"""
    
    print("ğŸš€ ØªØ³Øª OpenAI GPT")
    print("=" * 50)
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø±ÙˆÛŒØ³
    service = GraphRAGService()
    
    # ØªÙ†Ø¸ÛŒÙ… API Key
    OPENAI_API_KEY = "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"
    service.set_openai_api_key(OPENAI_API_KEY)
    
    # Ø³ÙˆØ§Ù„Ø§Øª ØªØ³Øª
    test_questions = [
        "Ú˜Ù† TP53 Ú†Ù‡ Ù†Ù‚Ø´ÛŒ Ø¯Ø± Ø³Ø±Ø·Ø§Ù† Ø¯Ø§Ø±Ø¯ØŸ",
        "Ù…Ú©Ø§Ù†ÛŒØ²Ù… Ø¹Ù…Ù„ Ø¯Ø§Ø±ÙˆÛŒ Ù…ØªÙÙˆØ±Ù…ÛŒÙ† Ú†ÛŒØ³ØªØŸ",
        "Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¢Ù„Ø²Ø§ÛŒÙ…Ø± Ú†Ù‡ Ø¹Ù„Ù„ Ú˜Ù†ØªÛŒÚ©ÛŒ Ø¯Ø§Ø±Ø¯ØŸ",
        "Ú˜Ù† BRCA1 Ú†Ú¯ÙˆÙ†Ù‡ Ø¨Ø§ Ø³Ø±Ø·Ø§Ù† Ø³ÛŒÙ†Ù‡ Ù…Ø±ØªØ¨Ø· Ø§Ø³ØªØŸ",
        "Ø¢Ø³Ù¾Ø±ÛŒÙ† Ú†Ú¯ÙˆÙ†Ù‡ Ø§Ø² Ù„Ø®ØªÙ‡ Ø´Ø¯Ù† Ø®ÙˆÙ† Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ"
    ]
    
    print("ğŸ” Ø´Ø±ÙˆØ¹ ØªØ³Øª OpenAI GPT...")
    print("-" * 40)
    
    for i, question in enumerate(test_questions, 1):
        print(f"\nğŸ“ Ø³ÙˆØ§Ù„ {i}: {question}")
        print("-" * 30)
        
        try:
            # ØªØ³Øª Ø¨Ø¯ÙˆÙ† Ú¯Ø±Ø§Ù
            result_no_graph = service.process_query(
                query=question,
                retrieval_method=RetrievalMethod.NO_RETRIEVAL,
                generation_model=GenerationModel.OPENAI_GPT
            )
            
            print("ğŸ¤– Ù¾Ø§Ø³Ø® OpenAI GPT (Ø¨Ø¯ÙˆÙ† Ú¯Ø±Ø§Ù):")
            print(result_no_graph['answer'])
            print(f"ğŸ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {result_no_graph['confidence']:.2f}")
            
            # ØªØ³Øª Ø¨Ø§ Ú¯Ø±Ø§Ù (Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)
            if service.G and service.G.number_of_nodes() > 0:
                print("\n" + "="*40)
                print("ğŸ”— ØªØ³Øª Ø¨Ø§ Ú¯Ø±Ø§Ù:")
                
                result_with_graph = service.process_query(
                    query=question,
                    retrieval_method=RetrievalMethod.ENSEMBLE,
                    generation_model=GenerationModel.OPENAI_GPT
                )
                
                print("ğŸ¤– Ù¾Ø§Ø³Ø® OpenAI GPT (Ø¨Ø§ Ú¯Ø±Ø§Ù):")
                print(result_with_graph['answer'])
                print(f"ğŸ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {result_with_graph['confidence']:.2f}")
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§: {e}")
        
        print("\n" + "="*50)

def test_openai_models():
    """ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù OpenAI"""
    
    print("\nğŸ§ª ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù OpenAI")
    print("=" * 50)
    
    service = GraphRAGService()
    OPENAI_API_KEY = "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"
    service.set_openai_api_key(OPENAI_API_KEY)
    
    question = "Ú˜Ù† TP53 Ú†Ù‡ Ù†Ù‚Ø´ÛŒ Ø¯Ø± Ø³Ø±Ø·Ø§Ù† Ø¯Ø§Ø±Ø¯ Ùˆ Ú†Ú¯ÙˆÙ†Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§Ø² Ø¢Ù† Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯ØŸ"
    
    print(f"Ø³ÙˆØ§Ù„: {question}")
    print("-" * 40)
    
    # ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
    models = [
        ("gpt-3.5-turbo", "GPT-3.5 Turbo (Ø§Ø±Ø²Ø§Ù† Ùˆ Ø³Ø±ÛŒØ¹)"),
        ("gpt-4", "GPT-4 (Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ±)"),
        ("gpt-4-turbo-preview", "GPT-4 Turbo (Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ†)")
    ]
    
    for model_name, description in models:
        print(f"\nğŸ¤– ØªØ³Øª {description}")
        print("-" * 30)
        
        try:
            # ØªØºÛŒÛŒØ± Ù…Ø¯Ù„ Ø¯Ø± Ú©Ø¯
            from openai import OpenAI
            client = OpenAI(api_key=OPENAI_API_KEY)
            
            # Ø§ÛŒØ¬Ø§Ø¯ prompt
            prompt = f"""
            ğŸ§¬ Ø³ÙˆØ§Ù„ Ù¾Ø²Ø´Ú©ÛŒ-Ø²ÛŒØ³ØªÛŒ:
            {question}
            
            ğŸ“‹ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ:
            Ù„Ø·ÙØ§Ù‹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ù†Ø´ ØªØ®ØµØµÛŒ Ø®ÙˆØ¯ Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡ Ø¹Ù„ÙˆÙ… Ø²ÛŒØ³ØªÛŒ Ùˆ Ù¾Ø²Ø´Ú©ÛŒØŒ Ù¾Ø§Ø³Ø® Ø¬Ø§Ù…Ø¹ Ùˆ Ø¯Ù‚ÛŒÙ‚ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ú©Ù‡ Ø´Ø§Ù…Ù„:
            
            1. ğŸ¯ ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¶ÙˆØ¹: Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚ Ø³ÙˆØ§Ù„ Ùˆ Ø¬Ù†Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¢Ù†
            2. ğŸ”¬ Ù…Ø¨Ø§Ù†ÛŒ Ø¹Ù„Ù…ÛŒ: ØªÙˆØ¶ÛŒØ­ Ù…Ú©Ø§Ù†ÛŒØ²Ù…â€ŒÙ‡Ø§ Ùˆ ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ³ØªÛŒ Ù…Ø±ØªØ¨Ø·
            3. ğŸ’Š Ø¬Ù†Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†ÛŒ: Ø¯Ø± ØµÙˆØ±Øª Ù…Ø±ØªØ¨Ø· Ø¨ÙˆØ¯Ù†ØŒ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†ÛŒ Ùˆ Ø¯Ø§Ø±ÙˆÛŒÛŒ
            4. ğŸ§ª ØªØ­Ù‚ÛŒÙ‚Ø§Øª: ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ ØªØ­Ù‚ÛŒÙ‚Ø§Øª Ùˆ Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø·
            5. ğŸ”® Ú†Ø´Ù…â€ŒØ§Ù†Ø¯Ø§Ø² Ø¢ÛŒÙ†Ø¯Ù‡: Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ Ùˆ Ù¾ÛŒØ´Ø±ÙØªâ€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡
            6. ğŸ’¡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ: Ù†Ú©Ø§Øª Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ Ù¾Ú˜ÙˆÙ‡Ø´Ú¯Ø±Ø§Ù† Ùˆ Ù¾Ø²Ø´Ú©Ø§Ù†
            
            Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ØŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ùˆ ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.
            """
            
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "You are a biomedical expert. Provide detailed, accurate, and well-structured answers in Persian with proper formatting and emojis."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.7
            )
            
            answer = response.choices[0].message.content.strip()
            usage = response.usage
            
            print("âœ… Ù…ÙˆÙÙ‚")
            print(f"ğŸ“Š Ø§Ø³ØªÙØ§Ø¯Ù‡ ØªÙˆÚ©Ù†: {usage.total_tokens}")
            print(f"ğŸ’° Ù‡Ø²ÛŒÙ†Ù‡ ØªÙ‚Ø±ÛŒØ¨ÛŒ: ${usage.total_tokens * 0.000002:.6f}")
            print("ğŸ“ Ù¾Ø§Ø³Ø®:")
            print(answer[:300] + "..." if len(answer) > 300 else answer)
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§: {e}")

if __name__ == "__main__":
    print("ğŸš€ Ø´Ø±ÙˆØ¹ ØªØ³Øª OpenAI GPT")
    
    # ØªØ³Øª Ø§ØµÙ„ÛŒ
    test_openai_gpt()
    
    # ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
    test_openai_models()
    
    print("\nâœ… ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ OpenAI Ú©Ø§Ù…Ù„ Ø´Ø¯!") 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ØªØ³Øª ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ… GraphRAG
"""

import sys
import os
from pathlib import Path

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± Ø§ØµÙ„ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ù‡ sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from graphrag_service import GraphRAGService, RetrievalMethod, GenerationModel

def test_default_limits():
    """ØªØ³Øª Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶"""
    print("ğŸ§ª ØªØ³Øª Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶")
    print("=" * 50)
    
    service = GraphRAGService()
    
    # Ù†Ù…Ø§ÛŒØ´ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
    config = service.get_config()
    print("ğŸ“‹ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶:")
    for key, value in config.items():
        print(f"  â€¢ {key}: {value}")
    
    # ØªØ³Øª Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
    query = "How does TP53 relate to cancer?"
    result = service.process_query(
        query=query,
        retrieval_method=RetrievalMethod.INTELLIGENT,
        generation_model=GenerationModel.GPT_SIMULATION,
        max_depth=config['max_depth']
    )
    
    print(f"\nğŸ“Š Ù†ØªØ§ÛŒØ¬ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶:")
    print(f"  â€¢ ØªØ¹Ø¯Ø§Ø¯ Ù†ÙˆØ¯Ù‡Ø§: {len(result.get('retrieved_nodes', []))}")
    print(f"  â€¢ ØªØ¹Ø¯Ø§Ø¯ ÛŒØ§Ù„â€ŒÙ‡Ø§: {len(result.get('retrieved_edges', []))}")
    print(f"  â€¢ Ø·ÙˆÙ„ Ù¾Ø§Ø³Ø®: {len(result.get('answer', ''))} Ú©Ø§Ø±Ø§Ú©ØªØ±")
    
    return result

def test_increased_limits():
    """ØªØ³Øª Ø¨Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§"""
    print("\nğŸ§ª ØªØ³Øª Ø¨Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§")
    print("=" * 50)
    
    service = GraphRAGService()
    
    # Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
    service.set_config(
        max_nodes=20,           # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø² 10 Ø¨Ù‡ 20
        max_edges=40,           # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø² 20 Ø¨Ù‡ 40
        max_depth=4,            # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø² 3 Ø¨Ù‡ 4
        max_paths=10,           # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø² 5 Ø¨Ù‡ 10
        max_context_length=3000, # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø² 2000 Ø¨Ù‡ 3000
        max_answer_tokens=1500,  # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø² 1000 Ø¨Ù‡ 1500
        max_prompt_tokens=6000   # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø² 4000 Ø¨Ù‡ 6000
    )
    
    # Ù†Ù…Ø§ÛŒØ´ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø¯ÛŒØ¯
    config = service.get_config()
    print("ğŸ“‹ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø¯ÛŒØ¯:")
    for key, value in config.items():
        print(f"  â€¢ {key}: {value}")
    
    # ØªØ³Øª Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø¯ÛŒØ¯
    query = "How does TP53 relate to cancer?"
    result = service.process_query(
        query=query,
        retrieval_method=RetrievalMethod.INTELLIGENT,
        generation_model=GenerationModel.GPT_SIMULATION,
        max_depth=config['max_depth']
    )
    
    print(f"\nğŸ“Š Ù†ØªØ§ÛŒØ¬ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø¯ÛŒØ¯:")
    print(f"  â€¢ ØªØ¹Ø¯Ø§Ø¯ Ù†ÙˆØ¯Ù‡Ø§: {len(result.get('retrieved_nodes', []))}")
    print(f"  â€¢ ØªØ¹Ø¯Ø§Ø¯ ÛŒØ§Ù„â€ŒÙ‡Ø§: {len(result.get('retrieved_edges', []))}")
    print(f"  â€¢ Ø·ÙˆÙ„ Ù¾Ø§Ø³Ø®: {len(result.get('answer', ''))} Ú©Ø§Ø±Ø§Ú©ØªØ±")
    
    return result

def test_decreased_limits():
    """ØªØ³Øª Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§"""
    print("\nğŸ§ª ØªØ³Øª Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§")
    print("=" * 50)
    
    service = GraphRAGService()
    
    # Ú©Ø§Ù‡Ø´ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
    service.set_config(
        max_nodes=5,            # Ú©Ø§Ù‡Ø´ Ø§Ø² 10 Ø¨Ù‡ 5
        max_edges=10,           # Ú©Ø§Ù‡Ø´ Ø§Ø² 20 Ø¨Ù‡ 10
        max_depth=2,            # Ú©Ø§Ù‡Ø´ Ø§Ø² 3 Ø¨Ù‡ 2
        max_paths=3,            # Ú©Ø§Ù‡Ø´ Ø§Ø² 5 Ø¨Ù‡ 3
        max_context_length=1000, # Ú©Ø§Ù‡Ø´ Ø§Ø² 2000 Ø¨Ù‡ 1000
        max_answer_tokens=500,   # Ú©Ø§Ù‡Ø´ Ø§Ø² 1000 Ø¨Ù‡ 500
        max_prompt_tokens=2000   # Ú©Ø§Ù‡Ø´ Ø§Ø² 4000 Ø¨Ù‡ 2000
    )
    
    # Ù†Ù…Ø§ÛŒØ´ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø¯ÛŒØ¯
    config = service.get_config()
    print("ğŸ“‹ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø¯ÛŒØ¯:")
    for key, value in config.items():
        print(f"  â€¢ {key}: {value}")
    
    # ØªØ³Øª Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø¯ÛŒØ¯
    query = "How does TP53 relate to cancer?"
    result = service.process_query(
        query=query,
        retrieval_method=RetrievalMethod.INTELLIGENT,
        generation_model=GenerationModel.GPT_SIMULATION,
        max_depth=config['max_depth']
    )
    
    print(f"\nğŸ“Š Ù†ØªØ§ÛŒØ¬ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø¯ÛŒØ¯:")
    print(f"  â€¢ ØªØ¹Ø¯Ø§Ø¯ Ù†ÙˆØ¯Ù‡Ø§: {len(result.get('retrieved_nodes', []))}")
    print(f"  â€¢ ØªØ¹Ø¯Ø§Ø¯ ÛŒØ§Ù„â€ŒÙ‡Ø§: {len(result.get('retrieved_edges', []))}")
    print(f"  â€¢ Ø·ÙˆÙ„ Ù¾Ø§Ø³Ø®: {len(result.get('answer', ''))} Ú©Ø§Ø±Ø§Ú©ØªØ±")
    
    return result

def test_performance_comparison():
    """Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø®ØªÙ„Ù"""
    print("\nğŸ§ª Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯")
    print("=" * 50)
    
    queries = [
        "How does TP53 relate to cancer?",
        "What genes are expressed in heart?",
        "Which drugs treat diabetes?",
        "What is the role of BRCA1 in breast cancer?"
    ]
    
    configs = {
        'Ú©Ù…': {'max_nodes': 5, 'max_depth': 2, 'max_answer_tokens': 500},
        'Ù…ØªÙˆØ³Ø·': {'max_nodes': 10, 'max_depth': 3, 'max_answer_tokens': 1000},
        'Ø²ÛŒØ§Ø¯': {'max_nodes': 20, 'max_depth': 4, 'max_answer_tokens': 1500}
    }
    
    for config_name, config_values in configs.items():
        print(f"\nğŸ”§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª {config_name}:")
        service = GraphRAGService()
        service.set_config(**config_values)
        
        total_nodes = 0
        total_edges = 0
        total_answer_length = 0
        
        for query in queries:
            result = service.process_query(
                query=query,
                retrieval_method=RetrievalMethod.INTELLIGENT,
                generation_model=GenerationModel.GPT_SIMULATION
            )
            
            total_nodes += len(result.get('retrieved_nodes', []))
            total_edges += len(result.get('retrieved_edges', []))
            total_answer_length += len(result.get('answer', ''))
        
        avg_nodes = total_nodes / len(queries)
        avg_edges = total_edges / len(queries)
        avg_answer_length = total_answer_length / len(queries)
        
        print(f"  â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù†ÙˆØ¯Ù‡Ø§: {avg_nodes:.1f}")
        print(f"  â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ÛŒØ§Ù„â€ŒÙ‡Ø§: {avg_edges:.1f}")
        print(f"  â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø·ÙˆÙ„ Ù¾Ø§Ø³Ø®: {avg_answer_length:.0f} Ú©Ø§Ø±Ø§Ú©ØªØ±")

def test_web_app_config():
    """ØªØ³Øª ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±Ø§Ø¨Ø· ÙˆØ¨"""
    print("\nğŸŒ ØªØ³Øª ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±Ø§Ø¨Ø· ÙˆØ¨")
    print("=" * 50)
    
    service = GraphRAGService()
    
    # ØªØ³Øª ØªØºÛŒÛŒØ± ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    print("ğŸ“ ØªØºÛŒÛŒØ± ØªÙ†Ø¸ÛŒÙ…Ø§Øª...")
    service.set_config(
        max_nodes=15,
        max_edges=30,
        max_depth=3,
        max_answer_tokens=1200
    )
    
    # Ø¨Ø±Ø±Ø³ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø¯ÛŒØ¯
    config = service.get_config()
    print("âœ… ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø¯ÛŒØ¯:")
    for key, value in config.items():
        print(f"  â€¢ {key}: {value}")
    
    # ØªØ³Øª Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    print("\nğŸ”„ Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª...")
    service.set_config(
        max_nodes=10,
        max_edges=20,
        max_depth=3,
        max_paths=5,
        max_context_length=2000,
        max_answer_tokens=1000,
        max_prompt_tokens=4000,
        enable_verbose_logging=True,
        enable_biological_enrichment=True,
        enable_smart_filtering=True
    )
    
    config = service.get_config()
    print("âœ… ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ø´Ø¯Ù‡:")
    for key, value in config.items():
        print(f"  â€¢ {key}: {value}")

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    print("ğŸ§ª ØªØ³Øª ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ GraphRAG")
    print("=" * 60)
    
    # ØªØ³Øª Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
    test_default_limits()
    
    # ØªØ³Øª Ø¨Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
    test_increased_limits()
    
    # ØªØ³Øª Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
    test_decreased_limits()
    
    # Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯
    test_performance_comparison()
    
    # ØªØ³Øª ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±Ø§Ø¨Ø· ÙˆØ¨
    test_web_app_config()
    
    print("\nâœ… ØªÙ…Ø§Ù… ØªØ³Øªâ€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
    print("\nğŸŒ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø±Ø§Ø¨Ø· ÙˆØ¨:")
    print("   1. Ø³Ø±ÙˆØ± Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯: python web_app.py")
    print("   2. Ø¨Ù‡ Ø¢Ø¯Ø±Ø³ http://localhost:5000 Ø¨Ø±ÙˆÛŒØ¯")
    print("   3. Ø±ÙˆÛŒ Ø¯Ú©Ù…Ù‡ 'ØªÙ†Ø¸ÛŒÙ…Ø§Øª' Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯")
    print("   4. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†ÛŒØ¯")

if __name__ == "__main__":
    main() 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ØªØ³Øª Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø³Ø§Ø¯Ù‡ Ùˆ Ù‡ÙˆØ´Ù…Ù†Ø¯
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from graphrag_service import GraphRAGService, RetrievalMethod, GenerationModel

def test_text_generation_types():
    """ØªØ³Øª Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø³Ø§Ø¯Ù‡ Ùˆ Ù‡ÙˆØ´Ù…Ù†Ø¯"""
    
    print("ğŸ§ª Ø´Ø±ÙˆØ¹ ØªØ³Øª Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ†...")
    print("=" * 60)
    
    # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆÛŒØ³
    service = GraphRAGService()
    service.initialize()
    
    # Ø³ÙˆØ§Ù„ ØªØ³Øª
    test_query = "What genes are expressed in heart?"
    
    print(f"ğŸ“ Ø³ÙˆØ§Ù„ ØªØ³Øª: {test_query}")
    print()
    
    # ØªØ³Øª Ø¨Ø§ Ù†ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø³Ø§Ø¯Ù‡
    print("ğŸ”¹ ØªØ³Øª Ù†ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø³Ø§Ø¯Ù‡:")
    print("-" * 40)
    
    try:
        result_simple = service.process_query(
            query=test_query,
            retrieval_method=RetrievalMethod.BFS,
            generation_model=GenerationModel.GENERAL_SIMPLE,
            text_generation_type='SIMPLE',
            max_depth=2
        )
        
        print("âœ… Ù†ØªÛŒØ¬Ù‡ Ù†ÙˆØ¹ Ø³Ø§Ø¯Ù‡:")
        print(f"â€¢ Ù¾Ø§Ø³Ø®: {result_simple['answer'][:200]}...")
        print(f"â€¢ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {result_simple['confidence']}")
        print(f"â€¢ Ù†ÙˆØ¹ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡: Ø³Ø§Ø¯Ù‡")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù†ÙˆØ¹ Ø³Ø§Ø¯Ù‡: {e}")
    
    print()
    print("=" * 60)
    print()
    
    # ØªØ³Øª Ø¨Ø§ Ù†ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ù‡ÙˆØ´Ù…Ù†Ø¯
    print("ğŸ”¹ ØªØ³Øª Ù†ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ù‡ÙˆØ´Ù…Ù†Ø¯:")
    print("-" * 40)
    
    try:
        result_intelligent = service.process_query(
            query=test_query,
            retrieval_method=RetrievalMethod.BFS,
            generation_model=GenerationModel.GENERAL_SIMPLE,
            text_generation_type='INTELLIGENT',
            max_depth=2
        )
        
        print("âœ… Ù†ØªÛŒØ¬Ù‡ Ù†ÙˆØ¹ Ù‡ÙˆØ´Ù…Ù†Ø¯:")
        print(f"â€¢ Ù¾Ø§Ø³Ø®: {result_intelligent['answer'][:200]}...")
        print(f"â€¢ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {result_intelligent['confidence']}")
        print(f"â€¢ Ù†ÙˆØ¹ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡: Ù‡ÙˆØ´Ù…Ù†Ø¯")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù†ÙˆØ¹ Ù‡ÙˆØ´Ù…Ù†Ø¯: {e}")
    
    print()
    print("=" * 60)
    print()
    
    # Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ØªØ§ÛŒØ¬
    print("ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ØªØ§ÛŒØ¬:")
    print("-" * 40)
    
    if 'result_simple' in locals() and 'result_intelligent' in locals():
        print("âœ… Ù‡Ø± Ø¯Ùˆ Ù†ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø¬Ø±Ø§ Ø´Ø¯Ù†Ø¯")
        print(f"â€¢ ØªÙØ§ÙˆØª Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {result_intelligent['confidence'] - result_simple['confidence']:.2f}")
        
        # Ø¨Ø±Ø±Ø³ÛŒ ØªÙØ§ÙˆØª Ø¯Ø± Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡
        if 'context_text' in result_simple and 'context_text' in result_intelligent:
            simple_context_length = len(result_simple['context_text'])
            intelligent_context_length = len(result_intelligent['context_text'])
            print(f"â€¢ Ø·ÙˆÙ„ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ø³Ø§Ø¯Ù‡: {simple_context_length} Ú©Ø§Ø±Ø§Ú©ØªØ±")
            print(f"â€¢ Ø·ÙˆÙ„ Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯: {intelligent_context_length} Ú©Ø§Ø±Ø§Ú©ØªØ±")
            print(f"â€¢ ØªÙØ§ÙˆØª Ø·ÙˆÙ„: {intelligent_context_length - simple_context_length} Ú©Ø§Ø±Ø§Ú©ØªØ±")
    else:
        print("âŒ Ø§Ù…Ú©Ø§Ù† Ù…Ù‚Ø§ÛŒØ³Ù‡ Ú©Ø§Ù…Ù„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
    
    print()
    print("ğŸ‰ ØªØ³Øª Ú©Ø§Ù…Ù„ Ø´Ø¯!")

if __name__ == "__main__":
    test_text_generation_types() 